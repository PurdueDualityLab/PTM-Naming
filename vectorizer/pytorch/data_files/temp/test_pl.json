{"bert-base-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "bert-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "bert-large-cased-whole-word-masking": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "bert-large-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "bert-large-uncased-whole-word-masking": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23}, "bert-large-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23}, "byeongal/bert-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "mlcorelib/deberta-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "model-attribution-challenge/bert-base-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "model-attribution-challenge/bert-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "Narsil/bert-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "bert-base-multilingual-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "bert-base-multilingual-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "Geotrend/bert-base-10lang-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-15lang-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-25lang-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-ar-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-bg-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-da-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-de-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-el-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-ar-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-bg-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-da-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-de-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-el-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-el-ru-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-es-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-es-it-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-es-pt-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-es-zh-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-ar-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-da-ja-vi-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-de-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-de-no-da-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-es-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-es-de-zh-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-es-pt-it-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-it-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-lt-no-pl-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-nl-ru-ar-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-uk-el-ro-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-zh-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-fr-zh-ja-vi-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-hi-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-it-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-ja-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-lt-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-nl-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-no-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-pl-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-pt-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-ro-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-ru-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-sw-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-th-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-tr-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-uk-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-ur-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-vi-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-zh-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-en-zh-hi-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-es-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-fr-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-hi-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-it-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-ja-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-lt-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-nl-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-no-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-pl-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-pt-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-ro-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-ru-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-sw-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-th-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-tr-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-uk-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-ur-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-vi-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Geotrend/bert-base-zh-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "amine/bert-base-5lang-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "asafaya/bert-base-arabic": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "asafaya/bert-large-arabic": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "asafaya/bert-medium-arabic": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 8, "(add, softmax)": 8, "(softmax, Dropout)": 8, "(Dropout, matmul)": 8, "(matmul, permute)": 8, "(permute, contiguous)": 8, "(contiguous, view)": 8, "(view, Linear)": 8, "(Linear, Dropout)": 16, "(Dropout, add)": 16, "(add, LayerNorm)": 16, "(LayerNorm, Linear)": 29, "(LayerNorm, add)": 15, "(Linear, GELUActivation)": 8, "(GELUActivation, Linear)": 8, "(Linear, view)": 21, "(view, permute)": 21, "(permute, matmul)": 14, "(permute, transpose)": 7, "(transpose, matmul)": 7, "(matmul, div)": 7, "(div, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "asafaya/bert-mini-arabic": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, matmul)": 6, "(matmul, div)": 3, "(div, add)": 3, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 3, "(transpose, matmul)": 3}, "aubmindlab/bert-base-arabert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "aubmindlab/bert-base-arabertv01": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "aubmindlab/bert-base-arabertv02-twitter": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "aubmindlab/bert-base-arabertv02": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "aubmindlab/bert-base-arabertv2": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "aubmindlab/bert-large-arabertv02-twitter": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "aubmindlab/bert-large-arabertv02": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "aubmindlab/bert-large-arabertv2": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "biu-nlp/alephbert-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "cahya/bert-base-indonesian-1.5G": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "cahya/bert-base-indonesian-522M": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "dbmdz/bert-base-italian-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "dbmdz/bert-base-italian-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "dbmdz/bert-base-italian-xxl-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "dbmdz/bert-base-italian-xxl-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "hiroshi-matsuda-rit/bert-base-japanese-basic-char-v2": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "onlplab/alephbert-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "sagorsarker/bangla-bert-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "w11wo/javanese-bert-small": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "mmaguero/gn-bert-base-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "mmaguero/gn-bert-large-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "mmaguero/gn-bert-tiny-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 2, "(add, softmax)": 2, "(softmax, Dropout)": 2, "(Dropout, matmul)": 2, "(matmul, permute)": 2, "(permute, contiguous)": 2, "(contiguous, view)": 2, "(view, Linear)": 2, "(Linear, Dropout)": 4, "(Dropout, add)": 4, "(add, LayerNorm)": 4, "(LayerNorm, Linear)": 5, "(LayerNorm, add)": 3, "(Linear, GELUActivation)": 2, "(GELUActivation, Linear)": 2, "(Linear, view)": 3, "(view, permute)": 3, "(permute, matmul)": 2, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 1, "(transpose, matmul)": 1, "(matmul, div)": 1, "(div, add)": 1}, "mmaguero/gn-bert-small-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, view)": 15, "(view, permute)": 15, "(permute, matmul)": 10, "(matmul, div)": 5, "(div, add)": 5, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(permute, transpose)": 5, "(transpose, matmul)": 5}, "mmaguero/beto-gn-base-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "mmaguero/multilingual-bert-gn-base-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "rmihaylov/bert-base-theseus-bg": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 15, "(view, permute)": 15, "(permute, matmul)": 10, "(matmul, div)": 5, "(div, add)": 5, "(permute, transpose)": 5, "(transpose, matmul)": 5}, "rmihaylov/bert-base-bg": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "StanfordAIMI/RadBERT": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "conan1024hao/cjkbert-small": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(Linear, view)": 9, "(view, permute)": 9, "(permute, matmul)": 6, "(matmul, div)": 3, "(div, add)": 3, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(permute, transpose)": 3, "(transpose, matmul)": 3}, "StevenLimcorn/MelayuBERT": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "anas-awadalla/bert-medium-pretrained-on-squad": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 8, "(add, softmax)": 8, "(softmax, Dropout)": 8, "(Dropout, matmul)": 8, "(matmul, permute)": 8, "(permute, contiguous)": 8, "(contiguous, view)": 8, "(view, Linear)": 8, "(Linear, Dropout)": 16, "(Dropout, add)": 16, "(add, LayerNorm)": 16, "(LayerNorm, Linear)": 29, "(LayerNorm, add)": 15, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 8, "(GELUActivation, Linear)": 8, "(Linear, view)": 21, "(view, permute)": 21, "(permute, matmul)": 14, "(matmul, div)": 7, "(div, add)": 7, "(permute, transpose)": 7, "(transpose, matmul)": 7}, "anas-awadalla/bert-small-pretrained-on-squad": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(permute, matmul)": 6}, "Chrispfield/bert-base-uncased-issues-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "ariesutiono/finetuned-test-1": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "ariesutiono/scibert-lm-const-finetuned-20": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "ariesutiono/scibert-lm-v1-finetuned-20": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "ariesutiono/scibert-lm-v2-finetuned-20": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "Ebtihal/AraBertMo_base_V1": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V2": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V3": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V4": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V5": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V6": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V7": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V8": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V9": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Ebtihal/AraBertMo_base_V10": {"([INPUT], __getitem__)": 1, "(__getitem__, mul)": 1, "(mul, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(permute, [OUTPUT])": 22, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 22}, "Narshion/bert-base-multilingual-cased-urgency": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "markverschuren/bert-base-dutch-cased-finetuned-mark": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "vppvgit/BiblItBERT-1": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "vppvgit/Finetuned": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "xxr/bert-base-uncased-issues-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "xxr/bert-base-uncased-multi-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "xxr/bert-base-chinese-complaint-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "Kowsher/bangla-bert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "lewtun/MiniLM-L12-H384-uncased-finetuned-imdb": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "IIC/dpr-spanish-passage_encoder-squades-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "IIC/dpr-spanish-question_encoder-squades-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "IIC/dpr-spanish-passage_encoder-allqa-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "IIC/dpr-spanish-question_encoder-allqa-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "MutazYoune/Ara_DialectBERT": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "saghar/TinyBERT_General_6L_768D-finetuned-wikitext103": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(Dropout, [OUTPUT])": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(LayerNorm, [OUTPUT])": 6, "(Linear, view)": 15, "(view, permute)": 15, "(permute, matmul)": 10, "(LayerNorm, __getitem__)": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 5, "(transpose, matmul)": 5, "(matmul, div)": 5, "(div, add)": 5}, "saghar/TinyBERT_L-4_H-312_v2-finetuned-wikitext103": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(Dropout, [OUTPUT])": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 4, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, matmul)": 6, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3}, "saghar/xtremedistil-l6-h384-uncased-finetuned-wikitext103": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(Dropout, [OUTPUT])": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(LayerNorm, [OUTPUT])": 6, "(Linear, view)": 15, "(view, permute)": 15, "(permute, matmul)": 10, "(LayerNorm, __getitem__)": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(matmul, div)": 5, "(div, add)": 5, "(permute, transpose)": 5, "(transpose, matmul)": 5}, "saghar/xtremedistil-l12-h384-uncased-finetuned-wikitext103": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(Dropout, [OUTPUT])": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, [OUTPUT])": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "SauravMaheshkar/clr-finetuned-bert-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "SauravMaheshkar/clr-finetuned-bert-large-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23}, "SauravMaheshkar/clr-pretrained-bert-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "Tsubasaz/clinical-pubmed-bert-base-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "Tsubasaz/clinical-pubmed-bert-base-512": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "alexanderfalk/danbert-small-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, view)": 15, "(view, permute)": 15, "(permute, transpose)": 5, "(transpose, matmul)": 5, "(matmul, div)": 5, "(div, add)": 5, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(permute, matmul)": 10, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "pablocosta/bertabaporu-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "pablocosta/bertabaporu-large-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "bashar-talafha/multi-dialect-bert-base-arabic": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "batterydata/batterybert-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "batterydata/batterybert-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "batterydata/batteryscibert-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "batterydata/batteryscibert-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "batterydata/batteryonlybert-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "batterydata/batteryonlybert-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "qarib/bert-base-qarib": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "qarib/bert-base-qarib60_1790k": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "qarib/bert-base-qarib60_1970k": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "qarib/bert-base-qarib60_860k": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "cook/cicero-similis": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(Linear, view)": 15, "(view, permute)": 15, "(permute, matmul)": 10, "(matmul, div)": 5, "(div, add)": 5, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 5, "(transpose, matmul)": 5}, "coppercitylabs/uzbert-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "damlab/HIV_BERT": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 30, "(add, softmax)": 30, "(softmax, Dropout)": 30, "(Dropout, matmul)": 30, "(matmul, permute)": 30, "(permute, contiguous)": 30, "(contiguous, view)": 30, "(view, Linear)": 30, "(Linear, Dropout)": 60, "(Dropout, add)": 60, "(add, LayerNorm)": 60, "(LayerNorm, Linear)": 117, "(LayerNorm, add)": 59, "(Linear, view)": 87, "(view, permute)": 87, "(permute, transpose)": 29, "(transpose, matmul)": 29, "(matmul, div)": 29, "(div, add)": 29, "(permute, matmul)": 58, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 30, "(GELUActivation, Linear)": 30}, "baikal-nlp/dbert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "michelecafagna26/vinvl-base-image-captioning": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "flax-community/bert-base-uncased-swahili": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "indolem/indobert-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "indolem/indobertweet-base-uncased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "jackaduma/SecBERT": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, view)": 15, "(view, permute)": 15, "(permute, transpose)": 5, "(transpose, matmul)": 5, "(matmul, div)": 5, "(div, add)": 5, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(permute, matmul)": 10, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "johngiorgi/declutr-sci-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(LayerNorm, [OUTPUT])": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(LayerNorm, __getitem__)": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "l3cube-pune/marathi-bert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "l3cube-pune/marathi-bert-v2": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "l3cube-pune/marathi-tweets-bert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "l3cube-pune/marathi-tweets-bert-hateful": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "l3cube-pune/mr-random-twt-1m": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "l3cube-pune/marathi-bert-scratch": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "l3cube-pune/mr-least-ht-1m": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "l3cube-pune/marathi-tweets-bert-scratch": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "neuralmind/bert-base-portuguese-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "neuralmind/bert-large-portuguese-cased": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "nlp4good/psych-search": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "pierreguillou/bert-base-cased-pt-lenerbr": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "pierreguillou/bert-large-cased-pt-lenerbr": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "pritamdeka/PubMedBert-abstract-cord19-v2": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "pritamdeka/PubMedBert-abstract-cord19": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "pritamdeka/PubMedBert-fulltext-cord19": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "naver/splade-cocondenser-selfdistil": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "naver/splade-cocondenser-ensembledistil": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "naver/efficient-splade-VI-BT-large-query": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 2, "(add, softmax)": 2, "(softmax, Dropout)": 2, "(Dropout, matmul)": 2, "(matmul, permute)": 2, "(permute, contiguous)": 2, "(contiguous, view)": 2, "(view, Linear)": 2, "(Linear, Dropout)": 4, "(Dropout, add)": 4, "(add, LayerNorm)": 4, "(LayerNorm, Linear)": 5, "(LayerNorm, add)": 3, "(Linear, GELUActivation)": 2, "(GELUActivation, Linear)": 2, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 3, "(view, permute)": 3, "(permute, matmul)": 2, "(matmul, div)": 1, "(div, add)": 1, "(permute, transpose)": 1, "(transpose, matmul)": 1}, "smeylan/childes-bert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "tuhailong/chinese-roberta-wwm-ext": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "uer/chinese_roberta_L-10_H-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 10, "(add, softmax)": 10, "(softmax, Dropout)": 10, "(Dropout, matmul)": 10, "(matmul, permute)": 10, "(permute, contiguous)": 10, "(contiguous, view)": 10, "(view, Linear)": 10, "(Linear, Dropout)": 20, "(Dropout, add)": 20, "(add, LayerNorm)": 20, "(LayerNorm, Linear)": 37, "(LayerNorm, add)": 19, "(Linear, view)": 27, "(view, permute)": 27, "(permute, transpose)": 9, "(transpose, matmul)": 9, "(matmul, div)": 9, "(div, add)": 9, "(permute, matmul)": 18, "(Linear, GELUActivation)": 10, "(GELUActivation, Linear)": 10, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/chinese_roberta_L-10_H-256": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 10, "(add, softmax)": 10, "(softmax, Dropout)": 10, "(Dropout, matmul)": 10, "(matmul, permute)": 10, "(permute, contiguous)": 10, "(contiguous, view)": 10, "(view, Linear)": 10, "(Linear, Dropout)": 20, "(Dropout, add)": 20, "(add, LayerNorm)": 20, "(LayerNorm, Linear)": 37, "(LayerNorm, add)": 19, "(Linear, GELUActivation)": 10, "(GELUActivation, Linear)": 10, "(Linear, view)": 27, "(view, permute)": 27, "(permute, matmul)": 18, "(matmul, div)": 9, "(div, add)": 9, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 9, "(transpose, matmul)": 9}, "uer/chinese_roberta_L-10_H-512": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 10, "(add, softmax)": 10, "(softmax, Dropout)": 10, "(Dropout, matmul)": 10, "(matmul, permute)": 10, "(permute, contiguous)": 10, "(contiguous, view)": 10, "(view, Linear)": 10, "(Linear, Dropout)": 20, "(Dropout, add)": 20, "(add, LayerNorm)": 20, "(LayerNorm, Linear)": 37, "(LayerNorm, add)": 19, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 10, "(GELUActivation, Linear)": 10, "(Linear, view)": 27, "(view, permute)": 27, "(permute, matmul)": 18, "(matmul, div)": 9, "(div, add)": 9, "(permute, transpose)": 9, "(transpose, matmul)": 9}, "uer/chinese_roberta_L-10_H-768": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 10, "(add, softmax)": 10, "(softmax, Dropout)": 10, "(Dropout, matmul)": 10, "(matmul, permute)": 10, "(permute, contiguous)": 10, "(contiguous, view)": 10, "(view, Linear)": 10, "(Linear, Dropout)": 20, "(Dropout, add)": 20, "(add, LayerNorm)": 20, "(LayerNorm, Linear)": 37, "(LayerNorm, add)": 19, "(Linear, view)": 27, "(view, permute)": 27, "(permute, transpose)": 9, "(transpose, matmul)": 9, "(matmul, div)": 9, "(div, add)": 9, "(Linear, GELUActivation)": 10, "(GELUActivation, Linear)": 10, "(permute, matmul)": 18, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/chinese_roberta_L-12_H-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(permute, matmul)": 22, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/chinese_roberta_L-12_H-256": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "uer/chinese_roberta_L-12_H-512": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/chinese_roberta_L-12_H-768": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/chinese_roberta_L-2_H-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 2, "(add, softmax)": 2, "(softmax, Dropout)": 2, "(Dropout, matmul)": 2, "(matmul, permute)": 2, "(permute, contiguous)": 2, "(contiguous, view)": 2, "(view, Linear)": 2, "(Linear, Dropout)": 4, "(Dropout, add)": 4, "(add, LayerNorm)": 4, "(LayerNorm, Linear)": 5, "(LayerNorm, add)": 3, "(Linear, GELUActivation)": 2, "(GELUActivation, Linear)": 2, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 3, "(view, permute)": 3, "(permute, matmul)": 2, "(matmul, div)": 1, "(div, add)": 1, "(permute, transpose)": 1, "(transpose, matmul)": 1}, "uer/chinese_roberta_L-2_H-256": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 2, "(add, softmax)": 2, "(softmax, Dropout)": 2, "(Dropout, matmul)": 2, "(matmul, permute)": 2, "(permute, contiguous)": 2, "(contiguous, view)": 2, "(view, Linear)": 2, "(Linear, Dropout)": 4, "(Dropout, add)": 4, "(add, LayerNorm)": 4, "(LayerNorm, Linear)": 5, "(LayerNorm, add)": 3, "(Linear, GELUActivation)": 2, "(GELUActivation, Linear)": 2, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 3, "(view, permute)": 3, "(permute, transpose)": 1, "(transpose, matmul)": 1, "(matmul, div)": 1, "(div, add)": 1, "(permute, matmul)": 2}, "uer/chinese_roberta_L-2_H-512": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 2, "(add, softmax)": 2, "(softmax, Dropout)": 2, "(Dropout, matmul)": 2, "(matmul, permute)": 2, "(permute, contiguous)": 2, "(contiguous, view)": 2, "(view, Linear)": 2, "(Linear, Dropout)": 4, "(Dropout, add)": 4, "(add, LayerNorm)": 4, "(LayerNorm, Linear)": 5, "(LayerNorm, add)": 3, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 2, "(GELUActivation, Linear)": 2, "(Linear, view)": 3, "(view, permute)": 3, "(permute, transpose)": 1, "(transpose, matmul)": 1, "(matmul, div)": 1, "(div, add)": 1, "(permute, matmul)": 2}, "uer/chinese_roberta_L-2_H-768": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 2, "(add, softmax)": 2, "(softmax, Dropout)": 2, "(Dropout, matmul)": 2, "(matmul, permute)": 2, "(permute, contiguous)": 2, "(contiguous, view)": 2, "(view, Linear)": 2, "(Linear, Dropout)": 4, "(Dropout, add)": 4, "(add, LayerNorm)": 4, "(LayerNorm, Linear)": 5, "(LayerNorm, add)": 3, "(Linear, GELUActivation)": 2, "(GELUActivation, Linear)": 2, "(Linear, view)": 3, "(view, permute)": 3, "(permute, matmul)": 2, "(matmul, div)": 1, "(div, add)": 1, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 1, "(transpose, matmul)": 1}, "uer/chinese_roberta_L-4_H-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(Linear, view)": 9, "(view, permute)": 9, "(permute, matmul)": 6, "(matmul, div)": 3, "(div, add)": 3, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 3, "(transpose, matmul)": 3}, "uer/chinese_roberta_L-4_H-256": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, matmul)": 6, "(matmul, div)": 3, "(div, add)": 3, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 3, "(transpose, matmul)": 3}, "uer/chinese_roberta_L-4_H-512": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(permute, matmul)": 6}, "uer/chinese_roberta_L-4_H-768": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(Linear, view)": 9, "(view, permute)": 9, "(permute, matmul)": 6, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/chinese_roberta_L-6_H-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(Linear, view)": 15, "(view, permute)": 15, "(permute, matmul)": 10, "(matmul, div)": 5, "(div, add)": 5, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 5, "(transpose, matmul)": 5}, "uer/chinese_roberta_L-6_H-256": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(Linear, view)": 15, "(view, permute)": 15, "(permute, matmul)": 10, "(matmul, div)": 5, "(div, add)": 5, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 5, "(transpose, matmul)": 5}, "uer/chinese_roberta_L-6_H-512": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(Linear, view)": 15, "(view, permute)": 15, "(permute, matmul)": 10, "(matmul, div)": 5, "(div, add)": 5, "(permute, transpose)": 5, "(transpose, matmul)": 5}, "uer/chinese_roberta_L-6_H-768": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 6, "(add, softmax)": 6, "(softmax, Dropout)": 6, "(Dropout, matmul)": 6, "(matmul, permute)": 6, "(permute, contiguous)": 6, "(contiguous, view)": 6, "(view, Linear)": 6, "(Linear, Dropout)": 12, "(Dropout, add)": 12, "(add, LayerNorm)": 12, "(LayerNorm, Linear)": 21, "(LayerNorm, add)": 11, "(Linear, view)": 15, "(view, permute)": 15, "(permute, transpose)": 5, "(transpose, matmul)": 5, "(matmul, div)": 5, "(div, add)": 5, "(Linear, GELUActivation)": 6, "(GELUActivation, Linear)": 6, "(permute, matmul)": 10, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/chinese_roberta_L-8_H-128": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 8, "(add, softmax)": 8, "(softmax, Dropout)": 8, "(Dropout, matmul)": 8, "(matmul, permute)": 8, "(permute, contiguous)": 8, "(contiguous, view)": 8, "(view, Linear)": 8, "(Linear, Dropout)": 16, "(Dropout, add)": 16, "(add, LayerNorm)": 16, "(LayerNorm, Linear)": 29, "(LayerNorm, add)": 15, "(Linear, view)": 21, "(view, permute)": 21, "(permute, transpose)": 7, "(transpose, matmul)": 7, "(matmul, div)": 7, "(div, add)": 7, "(permute, matmul)": 14, "(Linear, GELUActivation)": 8, "(GELUActivation, Linear)": 8, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/chinese_roberta_L-8_H-256": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 8, "(add, softmax)": 8, "(softmax, Dropout)": 8, "(Dropout, matmul)": 8, "(matmul, permute)": 8, "(permute, contiguous)": 8, "(contiguous, view)": 8, "(view, Linear)": 8, "(Linear, Dropout)": 16, "(Dropout, add)": 16, "(add, LayerNorm)": 16, "(LayerNorm, Linear)": 29, "(LayerNorm, add)": 15, "(Linear, GELUActivation)": 8, "(GELUActivation, Linear)": 8, "(Linear, view)": 21, "(view, permute)": 21, "(permute, matmul)": 14, "(matmul, div)": 7, "(div, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 7, "(transpose, matmul)": 7}, "uer/chinese_roberta_L-8_H-512": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 8, "(add, softmax)": 8, "(softmax, Dropout)": 8, "(Dropout, matmul)": 8, "(matmul, permute)": 8, "(permute, contiguous)": 8, "(contiguous, view)": 8, "(view, Linear)": 8, "(Linear, Dropout)": 16, "(Dropout, add)": 16, "(add, LayerNorm)": 16, "(LayerNorm, Linear)": 29, "(LayerNorm, add)": 15, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 8, "(GELUActivation, Linear)": 8, "(Linear, view)": 21, "(view, permute)": 21, "(permute, matmul)": 14, "(matmul, div)": 7, "(div, add)": 7, "(permute, transpose)": 7, "(transpose, matmul)": 7}, "uer/chinese_roberta_L-8_H-768": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 8, "(add, softmax)": 8, "(softmax, Dropout)": 8, "(Dropout, matmul)": 8, "(matmul, permute)": 8, "(permute, contiguous)": 8, "(contiguous, view)": 8, "(view, Linear)": 8, "(Linear, Dropout)": 16, "(Dropout, add)": 16, "(add, LayerNorm)": 16, "(LayerNorm, Linear)": 29, "(LayerNorm, add)": 15, "(Linear, view)": 21, "(view, permute)": 21, "(permute, transpose)": 7, "(transpose, matmul)": 7, "(matmul, div)": 7, "(div, add)": 7, "(Linear, GELUActivation)": 8, "(GELUActivation, Linear)": 8, "(permute, matmul)": 14, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "uer/roberta-tiny-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 2, "(add, softmax)": 2, "(softmax, Dropout)": 2, "(Dropout, matmul)": 2, "(matmul, permute)": 2, "(permute, contiguous)": 2, "(contiguous, view)": 2, "(view, Linear)": 2, "(Linear, Dropout)": 4, "(Dropout, add)": 4, "(add, LayerNorm)": 4, "(LayerNorm, Linear)": 5, "(LayerNorm, add)": 3, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 2, "(GELUActivation, Linear)": 2, "(Linear, view)": 3, "(view, permute)": 3, "(permute, transpose)": 1, "(transpose, matmul)": 1, "(matmul, div)": 1, "(div, add)": 1, "(permute, matmul)": 2}, "uer/roberta-mini-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 6}, "uer/roberta-small-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 6}, "uer/roberta-medium-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 8, "(add, softmax)": 8, "(softmax, Dropout)": 8, "(Dropout, matmul)": 8, "(matmul, permute)": 8, "(permute, contiguous)": 8, "(contiguous, view)": 8, "(view, Linear)": 8, "(Linear, Dropout)": 16, "(Dropout, add)": 16, "(add, LayerNorm)": 16, "(LayerNorm, Linear)": 29, "(LayerNorm, add)": 15, "(Linear, GELUActivation)": 8, "(GELUActivation, Linear)": 8, "(Linear, view)": 21, "(view, permute)": 21, "(permute, transpose)": 7, "(transpose, matmul)": 7, "(matmul, div)": 7, "(div, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, matmul)": 14}, "uer/roberta-base-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "uer/roberta-large-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "w11wo/javanese-bert-small-imdb": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "wangfan/jdt-fin-roberta-wwm-large": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "wangfan/jdt-fin-roberta-wwm": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "zjunlp/OntoProtein": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 30, "(add, softmax)": 30, "(softmax, Dropout)": 30, "(Dropout, matmul)": 30, "(matmul, permute)": 30, "(permute, contiguous)": 30, "(contiguous, view)": 30, "(view, Linear)": 30, "(Linear, Dropout)": 60, "(Dropout, add)": 60, "(add, LayerNorm)": 60, "(LayerNorm, Linear)": 117, "(LayerNorm, add)": 59, "(Linear, view)": 87, "(view, permute)": 87, "(permute, transpose)": 29, "(transpose, matmul)": 29, "(matmul, div)": 29, "(div, add)": 29, "(permute, matmul)": 58, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 30, "(GELUActivation, Linear)": 30}, "l3cube-pune/hing-bert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "l3cube-pune/hing-mbert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "l3cube-pune/hing-mbert-mixed": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "yarongef/DistilProtBert": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 15, "(add, softmax)": 15, "(softmax, Dropout)": 15, "(Dropout, matmul)": 15, "(matmul, permute)": 15, "(permute, contiguous)": 15, "(contiguous, view)": 15, "(view, Linear)": 15, "(Linear, Dropout)": 30, "(Dropout, add)": 30, "(add, LayerNorm)": 30, "(LayerNorm, Linear)": 57, "(LayerNorm, add)": 29, "(Linear, view)": 42, "(view, permute)": 42, "(permute, transpose)": 14, "(transpose, matmul)": 14, "(matmul, div)": 14, "(div, add)": 14, "(permute, matmul)": 28, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 15, "(GELUActivation, Linear)": 15}, "damlab/GO-language": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "MLRS/BERTu": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "MLRS/mBERTu": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "enoriega/kw_pubmed_1000_0.0003": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "mayankb96/bert-base-uncased-finetuned-lexglue": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "enoriega/kw_pubmed_vanilla_sentence_10000_0.0003_2": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "egumasa/bert-base-uncased-finetuned-academic": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "ysnow9876/alephbert-base-finetuned-for-shut": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "vasugoel/K-12BERT": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "rufimelo/Legal-BERTimbau-large": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "rufimelo/Legal-BERTimbau-base": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "rufimelo/Legal-BERTimbau-large-v2": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}, "muhtasham/bert-small-finetuned-legal-contracts10train10val": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(permute, matmul)": 6}, "muhtasham/bert-small-finetuned-legal-contracts-larger4010": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(permute, matmul)": 6}, "muhtasham/bert-small-finetuned-legal-contracts-larger20-5-1": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(permute, matmul)": 6}, "muhtasham/bert-small-finetuned-legal-definitions": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(permute, matmul)": 6}, "muhtasham/bert-small-finetuned-legal-definitions-longer": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 4, "(add, softmax)": 4, "(softmax, Dropout)": 4, "(Dropout, matmul)": 4, "(matmul, permute)": 4, "(permute, contiguous)": 4, "(contiguous, view)": 4, "(view, Linear)": 4, "(Linear, Dropout)": 8, "(Dropout, add)": 8, "(add, LayerNorm)": 8, "(LayerNorm, Linear)": 13, "(LayerNorm, add)": 7, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 4, "(GELUActivation, Linear)": 4, "(Linear, view)": 9, "(view, permute)": 9, "(permute, transpose)": 3, "(transpose, matmul)": 3, "(matmul, div)": 3, "(div, add)": 3, "(permute, matmul)": 6}, "GabrielDGC/bert-base-spanish-wwm-uncased-finetuned-imdb-spanish": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Luciano/bertimbau-base-finetuned-lener-br": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "Luciano/bert-base-multilingual-cased-finetuned-lener_br": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, matmul)": 22, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 11, "(transpose, matmul)": 11}, "AndyChiang/cdgp-csg-bert-cloth": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "AndyChiang/cdgp-csg-scibert-cloth": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "AndyChiang/cdgp-csg-bert-dgen": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "AndyChiang/cdgp-csg-scibert-dgen": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "Aunsiels/ChildBERT": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "KennethEnevoldsen/dfm-bert-large-v1-2048bsz-1Msteps": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(permute, transpose)": 23, "(transpose, matmul)": 23, "(matmul, div)": 23, "(div, add)": 23}, "alanila/autotrain-acc_keys-2347073860": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 12, "(add, softmax)": 12, "(softmax, Dropout)": 12, "(Dropout, matmul)": 12, "(matmul, permute)": 12, "(permute, contiguous)": 12, "(contiguous, view)": 12, "(view, Linear)": 12, "(Linear, Dropout)": 24, "(Dropout, add)": 24, "(add, LayerNorm)": 24, "(LayerNorm, Linear)": 45, "(LayerNorm, add)": 23, "(Linear, view)": 33, "(view, permute)": 33, "(permute, transpose)": 11, "(transpose, matmul)": 11, "(matmul, div)": 11, "(div, add)": 11, "(Linear, GELUActivation)": 12, "(GELUActivation, Linear)": 12, "(permute, matmul)": 22, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1}, "stjiris/bert-large-portuguese-cased-legal-mlm": {"([INPUT], __getitem__)": 1, "(__getitem__, to)": 1, "(to, __rsub__)": 1, "(__rsub__, mul)": 1, "(mul, add)": 24, "(add, softmax)": 24, "(softmax, Dropout)": 24, "(Dropout, matmul)": 24, "(matmul, permute)": 24, "(permute, contiguous)": 24, "(contiguous, view)": 24, "(view, Linear)": 24, "(Linear, Dropout)": 48, "(Dropout, add)": 48, "(add, LayerNorm)": 48, "(LayerNorm, Linear)": 93, "(LayerNorm, add)": 47, "(Linear, view)": 69, "(view, permute)": 69, "(permute, matmul)": 46, "(LayerNorm, __getitem__)": 1, "(LayerNorm, [OUTPUT])": 1, "(__getitem__, Linear)": 1, "(Linear, Tanh)": 1, "(Tanh, [OUTPUT])": 1, "(Linear, GELUActivation)": 24, "(GELUActivation, Linear)": 24, "(matmul, div)": 23, "(div, add)": 23, "(permute, transpose)": 23, "(transpose, matmul)": 23}}