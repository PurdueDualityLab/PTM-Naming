{"bert-base-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "bert-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "bert-large-cased-whole-word-masking": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 24, "(add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)], softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)], Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 24, "(matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)], permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)])": 24, "(permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)], contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)])": 24, "(contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)], view [(1, 5, 16, 64)]->[(1, 5, 1024)])": 24, "(view [(1, 5, 16, 64)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Dropout [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 48, "(add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)], LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)])": 48, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 4096)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 47, "(Linear [(1, 5, 1024)]->[(1, 5, 4096)], GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)])": 24, "(GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)], Linear [(1, 5, 4096)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 4096)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 69, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], view [(1, 5, 1024)]->[(1, 5, 16, 64)])": 69, "(view [(1, 5, 1024)]->[(1, 5, 16, 64)], permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)])": 69, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)])": 23, "(transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)], div [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 23, "(div [(1, 16, 5, 5)]->[(1, 16, 5, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 23, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], __getitem__ [(1, 5, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 23}, "bert-large-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 24, "(add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)], softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)], Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 24, "(matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)], permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)])": 24, "(permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)], contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)])": 24, "(contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)], view [(1, 5, 16, 64)]->[(1, 5, 1024)])": 24, "(view [(1, 5, 16, 64)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Dropout [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 48, "(add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)], LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)])": 48, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 4096)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 47, "(Linear [(1, 5, 1024)]->[(1, 5, 4096)], GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)])": 24, "(GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)], Linear [(1, 5, 4096)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 4096)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 69, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], view [(1, 5, 1024)]->[(1, 5, 16, 64)])": 69, "(view [(1, 5, 1024)]->[(1, 5, 16, 64)], permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)])": 69, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)])": 23, "(transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)], div [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 23, "(div [(1, 16, 5, 5)]->[(1, 16, 5, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 23, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], __getitem__ [(1, 5, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 23}, "bert-large-uncased-whole-word-masking": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 24, "(add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)], softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 24, "(softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)], Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 24, "(Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 24, "(matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)], permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)])": 24, "(permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)], contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)])": 24, "(contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)], view [(1, 4, 16, 64)]->[(1, 4, 1024)])": 24, "(view [(1, 4, 16, 64)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(Dropout [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 48, "(add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)], LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)])": 48, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 4096)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 47, "(Linear [(1, 4, 1024)]->[(1, 4, 4096)], GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)])": 24, "(GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)], Linear [(1, 4, 4096)]->[(1, 4, 1024)])": 24, "(Linear [(1, 4, 4096)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 69, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], view [(1, 4, 1024)]->[(1, 4, 16, 64)])": 69, "(view [(1, 4, 1024)]->[(1, 4, 16, 64)], permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)])": 69, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 23, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], __getitem__ [(1, 4, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)])": 23, "(transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 23, "(matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)], div [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 23, "(div [(1, 16, 4, 4)]->[(1, 16, 4, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 23, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 23}, "bert-large-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 24, "(add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)], softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 24, "(softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)], Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 24, "(Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 24, "(matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)], permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)])": 24, "(permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)], contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)])": 24, "(contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)], view [(1, 4, 16, 64)]->[(1, 4, 1024)])": 24, "(view [(1, 4, 16, 64)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(Dropout [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 48, "(add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)], LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)])": 48, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 4096)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 47, "(Linear [(1, 4, 1024)]->[(1, 4, 4096)], GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)])": 24, "(GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)], Linear [(1, 4, 4096)]->[(1, 4, 1024)])": 24, "(Linear [(1, 4, 4096)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 69, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], view [(1, 4, 1024)]->[(1, 4, 16, 64)])": 69, "(view [(1, 4, 1024)]->[(1, 4, 16, 64)], permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)])": 69, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 23, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], __getitem__ [(1, 4, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)])": 23, "(transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 23, "(matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)], div [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 23, "(div [(1, 16, 4, 4)]->[(1, 16, 4, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 23, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 23}, "byeongal/bert-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "mlcorelib/deberta-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "model-attribution-challenge/bert-base-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "model-attribution-challenge/bert-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "Narsil/bert-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "bert-base-multilingual-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "bert-base-multilingual-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "Geotrend/bert-base-10lang-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-15lang-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-25lang-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-ar-cased": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Geotrend/bert-base-bg-cased": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Geotrend/bert-base-da-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-de-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-el-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-ar-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-bg-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-da-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-de-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-el-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-el-ru-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-es-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-es-it-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-es-pt-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-es-zh-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-ar-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-da-ja-vi-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-de-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-de-no-da-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-es-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-es-de-zh-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-es-pt-it-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-it-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-lt-no-pl-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-nl-ru-ar-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-uk-el-ro-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-zh-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-fr-zh-ja-vi-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-hi-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-it-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-ja-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-lt-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-nl-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-no-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-pl-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-pt-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-ro-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-ru-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-sw-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-th-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-tr-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-uk-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-ur-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-vi-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-zh-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-en-zh-hi-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-es-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-fr-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-hi-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-it-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-ja-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-lt-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-nl-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-no-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-pl-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-pt-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-ro-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-ru-cased": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Geotrend/bert-base-sw-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-th-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-tr-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-uk-cased": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Geotrend/bert-base-ur-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-vi-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "Geotrend/bert-base-zh-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "amine/bert-base-5lang-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "asafaya/bert-base-arabic": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "asafaya/bert-large-arabic": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "asafaya/bert-medium-arabic": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 8, 7, 7), (1, 1, 1, 7)]->[(1, 8, 7, 7)])": 8, "(add [(1, 8, 7, 7), (1, 1, 1, 7)]->[(1, 8, 7, 7)], softmax [(1, 8, 7, 7)]->[(1, 8, 7, 7)])": 8, "(softmax [(1, 8, 7, 7)]->[(1, 8, 7, 7)], Dropout [(1, 8, 7, 7)]->[(1, 8, 7, 7)])": 8, "(Dropout [(1, 8, 7, 7)]->[(1, 8, 7, 7)], matmul [(1, 8, 7, 7), (1, 8, 7, 64)]->[(1, 8, 7, 64)])": 8, "(matmul [(1, 8, 7, 7), (1, 8, 7, 64)]->[(1, 8, 7, 64)], permute [(1, 8, 7, 64)]->[(1, 7, 8, 64)])": 8, "(permute [(1, 8, 7, 64)]->[(1, 7, 8, 64)], contiguous [(1, 7, 8, 64)]->[(1, 7, 8, 64)])": 8, "(contiguous [(1, 7, 8, 64)]->[(1, 7, 8, 64)], view [(1, 7, 8, 64)]->[(1, 7, 512)])": 8, "(view [(1, 7, 8, 64)]->[(1, 7, 512)], Linear [(1, 7, 512)]->[(1, 7, 512)])": 8, "(Linear [(1, 7, 512)]->[(1, 7, 512)], Dropout [(1, 7, 512)]->[(1, 7, 512)])": 8, "(Dropout [(1, 7, 512)]->[(1, 7, 512)], add [(1, 7, 512), (1, 7, 512)]->[(1, 7, 512)])": 16, "(add [(1, 7, 512), (1, 7, 512)]->[(1, 7, 512)], LayerNorm [(1, 7, 512)]->[(1, 7, 512)])": 16, "(LayerNorm [(1, 7, 512)]->[(1, 7, 512)], Linear [(1, 7, 512)]->[(1, 7, 2048)])": 8, "(LayerNorm [(1, 7, 512)]->[(1, 7, 512)], add [(1, 7, 512), (1, 7, 512)]->[(1, 7, 512)])": 15, "(Linear [(1, 7, 512)]->[(1, 7, 2048)], GELUActivation [(1, 7, 2048)]->[(1, 7, 2048)])": 8, "(GELUActivation [(1, 7, 2048)]->[(1, 7, 2048)], Linear [(1, 7, 2048)]->[(1, 7, 512)])": 8, "(Linear [(1, 7, 2048)]->[(1, 7, 512)], Dropout [(1, 7, 512)]->[(1, 7, 512)])": 8, "(LayerNorm [(1, 7, 512)]->[(1, 7, 512)], Linear [(1, 7, 512)]->[(1, 7, 512)])": 21, "(Linear [(1, 7, 512)]->[(1, 7, 512)], view [(1, 7, 512)]->[(1, 7, 8, 64)])": 21, "(view [(1, 7, 512)]->[(1, 7, 8, 64)], permute [(1, 7, 8, 64)]->[(1, 8, 7, 64)])": 21, "(permute [(1, 7, 8, 64)]->[(1, 8, 7, 64)], matmul [(1, 8, 7, 7), (1, 8, 7, 64)]->[(1, 8, 7, 64)])": 7, "(permute [(1, 7, 8, 64)]->[(1, 8, 7, 64)], transpose [(1, 8, 7, 64)]->[(1, 8, 64, 7)])": 7, "(transpose [(1, 8, 7, 64)]->[(1, 8, 64, 7)], matmul [(1, 8, 7, 64), (1, 8, 64, 7)]->[(1, 8, 7, 7)])": 7, "(matmul [(1, 8, 7, 64), (1, 8, 64, 7)]->[(1, 8, 7, 7)], div [(1, 8, 7, 7)]->[(1, 8, 7, 7)])": 7, "(div [(1, 8, 7, 7)]->[(1, 8, 7, 7)], add [(1, 8, 7, 7), (1, 1, 1, 7)]->[(1, 8, 7, 7)])": 7, "(permute [(1, 7, 8, 64)]->[(1, 8, 7, 64)], matmul [(1, 8, 7, 64), (1, 8, 64, 7)]->[(1, 8, 7, 7)])": 7, "(LayerNorm [(1, 7, 512)]->[(1, 7, 512)], __getitem__ [(1, 7, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 7, 512)]->[(1, 7, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1}, "asafaya/bert-mini-arabic": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 4, 7, 7), (1, 1, 1, 7)]->[(1, 4, 7, 7)])": 4, "(add [(1, 4, 7, 7), (1, 1, 1, 7)]->[(1, 4, 7, 7)], softmax [(1, 4, 7, 7)]->[(1, 4, 7, 7)])": 4, "(softmax [(1, 4, 7, 7)]->[(1, 4, 7, 7)], Dropout [(1, 4, 7, 7)]->[(1, 4, 7, 7)])": 4, "(Dropout [(1, 4, 7, 7)]->[(1, 4, 7, 7)], matmul [(1, 4, 7, 7), (1, 4, 7, 64)]->[(1, 4, 7, 64)])": 4, "(matmul [(1, 4, 7, 7), (1, 4, 7, 64)]->[(1, 4, 7, 64)], permute [(1, 4, 7, 64)]->[(1, 7, 4, 64)])": 4, "(permute [(1, 4, 7, 64)]->[(1, 7, 4, 64)], contiguous [(1, 7, 4, 64)]->[(1, 7, 4, 64)])": 4, "(contiguous [(1, 7, 4, 64)]->[(1, 7, 4, 64)], view [(1, 7, 4, 64)]->[(1, 7, 256)])": 4, "(view [(1, 7, 4, 64)]->[(1, 7, 256)], Linear [(1, 7, 256)]->[(1, 7, 256)])": 4, "(Linear [(1, 7, 256)]->[(1, 7, 256)], Dropout [(1, 7, 256)]->[(1, 7, 256)])": 4, "(Dropout [(1, 7, 256)]->[(1, 7, 256)], add [(1, 7, 256), (1, 7, 256)]->[(1, 7, 256)])": 8, "(add [(1, 7, 256), (1, 7, 256)]->[(1, 7, 256)], LayerNorm [(1, 7, 256)]->[(1, 7, 256)])": 8, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], Linear [(1, 7, 256)]->[(1, 7, 1024)])": 4, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], add [(1, 7, 256), (1, 7, 256)]->[(1, 7, 256)])": 7, "(Linear [(1, 7, 256)]->[(1, 7, 1024)], GELUActivation [(1, 7, 1024)]->[(1, 7, 1024)])": 4, "(GELUActivation [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 256)])": 4, "(Linear [(1, 7, 1024)]->[(1, 7, 256)], Dropout [(1, 7, 256)]->[(1, 7, 256)])": 4, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], Linear [(1, 7, 256)]->[(1, 7, 256)])": 9, "(Linear [(1, 7, 256)]->[(1, 7, 256)], view [(1, 7, 256)]->[(1, 7, 4, 64)])": 9, "(view [(1, 7, 256)]->[(1, 7, 4, 64)], permute [(1, 7, 4, 64)]->[(1, 4, 7, 64)])": 9, "(permute [(1, 7, 4, 64)]->[(1, 4, 7, 64)], matmul [(1, 4, 7, 64), (1, 4, 64, 7)]->[(1, 4, 7, 7)])": 3, "(matmul [(1, 4, 7, 64), (1, 4, 64, 7)]->[(1, 4, 7, 7)], div [(1, 4, 7, 7)]->[(1, 4, 7, 7)])": 3, "(div [(1, 4, 7, 7)]->[(1, 4, 7, 7)], add [(1, 4, 7, 7), (1, 1, 1, 7)]->[(1, 4, 7, 7)])": 3, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], __getitem__ [(1, 7, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(permute [(1, 7, 4, 64)]->[(1, 4, 7, 64)], matmul [(1, 4, 7, 7), (1, 4, 7, 64)]->[(1, 4, 7, 64)])": 3, "(permute [(1, 7, 4, 64)]->[(1, 4, 7, 64)], transpose [(1, 4, 7, 64)]->[(1, 4, 64, 7)])": 3, "(transpose [(1, 4, 7, 64)]->[(1, 4, 64, 7)], matmul [(1, 4, 7, 64), (1, 4, 64, 7)]->[(1, 4, 7, 7)])": 3}, "aubmindlab/bert-base-arabert": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "aubmindlab/bert-base-arabertv01": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "aubmindlab/bert-base-arabertv02-twitter": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "aubmindlab/bert-base-arabertv02": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "aubmindlab/bert-base-arabertv2": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "aubmindlab/bert-large-arabertv02-twitter": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "aubmindlab/bert-large-arabertv02": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "aubmindlab/bert-large-arabertv2": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "biu-nlp/alephbert-base": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "cahya/bert-base-indonesian-1.5G": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "cahya/bert-base-indonesian-522M": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "dbmdz/bert-base-italian-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "dbmdz/bert-base-italian-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "dbmdz/bert-base-italian-xxl-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "dbmdz/bert-base-italian-xxl-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "hiroshi-matsuda-rit/bert-base-japanese-basic-char-v2": {"([INPUT], __getitem__ [(1, 11)]->[(1, 1, 1, 11)])": 1, "(__getitem__ [(1, 11)]->[(1, 1, 1, 11)], to [(1, 1, 1, 11)]->[(1, 1, 1, 11)])": 1, "(to [(1, 1, 1, 11)]->[(1, 1, 1, 11)], __rsub__ [(1, 1, 1, 11)]->[(1, 1, 1, 11)])": 1, "(__rsub__ [(1, 1, 1, 11)]->[(1, 1, 1, 11)], mul [(1, 1, 1, 11)]->[(1, 1, 1, 11)])": 1, "(mul [(1, 1, 1, 11)]->[(1, 1, 1, 11)], add [(1, 12, 11, 11), (1, 1, 1, 11)]->[(1, 12, 11, 11)])": 12, "(add [(1, 12, 11, 11), (1, 1, 1, 11)]->[(1, 12, 11, 11)], softmax [(1, 12, 11, 11)]->[(1, 12, 11, 11)])": 12, "(softmax [(1, 12, 11, 11)]->[(1, 12, 11, 11)], Dropout [(1, 12, 11, 11)]->[(1, 12, 11, 11)])": 12, "(Dropout [(1, 12, 11, 11)]->[(1, 12, 11, 11)], matmul [(1, 12, 11, 11), (1, 12, 11, 64)]->[(1, 12, 11, 64)])": 12, "(matmul [(1, 12, 11, 11), (1, 12, 11, 64)]->[(1, 12, 11, 64)], permute [(1, 12, 11, 64)]->[(1, 11, 12, 64)])": 12, "(permute [(1, 12, 11, 64)]->[(1, 11, 12, 64)], contiguous [(1, 11, 12, 64)]->[(1, 11, 12, 64)])": 12, "(contiguous [(1, 11, 12, 64)]->[(1, 11, 12, 64)], view [(1, 11, 12, 64)]->[(1, 11, 768)])": 12, "(view [(1, 11, 12, 64)]->[(1, 11, 768)], Linear [(1, 11, 768)]->[(1, 11, 768)])": 12, "(Linear [(1, 11, 768)]->[(1, 11, 768)], Dropout [(1, 11, 768)]->[(1, 11, 768)])": 12, "(Dropout [(1, 11, 768)]->[(1, 11, 768)], add [(1, 11, 768), (1, 11, 768)]->[(1, 11, 768)])": 24, "(add [(1, 11, 768), (1, 11, 768)]->[(1, 11, 768)], LayerNorm [(1, 11, 768)]->[(1, 11, 768)])": 24, "(LayerNorm [(1, 11, 768)]->[(1, 11, 768)], Linear [(1, 11, 768)]->[(1, 11, 3072)])": 12, "(LayerNorm [(1, 11, 768)]->[(1, 11, 768)], add [(1, 11, 768), (1, 11, 768)]->[(1, 11, 768)])": 23, "(Linear [(1, 11, 768)]->[(1, 11, 3072)], GELUActivation [(1, 11, 3072)]->[(1, 11, 3072)])": 12, "(GELUActivation [(1, 11, 3072)]->[(1, 11, 3072)], Linear [(1, 11, 3072)]->[(1, 11, 768)])": 12, "(Linear [(1, 11, 3072)]->[(1, 11, 768)], Dropout [(1, 11, 768)]->[(1, 11, 768)])": 12, "(LayerNorm [(1, 11, 768)]->[(1, 11, 768)], Linear [(1, 11, 768)]->[(1, 11, 768)])": 33, "(Linear [(1, 11, 768)]->[(1, 11, 768)], view [(1, 11, 768)]->[(1, 11, 12, 64)])": 33, "(view [(1, 11, 768)]->[(1, 11, 12, 64)], permute [(1, 11, 12, 64)]->[(1, 12, 11, 64)])": 33, "(permute [(1, 11, 12, 64)]->[(1, 12, 11, 64)], matmul [(1, 12, 11, 11), (1, 12, 11, 64)]->[(1, 12, 11, 64)])": 11, "(LayerNorm [(1, 11, 768)]->[(1, 11, 768)], __getitem__ [(1, 11, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 11, 768)]->[(1, 11, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 11, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 11, 12, 64)]->[(1, 12, 11, 64)], matmul [(1, 12, 11, 64), (1, 12, 64, 11)]->[(1, 12, 11, 11)])": 11, "(matmul [(1, 12, 11, 64), (1, 12, 64, 11)]->[(1, 12, 11, 11)], div [(1, 12, 11, 11)]->[(1, 12, 11, 11)])": 11, "(div [(1, 12, 11, 11)]->[(1, 12, 11, 11)], add [(1, 12, 11, 11), (1, 1, 1, 11)]->[(1, 12, 11, 11)])": 11, "(permute [(1, 11, 12, 64)]->[(1, 12, 11, 64)], transpose [(1, 12, 11, 64)]->[(1, 12, 64, 11)])": 11, "(transpose [(1, 12, 11, 64)]->[(1, 12, 64, 11)], matmul [(1, 12, 11, 64), (1, 12, 64, 11)]->[(1, 12, 11, 11)])": 11}, "onlplab/alephbert-base": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "sagorsarker/bangla-bert-base": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "w11wo/javanese-bert-small": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "mmaguero/gn-bert-base-cased": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "mmaguero/gn-bert-large-cased": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "mmaguero/gn-bert-tiny-cased": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 4, 7, 7), (1, 1, 1, 7)]->[(1, 4, 7, 7)])": 2, "(add [(1, 4, 7, 7), (1, 1, 1, 7)]->[(1, 4, 7, 7)], softmax [(1, 4, 7, 7)]->[(1, 4, 7, 7)])": 2, "(softmax [(1, 4, 7, 7)]->[(1, 4, 7, 7)], Dropout [(1, 4, 7, 7)]->[(1, 4, 7, 7)])": 2, "(Dropout [(1, 4, 7, 7)]->[(1, 4, 7, 7)], matmul [(1, 4, 7, 7), (1, 4, 7, 64)]->[(1, 4, 7, 64)])": 2, "(matmul [(1, 4, 7, 7), (1, 4, 7, 64)]->[(1, 4, 7, 64)], permute [(1, 4, 7, 64)]->[(1, 7, 4, 64)])": 2, "(permute [(1, 4, 7, 64)]->[(1, 7, 4, 64)], contiguous [(1, 7, 4, 64)]->[(1, 7, 4, 64)])": 2, "(contiguous [(1, 7, 4, 64)]->[(1, 7, 4, 64)], view [(1, 7, 4, 64)]->[(1, 7, 256)])": 2, "(view [(1, 7, 4, 64)]->[(1, 7, 256)], Linear [(1, 7, 256)]->[(1, 7, 256)])": 2, "(Linear [(1, 7, 256)]->[(1, 7, 256)], Dropout [(1, 7, 256)]->[(1, 7, 256)])": 2, "(Dropout [(1, 7, 256)]->[(1, 7, 256)], add [(1, 7, 256), (1, 7, 256)]->[(1, 7, 256)])": 4, "(add [(1, 7, 256), (1, 7, 256)]->[(1, 7, 256)], LayerNorm [(1, 7, 256)]->[(1, 7, 256)])": 4, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], Linear [(1, 7, 256)]->[(1, 7, 768)])": 2, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], add [(1, 7, 256), (1, 7, 256)]->[(1, 7, 256)])": 3, "(Linear [(1, 7, 256)]->[(1, 7, 768)], GELUActivation [(1, 7, 768)]->[(1, 7, 768)])": 2, "(GELUActivation [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 256)])": 2, "(Linear [(1, 7, 768)]->[(1, 7, 256)], Dropout [(1, 7, 256)]->[(1, 7, 256)])": 2, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], Linear [(1, 7, 256)]->[(1, 7, 256)])": 3, "(Linear [(1, 7, 256)]->[(1, 7, 256)], view [(1, 7, 256)]->[(1, 7, 4, 64)])": 3, "(view [(1, 7, 256)]->[(1, 7, 4, 64)], permute [(1, 7, 4, 64)]->[(1, 4, 7, 64)])": 3, "(permute [(1, 7, 4, 64)]->[(1, 4, 7, 64)], matmul [(1, 4, 7, 7), (1, 4, 7, 64)]->[(1, 4, 7, 64)])": 1, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], __getitem__ [(1, 7, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 7, 256)]->[(1, 7, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(permute [(1, 7, 4, 64)]->[(1, 4, 7, 64)], transpose [(1, 4, 7, 64)]->[(1, 4, 64, 7)])": 1, "(transpose [(1, 4, 7, 64)]->[(1, 4, 64, 7)], matmul [(1, 4, 7, 64), (1, 4, 64, 7)]->[(1, 4, 7, 7)])": 1, "(matmul [(1, 4, 7, 64), (1, 4, 64, 7)]->[(1, 4, 7, 7)], div [(1, 4, 7, 7)]->[(1, 4, 7, 7)])": 1, "(div [(1, 4, 7, 7)]->[(1, 4, 7, 7)], add [(1, 4, 7, 7), (1, 1, 1, 7)]->[(1, 4, 7, 7)])": 1, "(permute [(1, 7, 4, 64)]->[(1, 4, 7, 64)], matmul [(1, 4, 7, 64), (1, 4, 64, 7)]->[(1, 4, 7, 7)])": 1}, "mmaguero/gn-bert-small-cased": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 6, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 6, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 6, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 6, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 6, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 6, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 6, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 6, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 6, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 12, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 6, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 15, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 15, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 15, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 5, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 5, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 5, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 5, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 6, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 6, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 6, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 5, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 5}, "mmaguero/beto-gn-base-cased": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "mmaguero/multilingual-bert-gn-base-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "rmihaylov/bert-base-theseus-bg": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 6, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 6, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 6, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 6, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 6, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 6, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 6, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 6, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 6, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 12, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 6, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 11, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 6, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 6, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 6, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 15, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 15, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 15, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 5, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 5, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 5, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 5, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 5, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 5}, "rmihaylov/bert-base-bg": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "StanfordAIMI/RadBERT": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "conan1024hao/cjkbert-small": {"([INPUT], __getitem__ [(1, 11)]->[(1, 1, 1, 11)])": 1, "(__getitem__ [(1, 11)]->[(1, 1, 1, 11)], to [(1, 1, 1, 11)]->[(1, 1, 1, 11)])": 1, "(to [(1, 1, 1, 11)]->[(1, 1, 1, 11)], __rsub__ [(1, 1, 1, 11)]->[(1, 1, 1, 11)])": 1, "(__rsub__ [(1, 1, 1, 11)]->[(1, 1, 1, 11)], mul [(1, 1, 1, 11)]->[(1, 1, 1, 11)])": 1, "(mul [(1, 1, 1, 11)]->[(1, 1, 1, 11)], add [(1, 8, 11, 11), (1, 1, 1, 11)]->[(1, 8, 11, 11)])": 4, "(add [(1, 8, 11, 11), (1, 1, 1, 11)]->[(1, 8, 11, 11)], softmax [(1, 8, 11, 11)]->[(1, 8, 11, 11)])": 4, "(softmax [(1, 8, 11, 11)]->[(1, 8, 11, 11)], Dropout [(1, 8, 11, 11)]->[(1, 8, 11, 11)])": 4, "(Dropout [(1, 8, 11, 11)]->[(1, 8, 11, 11)], matmul [(1, 8, 11, 11), (1, 8, 11, 64)]->[(1, 8, 11, 64)])": 4, "(matmul [(1, 8, 11, 11), (1, 8, 11, 64)]->[(1, 8, 11, 64)], permute [(1, 8, 11, 64)]->[(1, 11, 8, 64)])": 4, "(permute [(1, 8, 11, 64)]->[(1, 11, 8, 64)], contiguous [(1, 11, 8, 64)]->[(1, 11, 8, 64)])": 4, "(contiguous [(1, 11, 8, 64)]->[(1, 11, 8, 64)], view [(1, 11, 8, 64)]->[(1, 11, 512)])": 4, "(view [(1, 11, 8, 64)]->[(1, 11, 512)], Linear [(1, 11, 512)]->[(1, 11, 512)])": 4, "(Linear [(1, 11, 512)]->[(1, 11, 512)], Dropout [(1, 11, 512)]->[(1, 11, 512)])": 4, "(Dropout [(1, 11, 512)]->[(1, 11, 512)], add [(1, 11, 512), (1, 11, 512)]->[(1, 11, 512)])": 8, "(add [(1, 11, 512), (1, 11, 512)]->[(1, 11, 512)], LayerNorm [(1, 11, 512)]->[(1, 11, 512)])": 8, "(LayerNorm [(1, 11, 512)]->[(1, 11, 512)], Linear [(1, 11, 512)]->[(1, 11, 3072)])": 4, "(LayerNorm [(1, 11, 512)]->[(1, 11, 512)], add [(1, 11, 512), (1, 11, 512)]->[(1, 11, 512)])": 7, "(LayerNorm [(1, 11, 512)]->[(1, 11, 512)], Linear [(1, 11, 512)]->[(1, 11, 512)])": 9, "(Linear [(1, 11, 512)]->[(1, 11, 512)], view [(1, 11, 512)]->[(1, 11, 8, 64)])": 9, "(view [(1, 11, 512)]->[(1, 11, 8, 64)], permute [(1, 11, 8, 64)]->[(1, 8, 11, 64)])": 9, "(permute [(1, 11, 8, 64)]->[(1, 8, 11, 64)], matmul [(1, 8, 11, 64), (1, 8, 64, 11)]->[(1, 8, 11, 11)])": 3, "(matmul [(1, 8, 11, 64), (1, 8, 64, 11)]->[(1, 8, 11, 11)], div [(1, 8, 11, 11)]->[(1, 8, 11, 11)])": 3, "(div [(1, 8, 11, 11)]->[(1, 8, 11, 11)], add [(1, 8, 11, 11), (1, 1, 1, 11)]->[(1, 8, 11, 11)])": 3, "(permute [(1, 11, 8, 64)]->[(1, 8, 11, 64)], matmul [(1, 8, 11, 11), (1, 8, 11, 64)]->[(1, 8, 11, 64)])": 3, "(LayerNorm [(1, 11, 512)]->[(1, 11, 512)], __getitem__ [(1, 11, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 11, 512)]->[(1, 11, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 11, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 11, 512)]->[(1, 11, 3072)], GELUActivation [(1, 11, 3072)]->[(1, 11, 3072)])": 4, "(GELUActivation [(1, 11, 3072)]->[(1, 11, 3072)], Linear [(1, 11, 3072)]->[(1, 11, 512)])": 4, "(Linear [(1, 11, 3072)]->[(1, 11, 512)], Dropout [(1, 11, 512)]->[(1, 11, 512)])": 4, "(permute [(1, 11, 8, 64)]->[(1, 8, 11, 64)], transpose [(1, 8, 11, 64)]->[(1, 8, 64, 11)])": 3, "(transpose [(1, 8, 11, 64)]->[(1, 8, 64, 11)], matmul [(1, 8, 11, 64), (1, 8, 64, 11)]->[(1, 8, 11, 11)])": 3}, "StevenLimcorn/MelayuBERT": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "anas-awadalla/bert-medium-pretrained-on-squad": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 8, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 8, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 8, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 8, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 8, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 8, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 8, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 8, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 8, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 16, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 16, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 15, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 8, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 8, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 21, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 21, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 21, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 7, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 7, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 7, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 7, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 7, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 7}, "anas-awadalla/bert-small-pretrained-on-squad": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 4, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 4, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 4, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 4, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 4, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 8, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 7, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 4, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 9, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 9, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 3, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 3, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3}, "Chrispfield/bert-base-uncased-issues-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "ariesutiono/finetuned-test-1": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "ariesutiono/scibert-lm-const-finetuned-20": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "ariesutiono/scibert-lm-v1-finetuned-20": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "ariesutiono/scibert-lm-v2-finetuned-20": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "Ebtihal/AraBertMo_base_V1": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V2": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V3": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V4": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V5": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V6": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V7": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V8": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V9": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Ebtihal/AraBertMo_base_V10": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6), (1, 1, 1, 6)]->[(1, 1, 6, 6)], to [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(to [(1, 1, 6, 6)]->[(1, 1, 6, 6)], __rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(__rsub__ [(1, 1, 6, 6)]->[(1, 1, 6, 6)], mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)])": 1, "(mul [(1, 1, 6, 6)]->[(1, 1, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], [OUTPUT])": 22, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 6, 6)]->[(1, 12, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Narshion/bert-base-multilingual-cased-urgency": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "markverschuren/bert-base-dutch-cased-finetuned-mark": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "vppvgit/BiblItBERT-1": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "vppvgit/Finetuned": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "xxr/bert-base-uncased-issues-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "xxr/bert-base-uncased-multi-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "xxr/bert-base-chinese-complaint-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "Kowsher/bangla-bert": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "lewtun/MiniLM-L12-H384-uncased-finetuned-imdb": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)], permute [(1, 12, 4, 32)]->[(1, 4, 12, 32)])": 12, "(permute [(1, 12, 4, 32)]->[(1, 4, 12, 32)], contiguous [(1, 4, 12, 32)]->[(1, 4, 12, 32)])": 12, "(contiguous [(1, 4, 12, 32)]->[(1, 4, 12, 32)], view [(1, 4, 12, 32)]->[(1, 4, 384)])": 12, "(view [(1, 4, 12, 32)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 384)])": 12, "(Linear [(1, 4, 384)]->[(1, 4, 384)], Dropout [(1, 4, 384)]->[(1, 4, 384)])": 12, "(Dropout [(1, 4, 384)]->[(1, 4, 384)], add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)])": 24, "(add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)], LayerNorm [(1, 4, 384)]->[(1, 4, 384)])": 24, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 1536)])": 12, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)])": 23, "(Linear [(1, 4, 384)]->[(1, 4, 1536)], GELUActivation [(1, 4, 1536)]->[(1, 4, 1536)])": 12, "(GELUActivation [(1, 4, 1536)]->[(1, 4, 1536)], Linear [(1, 4, 1536)]->[(1, 4, 384)])": 12, "(Linear [(1, 4, 1536)]->[(1, 4, 384)], Dropout [(1, 4, 384)]->[(1, 4, 384)])": 12, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 384)])": 33, "(Linear [(1, 4, 384)]->[(1, 4, 384)], view [(1, 4, 384)]->[(1, 4, 12, 32)])": 33, "(view [(1, 4, 384)]->[(1, 4, 12, 32)], permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)])": 33, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)])": 11, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], __getitem__ [(1, 4, 384)]->[(1, 384)])": 1, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 384)]->[(1, 384)], Linear [(1, 384)]->[(1, 384)])": 1, "(Linear [(1, 384)]->[(1, 384)], Tanh [(1, 384)]->[(1, 384)])": 1, "(Tanh [(1, 384)]->[(1, 384)], [OUTPUT])": 1, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], transpose [(1, 12, 4, 32)]->[(1, 12, 32, 4)])": 11, "(transpose [(1, 12, 4, 32)]->[(1, 12, 32, 4)], matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)])": 11}, "IIC/dpr-spanish-passage_encoder-squades-base": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "IIC/dpr-spanish-question_encoder-squades-base": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "IIC/dpr-spanish-passage_encoder-allqa-base": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "IIC/dpr-spanish-question_encoder-allqa-base": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "MutazYoune/Ara_DialectBERT": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "saghar/TinyBERT_General_6L_768D-finetuned-wikitext103": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 6, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 6, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], [OUTPUT])": 6, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 6, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 6, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 6, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 6, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 6, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 12, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 6, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 6, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 6, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 6, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 15, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 6, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 15, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 15, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 5, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 5, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 5, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 5, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 5, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 5}, "saghar/TinyBERT_L-4_H-312_v2-finetuned-wikitext103": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 4, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 4, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 4, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 26)]->[(1, 12, 4, 26)])": 4, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], [OUTPUT])": 4, "(matmul [(1, 12, 4, 4), (1, 12, 4, 26)]->[(1, 12, 4, 26)], permute [(1, 12, 4, 26)]->[(1, 4, 12, 26)])": 4, "(permute [(1, 12, 4, 26)]->[(1, 4, 12, 26)], contiguous [(1, 4, 12, 26)]->[(1, 4, 12, 26)])": 4, "(contiguous [(1, 4, 12, 26)]->[(1, 4, 12, 26)], view [(1, 4, 12, 26)]->[(1, 4, 312)])": 4, "(view [(1, 4, 12, 26)]->[(1, 4, 312)], Linear [(1, 4, 312)]->[(1, 4, 312)])": 4, "(Linear [(1, 4, 312)]->[(1, 4, 312)], Dropout [(1, 4, 312)]->[(1, 4, 312)])": 4, "(Dropout [(1, 4, 312)]->[(1, 4, 312)], add [(1, 4, 312), (1, 4, 312)]->[(1, 4, 312)])": 8, "(add [(1, 4, 312), (1, 4, 312)]->[(1, 4, 312)], LayerNorm [(1, 4, 312)]->[(1, 4, 312)])": 8, "(LayerNorm [(1, 4, 312)]->[(1, 4, 312)], Linear [(1, 4, 312)]->[(1, 4, 1200)])": 4, "(LayerNorm [(1, 4, 312)]->[(1, 4, 312)], add [(1, 4, 312), (1, 4, 312)]->[(1, 4, 312)])": 7, "(LayerNorm [(1, 4, 312)]->[(1, 4, 312)], __getitem__ [(1, 4, 312)]->[(1, 312)])": 1, "(LayerNorm [(1, 4, 312)]->[(1, 4, 312)], [OUTPUT])": 4, "(__getitem__ [(1, 4, 312)]->[(1, 312)], Linear [(1, 312)]->[(1, 312)])": 1, "(Linear [(1, 312)]->[(1, 312)], Tanh [(1, 312)]->[(1, 312)])": 1, "(Tanh [(1, 312)]->[(1, 312)], [OUTPUT])": 1, "(Linear [(1, 4, 312)]->[(1, 4, 1200)], GELUActivation [(1, 4, 1200)]->[(1, 4, 1200)])": 4, "(GELUActivation [(1, 4, 1200)]->[(1, 4, 1200)], Linear [(1, 4, 1200)]->[(1, 4, 312)])": 4, "(Linear [(1, 4, 1200)]->[(1, 4, 312)], Dropout [(1, 4, 312)]->[(1, 4, 312)])": 4, "(LayerNorm [(1, 4, 312)]->[(1, 4, 312)], Linear [(1, 4, 312)]->[(1, 4, 312)])": 9, "(Linear [(1, 4, 312)]->[(1, 4, 312)], view [(1, 4, 312)]->[(1, 4, 12, 26)])": 9, "(view [(1, 4, 312)]->[(1, 4, 12, 26)], permute [(1, 4, 12, 26)]->[(1, 12, 4, 26)])": 9, "(permute [(1, 4, 12, 26)]->[(1, 12, 4, 26)], matmul [(1, 12, 4, 4), (1, 12, 4, 26)]->[(1, 12, 4, 26)])": 3, "(permute [(1, 4, 12, 26)]->[(1, 12, 4, 26)], transpose [(1, 12, 4, 26)]->[(1, 12, 26, 4)])": 3, "(transpose [(1, 12, 4, 26)]->[(1, 12, 26, 4)], matmul [(1, 12, 4, 26), (1, 12, 26, 4)]->[(1, 12, 4, 4)])": 3, "(matmul [(1, 12, 4, 26), (1, 12, 26, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 3, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 3, "(permute [(1, 4, 12, 26)]->[(1, 12, 4, 26)], matmul [(1, 12, 4, 26), (1, 12, 26, 4)]->[(1, 12, 4, 4)])": 3}, "saghar/xtremedistil-l6-h384-uncased-finetuned-wikitext103": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 6, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)])": 6, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], [OUTPUT])": 6, "(matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)], permute [(1, 12, 4, 32)]->[(1, 4, 12, 32)])": 6, "(permute [(1, 12, 4, 32)]->[(1, 4, 12, 32)], contiguous [(1, 4, 12, 32)]->[(1, 4, 12, 32)])": 6, "(contiguous [(1, 4, 12, 32)]->[(1, 4, 12, 32)], view [(1, 4, 12, 32)]->[(1, 4, 384)])": 6, "(view [(1, 4, 12, 32)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 384)])": 6, "(Linear [(1, 4, 384)]->[(1, 4, 384)], Dropout [(1, 4, 384)]->[(1, 4, 384)])": 6, "(Dropout [(1, 4, 384)]->[(1, 4, 384)], add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)])": 12, "(add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)], LayerNorm [(1, 4, 384)]->[(1, 4, 384)])": 12, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 1536)])": 6, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)])": 11, "(Linear [(1, 4, 384)]->[(1, 4, 1536)], GELUActivation [(1, 4, 1536)]->[(1, 4, 1536)])": 6, "(GELUActivation [(1, 4, 1536)]->[(1, 4, 1536)], Linear [(1, 4, 1536)]->[(1, 4, 384)])": 6, "(Linear [(1, 4, 1536)]->[(1, 4, 384)], Dropout [(1, 4, 384)]->[(1, 4, 384)])": 6, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 384)])": 15, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], [OUTPUT])": 6, "(Linear [(1, 4, 384)]->[(1, 4, 384)], view [(1, 4, 384)]->[(1, 4, 12, 32)])": 15, "(view [(1, 4, 384)]->[(1, 4, 12, 32)], permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)])": 15, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)])": 5, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], __getitem__ [(1, 4, 384)]->[(1, 384)])": 1, "(__getitem__ [(1, 4, 384)]->[(1, 384)], Linear [(1, 384)]->[(1, 384)])": 1, "(Linear [(1, 384)]->[(1, 384)], Tanh [(1, 384)]->[(1, 384)])": 1, "(Tanh [(1, 384)]->[(1, 384)], [OUTPUT])": 1, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)])": 5, "(matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 5, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 5, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], transpose [(1, 12, 4, 32)]->[(1, 12, 32, 4)])": 5, "(transpose [(1, 12, 4, 32)]->[(1, 12, 32, 4)], matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)])": 5}, "saghar/xtremedistil-l12-h384-uncased-finetuned-wikitext103": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], [OUTPUT])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)], permute [(1, 12, 4, 32)]->[(1, 4, 12, 32)])": 12, "(permute [(1, 12, 4, 32)]->[(1, 4, 12, 32)], contiguous [(1, 4, 12, 32)]->[(1, 4, 12, 32)])": 12, "(contiguous [(1, 4, 12, 32)]->[(1, 4, 12, 32)], view [(1, 4, 12, 32)]->[(1, 4, 384)])": 12, "(view [(1, 4, 12, 32)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 384)])": 12, "(Linear [(1, 4, 384)]->[(1, 4, 384)], Dropout [(1, 4, 384)]->[(1, 4, 384)])": 12, "(Dropout [(1, 4, 384)]->[(1, 4, 384)], add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)])": 24, "(add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)], LayerNorm [(1, 4, 384)]->[(1, 4, 384)])": 24, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 1536)])": 12, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], add [(1, 4, 384), (1, 4, 384)]->[(1, 4, 384)])": 23, "(Linear [(1, 4, 384)]->[(1, 4, 1536)], GELUActivation [(1, 4, 1536)]->[(1, 4, 1536)])": 12, "(GELUActivation [(1, 4, 1536)]->[(1, 4, 1536)], Linear [(1, 4, 1536)]->[(1, 4, 384)])": 12, "(Linear [(1, 4, 1536)]->[(1, 4, 384)], Dropout [(1, 4, 384)]->[(1, 4, 384)])": 12, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], Linear [(1, 4, 384)]->[(1, 4, 384)])": 33, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], [OUTPUT])": 12, "(Linear [(1, 4, 384)]->[(1, 4, 384)], view [(1, 4, 384)]->[(1, 4, 12, 32)])": 33, "(view [(1, 4, 384)]->[(1, 4, 12, 32)], permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)])": 33, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], matmul [(1, 12, 4, 4), (1, 12, 4, 32)]->[(1, 12, 4, 32)])": 11, "(LayerNorm [(1, 4, 384)]->[(1, 4, 384)], __getitem__ [(1, 4, 384)]->[(1, 384)])": 1, "(__getitem__ [(1, 4, 384)]->[(1, 384)], Linear [(1, 384)]->[(1, 384)])": 1, "(Linear [(1, 384)]->[(1, 384)], Tanh [(1, 384)]->[(1, 384)])": 1, "(Tanh [(1, 384)]->[(1, 384)], [OUTPUT])": 1, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(permute [(1, 4, 12, 32)]->[(1, 12, 4, 32)], transpose [(1, 12, 4, 32)]->[(1, 12, 32, 4)])": 11, "(transpose [(1, 12, 4, 32)]->[(1, 12, 32, 4)], matmul [(1, 12, 4, 32), (1, 12, 32, 4)]->[(1, 12, 4, 4)])": 11}, "SauravMaheshkar/clr-finetuned-bert-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "SauravMaheshkar/clr-finetuned-bert-large-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 24, "(add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)], softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 24, "(softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)], Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 24, "(Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 24, "(matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)], permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)])": 24, "(permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)], contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)])": 24, "(contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)], view [(1, 4, 16, 64)]->[(1, 4, 1024)])": 24, "(view [(1, 4, 16, 64)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(Dropout [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 48, "(add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)], LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)])": 48, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 4096)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 47, "(Linear [(1, 4, 1024)]->[(1, 4, 4096)], GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)])": 24, "(GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)], Linear [(1, 4, 4096)]->[(1, 4, 1024)])": 24, "(Linear [(1, 4, 4096)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 69, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], view [(1, 4, 1024)]->[(1, 4, 16, 64)])": 69, "(view [(1, 4, 1024)]->[(1, 4, 16, 64)], permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)])": 69, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 23, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], __getitem__ [(1, 4, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)])": 23, "(transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 23, "(matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)], div [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 23, "(div [(1, 16, 4, 4)]->[(1, 16, 4, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 23, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 23}, "SauravMaheshkar/clr-pretrained-bert-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "Tsubasaz/clinical-pubmed-bert-base-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "Tsubasaz/clinical-pubmed-bert-base-512": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "alexanderfalk/danbert-small-cased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 6, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 6, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 6, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 6, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 6, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 6, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 6, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 12, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 6, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 15, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 15, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 15, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 5, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 5, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 5, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 5, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 6, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 6, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 6, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 5, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 5, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "pablocosta/bertabaporu-base-uncased": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 8, 6, 6), (1, 1, 1, 6)]->[(1, 8, 6, 6)])": 12, "(add [(1, 8, 6, 6), (1, 1, 1, 6)]->[(1, 8, 6, 6)], softmax [(1, 8, 6, 6)]->[(1, 8, 6, 6)])": 12, "(softmax [(1, 8, 6, 6)]->[(1, 8, 6, 6)], Dropout [(1, 8, 6, 6)]->[(1, 8, 6, 6)])": 12, "(Dropout [(1, 8, 6, 6)]->[(1, 8, 6, 6)], matmul [(1, 8, 6, 6), (1, 8, 6, 96)]->[(1, 8, 6, 96)])": 12, "(matmul [(1, 8, 6, 6), (1, 8, 6, 96)]->[(1, 8, 6, 96)], permute [(1, 8, 6, 96)]->[(1, 6, 8, 96)])": 12, "(permute [(1, 8, 6, 96)]->[(1, 6, 8, 96)], contiguous [(1, 6, 8, 96)]->[(1, 6, 8, 96)])": 12, "(contiguous [(1, 6, 8, 96)]->[(1, 6, 8, 96)], view [(1, 6, 8, 96)]->[(1, 6, 768)])": 12, "(view [(1, 6, 8, 96)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 8, 96)])": 33, "(view [(1, 6, 768)]->[(1, 6, 8, 96)], permute [(1, 6, 8, 96)]->[(1, 8, 6, 96)])": 33, "(permute [(1, 6, 8, 96)]->[(1, 8, 6, 96)], matmul [(1, 8, 6, 6), (1, 8, 6, 96)]->[(1, 8, 6, 96)])": 11, "(permute [(1, 6, 8, 96)]->[(1, 8, 6, 96)], transpose [(1, 8, 6, 96)]->[(1, 8, 96, 6)])": 11, "(transpose [(1, 8, 6, 96)]->[(1, 8, 96, 6)], matmul [(1, 8, 6, 96), (1, 8, 96, 6)]->[(1, 8, 6, 6)])": 11, "(matmul [(1, 8, 6, 96), (1, 8, 96, 6)]->[(1, 8, 6, 6)], div [(1, 8, 6, 6)]->[(1, 8, 6, 6)])": 11, "(div [(1, 8, 6, 6)]->[(1, 8, 6, 6)], add [(1, 8, 6, 6), (1, 1, 1, 6)]->[(1, 8, 6, 6)])": 11, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 6, 8, 96)]->[(1, 8, 6, 96)], matmul [(1, 8, 6, 96), (1, 8, 96, 6)]->[(1, 8, 6, 6)])": 11}, "pablocosta/bertabaporu-large-uncased": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 16, 6, 6), (1, 1, 1, 6)]->[(1, 16, 6, 6)])": 24, "(add [(1, 16, 6, 6), (1, 1, 1, 6)]->[(1, 16, 6, 6)], softmax [(1, 16, 6, 6)]->[(1, 16, 6, 6)])": 24, "(softmax [(1, 16, 6, 6)]->[(1, 16, 6, 6)], Dropout [(1, 16, 6, 6)]->[(1, 16, 6, 6)])": 24, "(Dropout [(1, 16, 6, 6)]->[(1, 16, 6, 6)], matmul [(1, 16, 6, 6), (1, 16, 6, 64)]->[(1, 16, 6, 64)])": 24, "(matmul [(1, 16, 6, 6), (1, 16, 6, 64)]->[(1, 16, 6, 64)], permute [(1, 16, 6, 64)]->[(1, 6, 16, 64)])": 24, "(permute [(1, 16, 6, 64)]->[(1, 6, 16, 64)], contiguous [(1, 6, 16, 64)]->[(1, 6, 16, 64)])": 24, "(contiguous [(1, 6, 16, 64)]->[(1, 6, 16, 64)], view [(1, 6, 16, 64)]->[(1, 6, 1024)])": 24, "(view [(1, 6, 16, 64)]->[(1, 6, 1024)], Linear [(1, 6, 1024)]->[(1, 6, 1024)])": 24, "(Linear [(1, 6, 1024)]->[(1, 6, 1024)], Dropout [(1, 6, 1024)]->[(1, 6, 1024)])": 24, "(Dropout [(1, 6, 1024)]->[(1, 6, 1024)], add [(1, 6, 1024), (1, 6, 1024)]->[(1, 6, 1024)])": 48, "(add [(1, 6, 1024), (1, 6, 1024)]->[(1, 6, 1024)], LayerNorm [(1, 6, 1024)]->[(1, 6, 1024)])": 48, "(LayerNorm [(1, 6, 1024)]->[(1, 6, 1024)], Linear [(1, 6, 1024)]->[(1, 6, 4096)])": 24, "(LayerNorm [(1, 6, 1024)]->[(1, 6, 1024)], add [(1, 6, 1024), (1, 6, 1024)]->[(1, 6, 1024)])": 47, "(Linear [(1, 6, 1024)]->[(1, 6, 4096)], GELUActivation [(1, 6, 4096)]->[(1, 6, 4096)])": 24, "(GELUActivation [(1, 6, 4096)]->[(1, 6, 4096)], Linear [(1, 6, 4096)]->[(1, 6, 1024)])": 24, "(Linear [(1, 6, 4096)]->[(1, 6, 1024)], Dropout [(1, 6, 1024)]->[(1, 6, 1024)])": 24, "(LayerNorm [(1, 6, 1024)]->[(1, 6, 1024)], Linear [(1, 6, 1024)]->[(1, 6, 1024)])": 69, "(Linear [(1, 6, 1024)]->[(1, 6, 1024)], view [(1, 6, 1024)]->[(1, 6, 16, 64)])": 69, "(view [(1, 6, 1024)]->[(1, 6, 16, 64)], permute [(1, 6, 16, 64)]->[(1, 16, 6, 64)])": 69, "(permute [(1, 6, 16, 64)]->[(1, 16, 6, 64)], transpose [(1, 16, 6, 64)]->[(1, 16, 64, 6)])": 23, "(transpose [(1, 16, 6, 64)]->[(1, 16, 64, 6)], matmul [(1, 16, 6, 64), (1, 16, 64, 6)]->[(1, 16, 6, 6)])": 23, "(matmul [(1, 16, 6, 64), (1, 16, 64, 6)]->[(1, 16, 6, 6)], div [(1, 16, 6, 6)]->[(1, 16, 6, 6)])": 23, "(div [(1, 16, 6, 6)]->[(1, 16, 6, 6)], add [(1, 16, 6, 6), (1, 1, 1, 6)]->[(1, 16, 6, 6)])": 23, "(permute [(1, 6, 16, 64)]->[(1, 16, 6, 64)], matmul [(1, 16, 6, 6), (1, 16, 6, 64)]->[(1, 16, 6, 64)])": 23, "(LayerNorm [(1, 6, 1024)]->[(1, 6, 1024)], __getitem__ [(1, 6, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 6, 1024)]->[(1, 6, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 6, 16, 64)]->[(1, 16, 6, 64)], matmul [(1, 16, 6, 64), (1, 16, 64, 6)]->[(1, 16, 6, 6)])": 23}, "bashar-talafha/multi-dialect-bert-base-arabic": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "batterydata/batterybert-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "batterydata/batterybert-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "batterydata/batteryscibert-cased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "batterydata/batteryscibert-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "batterydata/batteryonlybert-cased": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "batterydata/batteryonlybert-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "qarib/bert-base-qarib": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "qarib/bert-base-qarib60_1790k": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "qarib/bert-base-qarib60_1970k": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "qarib/bert-base-qarib60_860k": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "cook/cicero-similis": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 6, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 6, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 6, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 6, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 6, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 6, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 6, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 6, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 6, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 12, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 6, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 6, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 6, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 6, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 15, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 15, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 15, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 5, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 5, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 5, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 5, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 5, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 5}, "coppercitylabs/uzbert-base-uncased": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "damlab/HIV_BERT": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 30, "(add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)], softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 30, "(softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)], Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 30, "(Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 30, "(matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)], permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)])": 30, "(permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)], contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)])": 30, "(contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)], view [(1, 4, 16, 64)]->[(1, 4, 1024)])": 30, "(view [(1, 4, 16, 64)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 30, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 30, "(Dropout [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 60, "(add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)], LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)])": 60, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 4096)])": 30, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 59, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 87, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], view [(1, 4, 1024)]->[(1, 4, 16, 64)])": 87, "(view [(1, 4, 1024)]->[(1, 4, 16, 64)], permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)])": 87, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)])": 29, "(transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 29, "(matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)], div [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 29, "(div [(1, 16, 4, 4)]->[(1, 16, 4, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 29, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 29, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 29, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], __getitem__ [(1, 4, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 4, 1024)]->[(1, 4, 4096)], GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)])": 30, "(GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)], Linear [(1, 4, 4096)]->[(1, 4, 1024)])": 30, "(Linear [(1, 4, 4096)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 30}, "baikal-nlp/dbert": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "michelecafagna26/vinvl-base-image-captioning": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "flax-community/bert-base-uncased-swahili": {"([INPUT], __getitem__ [(1, 3)]->[(1, 1, 1, 3)])": 1, "(__getitem__ [(1, 3)]->[(1, 1, 1, 3)], to [(1, 1, 1, 3)]->[(1, 1, 1, 3)])": 1, "(to [(1, 1, 1, 3)]->[(1, 1, 1, 3)], __rsub__ [(1, 1, 1, 3)]->[(1, 1, 1, 3)])": 1, "(__rsub__ [(1, 1, 1, 3)]->[(1, 1, 1, 3)], mul [(1, 1, 1, 3)]->[(1, 1, 1, 3)])": 1, "(mul [(1, 1, 1, 3)]->[(1, 1, 1, 3)], add [(1, 12, 3, 3), (1, 1, 1, 3)]->[(1, 12, 3, 3)])": 12, "(add [(1, 12, 3, 3), (1, 1, 1, 3)]->[(1, 12, 3, 3)], softmax [(1, 12, 3, 3)]->[(1, 12, 3, 3)])": 12, "(softmax [(1, 12, 3, 3)]->[(1, 12, 3, 3)], Dropout [(1, 12, 3, 3)]->[(1, 12, 3, 3)])": 12, "(Dropout [(1, 12, 3, 3)]->[(1, 12, 3, 3)], matmul [(1, 12, 3, 3), (1, 12, 3, 64)]->[(1, 12, 3, 64)])": 12, "(matmul [(1, 12, 3, 3), (1, 12, 3, 64)]->[(1, 12, 3, 64)], permute [(1, 12, 3, 64)]->[(1, 3, 12, 64)])": 12, "(permute [(1, 12, 3, 64)]->[(1, 3, 12, 64)], contiguous [(1, 3, 12, 64)]->[(1, 3, 12, 64)])": 12, "(contiguous [(1, 3, 12, 64)]->[(1, 3, 12, 64)], view [(1, 3, 12, 64)]->[(1, 3, 768)])": 12, "(view [(1, 3, 12, 64)]->[(1, 3, 768)], Linear [(1, 3, 768)]->[(1, 3, 768)])": 12, "(Linear [(1, 3, 768)]->[(1, 3, 768)], Dropout [(1, 3, 768)]->[(1, 3, 768)])": 12, "(Dropout [(1, 3, 768)]->[(1, 3, 768)], add [(1, 3, 768), (1, 3, 768)]->[(1, 3, 768)])": 24, "(add [(1, 3, 768), (1, 3, 768)]->[(1, 3, 768)], LayerNorm [(1, 3, 768)]->[(1, 3, 768)])": 24, "(LayerNorm [(1, 3, 768)]->[(1, 3, 768)], Linear [(1, 3, 768)]->[(1, 3, 3072)])": 12, "(LayerNorm [(1, 3, 768)]->[(1, 3, 768)], add [(1, 3, 768), (1, 3, 768)]->[(1, 3, 768)])": 23, "(Linear [(1, 3, 768)]->[(1, 3, 3072)], GELUActivation [(1, 3, 3072)]->[(1, 3, 3072)])": 12, "(GELUActivation [(1, 3, 3072)]->[(1, 3, 3072)], Linear [(1, 3, 3072)]->[(1, 3, 768)])": 12, "(Linear [(1, 3, 3072)]->[(1, 3, 768)], Dropout [(1, 3, 768)]->[(1, 3, 768)])": 12, "(LayerNorm [(1, 3, 768)]->[(1, 3, 768)], Linear [(1, 3, 768)]->[(1, 3, 768)])": 33, "(Linear [(1, 3, 768)]->[(1, 3, 768)], view [(1, 3, 768)]->[(1, 3, 12, 64)])": 33, "(view [(1, 3, 768)]->[(1, 3, 12, 64)], permute [(1, 3, 12, 64)]->[(1, 12, 3, 64)])": 33, "(permute [(1, 3, 12, 64)]->[(1, 12, 3, 64)], matmul [(1, 12, 3, 3), (1, 12, 3, 64)]->[(1, 12, 3, 64)])": 11, "(permute [(1, 3, 12, 64)]->[(1, 12, 3, 64)], matmul [(1, 12, 3, 64), (1, 12, 64, 3)]->[(1, 12, 3, 3)])": 11, "(matmul [(1, 12, 3, 64), (1, 12, 64, 3)]->[(1, 12, 3, 3)], div [(1, 12, 3, 3)]->[(1, 12, 3, 3)])": 11, "(div [(1, 12, 3, 3)]->[(1, 12, 3, 3)], add [(1, 12, 3, 3), (1, 1, 1, 3)]->[(1, 12, 3, 3)])": 11, "(permute [(1, 3, 12, 64)]->[(1, 12, 3, 64)], transpose [(1, 12, 3, 64)]->[(1, 12, 64, 3)])": 11, "(transpose [(1, 12, 3, 64)]->[(1, 12, 64, 3)], matmul [(1, 12, 3, 64), (1, 12, 64, 3)]->[(1, 12, 3, 3)])": 11, "(LayerNorm [(1, 3, 768)]->[(1, 3, 768)], __getitem__ [(1, 3, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 3, 768)]->[(1, 3, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 3, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "indolem/indobert-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "indolem/indobertweet-base-uncased": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "jackaduma/SecBERT": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 6, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 6, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 6, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 6, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 6, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 6, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 6, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 12, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 6, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 15, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 15, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 15, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 5, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 5, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 5, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 5, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 6, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 6, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 6, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 5, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 5, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "johngiorgi/declutr-sci-base": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "l3cube-pune/marathi-bert": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "l3cube-pune/marathi-bert-v2": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "l3cube-pune/marathi-tweets-bert": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "l3cube-pune/marathi-tweets-bert-hateful": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "l3cube-pune/mr-random-twt-1m": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "l3cube-pune/marathi-bert-scratch": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "l3cube-pune/mr-least-ht-1m": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "l3cube-pune/marathi-tweets-bert-scratch": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "neuralmind/bert-base-portuguese-cased": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "neuralmind/bert-large-portuguese-cased": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "nlp4good/psych-search": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "pierreguillou/bert-base-cased-pt-lenerbr": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "pierreguillou/bert-large-cased-pt-lenerbr": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "pritamdeka/PubMedBert-abstract-cord19-v2": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "pritamdeka/PubMedBert-abstract-cord19": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "pritamdeka/PubMedBert-fulltext-cord19": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "naver/splade-cocondenser-selfdistil": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "naver/splade-cocondenser-ensembledistil": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "naver/efficient-splade-VI-BT-large-query": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 2, "(add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)], softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 2, "(softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)], Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 2, "(Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 2, "(matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)], permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)])": 2, "(permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)], contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)])": 2, "(contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)], view [(1, 4, 2, 64)]->[(1, 4, 128)])": 2, "(view [(1, 4, 2, 64)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 2, "(Linear [(1, 4, 128)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 2, "(Dropout [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 4, "(add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)], LayerNorm [(1, 4, 128)]->[(1, 4, 128)])": 4, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 512)])": 2, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 3, "(Linear [(1, 4, 128)]->[(1, 4, 512)], GELUActivation [(1, 4, 512)]->[(1, 4, 512)])": 2, "(GELUActivation [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 128)])": 2, "(Linear [(1, 4, 512)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 2, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 3, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], __getitem__ [(1, 4, 128)]->[(1, 128)])": 1, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 128)]->[(1, 128)], Linear [(1, 128)]->[(1, 128)])": 1, "(Linear [(1, 128)]->[(1, 128)], Tanh [(1, 128)]->[(1, 128)])": 1, "(Tanh [(1, 128)]->[(1, 128)], [OUTPUT])": 1, "(Linear [(1, 4, 128)]->[(1, 4, 128)], view [(1, 4, 128)]->[(1, 4, 2, 64)])": 3, "(view [(1, 4, 128)]->[(1, 4, 2, 64)], permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)])": 3, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 1, "(matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)], div [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 1, "(div [(1, 2, 4, 4)]->[(1, 2, 4, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 1, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 1, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)])": 1, "(transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 1}, "smeylan/childes-bert": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "tuhailong/chinese-roberta-wwm-ext": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "uer/chinese_roberta_L-10_H-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 10, "(add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)], softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 10, "(softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)], Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 10, "(Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 10, "(matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)], permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)])": 10, "(permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)], contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)])": 10, "(contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)], view [(1, 4, 2, 64)]->[(1, 4, 128)])": 10, "(view [(1, 4, 2, 64)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 10, "(Linear [(1, 4, 128)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 10, "(Dropout [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 20, "(add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)], LayerNorm [(1, 4, 128)]->[(1, 4, 128)])": 20, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 512)])": 10, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 19, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 27, "(Linear [(1, 4, 128)]->[(1, 4, 128)], view [(1, 4, 128)]->[(1, 4, 2, 64)])": 27, "(view [(1, 4, 128)]->[(1, 4, 2, 64)], permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)])": 27, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)])": 9, "(transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 9, "(matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)], div [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 9, "(div [(1, 2, 4, 4)]->[(1, 2, 4, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 9, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 9, "(Linear [(1, 4, 128)]->[(1, 4, 512)], GELUActivation [(1, 4, 512)]->[(1, 4, 512)])": 10, "(GELUActivation [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 128)])": 10, "(Linear [(1, 4, 512)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 10, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 9, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], __getitem__ [(1, 4, 128)]->[(1, 128)])": 1, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 128)]->[(1, 128)], Linear [(1, 128)]->[(1, 128)])": 1, "(Linear [(1, 128)]->[(1, 128)], Tanh [(1, 128)]->[(1, 128)])": 1, "(Tanh [(1, 128)]->[(1, 128)], [OUTPUT])": 1}, "uer/chinese_roberta_L-10_H-256": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 10, "(add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)], softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 10, "(softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)], Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 10, "(Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 10, "(matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 10, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 10, "(contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)], view [(1, 4, 4, 64)]->[(1, 4, 256)])": 10, "(view [(1, 4, 4, 64)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 10, "(Linear [(1, 4, 256)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 10, "(Dropout [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 20, "(add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)], LayerNorm [(1, 4, 256)]->[(1, 4, 256)])": 20, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 1024)])": 10, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 19, "(Linear [(1, 4, 256)]->[(1, 4, 1024)], GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)])": 10, "(GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 256)])": 10, "(Linear [(1, 4, 1024)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 10, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 27, "(Linear [(1, 4, 256)]->[(1, 4, 256)], view [(1, 4, 256)]->[(1, 4, 4, 64)])": 27, "(view [(1, 4, 256)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 27, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 9, "(matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)], div [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 9, "(div [(1, 4, 4, 4)]->[(1, 4, 4, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 9, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], __getitem__ [(1, 4, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)])": 9, "(transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 9, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 9}, "uer/chinese_roberta_L-10_H-512": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 10, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 10, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 10, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 10, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 10, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 10, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 10, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 10, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 10, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 20, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 20, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 10, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 19, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 10, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 10, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 10, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 27, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 27, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 27, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 9, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 9, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 9, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 9}, "uer/chinese_roberta_L-10_H-768": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 10, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 10, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 10, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 10, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 10, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 10, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 10, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 10, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 10, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 20, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 20, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 10, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 19, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 27, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 27, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 27, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 9, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 9, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 9, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 9, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 10, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 10, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 10, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 9, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 9, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "uer/chinese_roberta_L-12_H-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 12, "(add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)], softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 12, "(softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)], Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 12, "(Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 12, "(matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)], permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)])": 12, "(permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)], contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)])": 12, "(contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)], view [(1, 4, 2, 64)]->[(1, 4, 128)])": 12, "(view [(1, 4, 2, 64)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 12, "(Linear [(1, 4, 128)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 12, "(Dropout [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 24, "(add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)], LayerNorm [(1, 4, 128)]->[(1, 4, 128)])": 24, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 512)])": 12, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 23, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 33, "(Linear [(1, 4, 128)]->[(1, 4, 128)], view [(1, 4, 128)]->[(1, 4, 2, 64)])": 33, "(view [(1, 4, 128)]->[(1, 4, 2, 64)], permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)])": 33, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)])": 11, "(transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 11, "(matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)], div [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 11, "(div [(1, 2, 4, 4)]->[(1, 2, 4, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 11, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 11, "(Linear [(1, 4, 128)]->[(1, 4, 512)], GELUActivation [(1, 4, 512)]->[(1, 4, 512)])": 12, "(GELUActivation [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 128)])": 12, "(Linear [(1, 4, 512)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 12, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 11, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], __getitem__ [(1, 4, 128)]->[(1, 128)])": 1, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 128)]->[(1, 128)], Linear [(1, 128)]->[(1, 128)])": 1, "(Linear [(1, 128)]->[(1, 128)], Tanh [(1, 128)]->[(1, 128)])": 1, "(Tanh [(1, 128)]->[(1, 128)], [OUTPUT])": 1}, "uer/chinese_roberta_L-12_H-256": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 12, "(add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)], softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 12, "(softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)], Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 12, "(Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 12, "(matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 12, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 12, "(contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)], view [(1, 4, 4, 64)]->[(1, 4, 256)])": 12, "(view [(1, 4, 4, 64)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 12, "(Linear [(1, 4, 256)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 12, "(Dropout [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 24, "(add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)], LayerNorm [(1, 4, 256)]->[(1, 4, 256)])": 24, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 1024)])": 12, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 23, "(Linear [(1, 4, 256)]->[(1, 4, 1024)], GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)])": 12, "(GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 256)])": 12, "(Linear [(1, 4, 1024)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 12, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 33, "(Linear [(1, 4, 256)]->[(1, 4, 256)], view [(1, 4, 256)]->[(1, 4, 4, 64)])": 33, "(view [(1, 4, 256)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 33, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 11, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 11, "(matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)], div [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 11, "(div [(1, 4, 4, 4)]->[(1, 4, 4, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 11, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], __getitem__ [(1, 4, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)])": 11, "(transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 11}, "uer/chinese_roberta_L-12_H-512": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 12, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 12, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 12, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 12, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 12, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 12, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 12, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 12, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 12, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 24, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 24, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 12, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 23, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 12, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 12, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 12, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 33, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 33, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 33, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 11, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 11, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 11, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 11, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 11, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 11}, "uer/chinese_roberta_L-12_H-768": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "uer/chinese_roberta_L-2_H-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 2, "(add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)], softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 2, "(softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)], Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 2, "(Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 2, "(matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)], permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)])": 2, "(permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)], contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)])": 2, "(contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)], view [(1, 4, 2, 64)]->[(1, 4, 128)])": 2, "(view [(1, 4, 2, 64)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 2, "(Linear [(1, 4, 128)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 2, "(Dropout [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 4, "(add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)], LayerNorm [(1, 4, 128)]->[(1, 4, 128)])": 4, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 512)])": 2, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 3, "(Linear [(1, 4, 128)]->[(1, 4, 512)], GELUActivation [(1, 4, 512)]->[(1, 4, 512)])": 2, "(GELUActivation [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 128)])": 2, "(Linear [(1, 4, 512)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 2, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 3, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], __getitem__ [(1, 4, 128)]->[(1, 128)])": 1, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 128)]->[(1, 128)], Linear [(1, 128)]->[(1, 128)])": 1, "(Linear [(1, 128)]->[(1, 128)], Tanh [(1, 128)]->[(1, 128)])": 1, "(Tanh [(1, 128)]->[(1, 128)], [OUTPUT])": 1, "(Linear [(1, 4, 128)]->[(1, 4, 128)], view [(1, 4, 128)]->[(1, 4, 2, 64)])": 3, "(view [(1, 4, 128)]->[(1, 4, 2, 64)], permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)])": 3, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 1, "(matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)], div [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 1, "(div [(1, 2, 4, 4)]->[(1, 2, 4, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 1, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 1, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)])": 1, "(transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 1}, "uer/chinese_roberta_L-2_H-256": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 2, "(add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)], softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 2, "(softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)], Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 2, "(Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 2, "(matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 2, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 2, "(contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)], view [(1, 4, 4, 64)]->[(1, 4, 256)])": 2, "(view [(1, 4, 4, 64)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 2, "(Linear [(1, 4, 256)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 2, "(Dropout [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 4, "(add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)], LayerNorm [(1, 4, 256)]->[(1, 4, 256)])": 4, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 1024)])": 2, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 3, "(Linear [(1, 4, 256)]->[(1, 4, 1024)], GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)])": 2, "(GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 256)])": 2, "(Linear [(1, 4, 1024)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 2, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], __getitem__ [(1, 4, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 3, "(Linear [(1, 4, 256)]->[(1, 4, 256)], view [(1, 4, 256)]->[(1, 4, 4, 64)])": 3, "(view [(1, 4, 256)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 3, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)])": 1, "(transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 1, "(matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)], div [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 1, "(div [(1, 4, 4, 4)]->[(1, 4, 4, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 1, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 1, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 1}, "uer/chinese_roberta_L-2_H-512": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 2, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 2, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 2, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 2, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 2, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 2, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 2, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 2, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 2, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 4, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 2, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 3, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 2, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 2, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 2, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 3, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 3, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 1, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 1, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 1, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 1, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 1, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 1}, "uer/chinese_roberta_L-2_H-768": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 2, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 2, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 2, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 2, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 2, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 2, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 2, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 2, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 2, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 4, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 4, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 2, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 3, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 2, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 2, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 2, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 3, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 3, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 3, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 1, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 1, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 1, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 1, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 1}, "uer/chinese_roberta_L-4_H-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 4, "(add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)], softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 4, "(softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)], Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 4, "(Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 4, "(matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)], permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)])": 4, "(permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)], contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)])": 4, "(contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)], view [(1, 4, 2, 64)]->[(1, 4, 128)])": 4, "(view [(1, 4, 2, 64)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 4, "(Linear [(1, 4, 128)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 4, "(Dropout [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 8, "(add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)], LayerNorm [(1, 4, 128)]->[(1, 4, 128)])": 8, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 7, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 9, "(Linear [(1, 4, 128)]->[(1, 4, 128)], view [(1, 4, 128)]->[(1, 4, 2, 64)])": 9, "(view [(1, 4, 128)]->[(1, 4, 2, 64)], permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)])": 9, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 3, "(matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)], div [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 3, "(div [(1, 2, 4, 4)]->[(1, 2, 4, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 3, "(Linear [(1, 4, 128)]->[(1, 4, 512)], GELUActivation [(1, 4, 512)]->[(1, 4, 512)])": 4, "(GELUActivation [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 128)])": 4, "(Linear [(1, 4, 512)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 4, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], __getitem__ [(1, 4, 128)]->[(1, 128)])": 1, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 128)]->[(1, 128)], Linear [(1, 128)]->[(1, 128)])": 1, "(Linear [(1, 128)]->[(1, 128)], Tanh [(1, 128)]->[(1, 128)])": 1, "(Tanh [(1, 128)]->[(1, 128)], [OUTPUT])": 1, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 3, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)])": 3, "(transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 3}, "uer/chinese_roberta_L-4_H-256": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 4, "(add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)], softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 4, "(softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)], Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 4, "(Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 4, "(matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 4, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 4, "(contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)], view [(1, 4, 4, 64)]->[(1, 4, 256)])": 4, "(view [(1, 4, 4, 64)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 4, "(Linear [(1, 4, 256)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 4, "(Dropout [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 8, "(add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)], LayerNorm [(1, 4, 256)]->[(1, 4, 256)])": 8, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 1024)])": 4, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 7, "(Linear [(1, 4, 256)]->[(1, 4, 1024)], GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)])": 4, "(GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 256)])": 4, "(Linear [(1, 4, 1024)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 4, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 9, "(Linear [(1, 4, 256)]->[(1, 4, 256)], view [(1, 4, 256)]->[(1, 4, 4, 64)])": 9, "(view [(1, 4, 256)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 9, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 3, "(matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)], div [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 3, "(div [(1, 4, 4, 4)]->[(1, 4, 4, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 3, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], __getitem__ [(1, 4, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)])": 3, "(transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 3, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 3}, "uer/chinese_roberta_L-4_H-512": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 4, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 4, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 4, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 4, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 4, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 8, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 7, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 4, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 9, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 9, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 3, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 3, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3}, "uer/chinese_roberta_L-4_H-768": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 4, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 4, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 4, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 4, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 4, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 4, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 4, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 4, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 4, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 8, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 8, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 4, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 7, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 9, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 9, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 9, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 3, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 4, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 4, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 4, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 3, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 3, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 3, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 3, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 3, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "uer/chinese_roberta_L-6_H-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 6, "(add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)], softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 6, "(softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)], Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 6, "(Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 6, "(matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)], permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)])": 6, "(permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)], contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)])": 6, "(contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)], view [(1, 4, 2, 64)]->[(1, 4, 128)])": 6, "(view [(1, 4, 2, 64)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 6, "(Linear [(1, 4, 128)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 6, "(Dropout [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 12, "(add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)], LayerNorm [(1, 4, 128)]->[(1, 4, 128)])": 12, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 512)])": 6, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 11, "(Linear [(1, 4, 128)]->[(1, 4, 512)], GELUActivation [(1, 4, 512)]->[(1, 4, 512)])": 6, "(GELUActivation [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 128)])": 6, "(Linear [(1, 4, 512)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 6, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 15, "(Linear [(1, 4, 128)]->[(1, 4, 128)], view [(1, 4, 128)]->[(1, 4, 2, 64)])": 15, "(view [(1, 4, 128)]->[(1, 4, 2, 64)], permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)])": 15, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 5, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 5, "(matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)], div [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 5, "(div [(1, 2, 4, 4)]->[(1, 2, 4, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 5, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], __getitem__ [(1, 4, 128)]->[(1, 128)])": 1, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 128)]->[(1, 128)], Linear [(1, 128)]->[(1, 128)])": 1, "(Linear [(1, 128)]->[(1, 128)], Tanh [(1, 128)]->[(1, 128)])": 1, "(Tanh [(1, 128)]->[(1, 128)], [OUTPUT])": 1, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)])": 5, "(transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 5}, "uer/chinese_roberta_L-6_H-256": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 6, "(add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)], softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 6, "(softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)], Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 6, "(Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 6, "(matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 6, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 6, "(contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)], view [(1, 4, 4, 64)]->[(1, 4, 256)])": 6, "(view [(1, 4, 4, 64)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 6, "(Linear [(1, 4, 256)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 6, "(Dropout [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 12, "(add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)], LayerNorm [(1, 4, 256)]->[(1, 4, 256)])": 12, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 1024)])": 6, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 11, "(Linear [(1, 4, 256)]->[(1, 4, 1024)], GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)])": 6, "(GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 256)])": 6, "(Linear [(1, 4, 1024)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 6, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 15, "(Linear [(1, 4, 256)]->[(1, 4, 256)], view [(1, 4, 256)]->[(1, 4, 4, 64)])": 15, "(view [(1, 4, 256)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 15, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 5, "(matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)], div [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 5, "(div [(1, 4, 4, 4)]->[(1, 4, 4, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 5, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], __getitem__ [(1, 4, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)])": 5, "(transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 5, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 5}, "uer/chinese_roberta_L-6_H-512": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 6, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 6, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 6, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 6, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 6, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 6, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 6, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 6, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 6, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 12, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 12, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 6, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 11, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 6, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 6, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 6, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 15, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 15, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 15, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 5, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 5, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 5, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 5, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 5, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 5}, "uer/chinese_roberta_L-6_H-768": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 6, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 6, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 6, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 6, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 6, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 6, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 6, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 6, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 12, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 6, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 15, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 15, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 15, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 5, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 5, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 5, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 5, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 6, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 6, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 6, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 5, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 5, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "uer/chinese_roberta_L-8_H-128": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 8, "(add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)], softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 8, "(softmax [(1, 2, 4, 4)]->[(1, 2, 4, 4)], Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 8, "(Dropout [(1, 2, 4, 4)]->[(1, 2, 4, 4)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 8, "(matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)], permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)])": 8, "(permute [(1, 2, 4, 64)]->[(1, 4, 2, 64)], contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)])": 8, "(contiguous [(1, 4, 2, 64)]->[(1, 4, 2, 64)], view [(1, 4, 2, 64)]->[(1, 4, 128)])": 8, "(view [(1, 4, 2, 64)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 8, "(Linear [(1, 4, 128)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 8, "(Dropout [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 16, "(add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)], LayerNorm [(1, 4, 128)]->[(1, 4, 128)])": 16, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], add [(1, 4, 128), (1, 4, 128)]->[(1, 4, 128)])": 15, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], Linear [(1, 4, 128)]->[(1, 4, 128)])": 21, "(Linear [(1, 4, 128)]->[(1, 4, 128)], view [(1, 4, 128)]->[(1, 4, 2, 64)])": 21, "(view [(1, 4, 128)]->[(1, 4, 2, 64)], permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)])": 21, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)])": 7, "(transpose [(1, 2, 4, 64)]->[(1, 2, 64, 4)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 7, "(matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)], div [(1, 2, 4, 4)]->[(1, 2, 4, 4)])": 7, "(div [(1, 2, 4, 4)]->[(1, 2, 4, 4)], add [(1, 2, 4, 4), (1, 1, 1, 4)]->[(1, 2, 4, 4)])": 7, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 4), (1, 2, 4, 64)]->[(1, 2, 4, 64)])": 7, "(Linear [(1, 4, 128)]->[(1, 4, 512)], GELUActivation [(1, 4, 512)]->[(1, 4, 512)])": 8, "(GELUActivation [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 128)])": 8, "(Linear [(1, 4, 512)]->[(1, 4, 128)], Dropout [(1, 4, 128)]->[(1, 4, 128)])": 8, "(permute [(1, 4, 2, 64)]->[(1, 2, 4, 64)], matmul [(1, 2, 4, 64), (1, 2, 64, 4)]->[(1, 2, 4, 4)])": 7, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], __getitem__ [(1, 4, 128)]->[(1, 128)])": 1, "(LayerNorm [(1, 4, 128)]->[(1, 4, 128)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 128)]->[(1, 128)], Linear [(1, 128)]->[(1, 128)])": 1, "(Linear [(1, 128)]->[(1, 128)], Tanh [(1, 128)]->[(1, 128)])": 1, "(Tanh [(1, 128)]->[(1, 128)], [OUTPUT])": 1}, "uer/chinese_roberta_L-8_H-256": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 8, "(add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)], softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 8, "(softmax [(1, 4, 4, 4)]->[(1, 4, 4, 4)], Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 8, "(Dropout [(1, 4, 4, 4)]->[(1, 4, 4, 4)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 8, "(matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 8, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 8, "(contiguous [(1, 4, 4, 64)]->[(1, 4, 4, 64)], view [(1, 4, 4, 64)]->[(1, 4, 256)])": 8, "(view [(1, 4, 4, 64)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 8, "(Linear [(1, 4, 256)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 8, "(Dropout [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 16, "(add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)], LayerNorm [(1, 4, 256)]->[(1, 4, 256)])": 16, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 1024)])": 8, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], add [(1, 4, 256), (1, 4, 256)]->[(1, 4, 256)])": 15, "(Linear [(1, 4, 256)]->[(1, 4, 1024)], GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)])": 8, "(GELUActivation [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 256)])": 8, "(Linear [(1, 4, 1024)]->[(1, 4, 256)], Dropout [(1, 4, 256)]->[(1, 4, 256)])": 8, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], Linear [(1, 4, 256)]->[(1, 4, 256)])": 21, "(Linear [(1, 4, 256)]->[(1, 4, 256)], view [(1, 4, 256)]->[(1, 4, 4, 64)])": 21, "(view [(1, 4, 256)]->[(1, 4, 4, 64)], permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)])": 21, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 7, "(matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)], div [(1, 4, 4, 4)]->[(1, 4, 4, 4)])": 7, "(div [(1, 4, 4, 4)]->[(1, 4, 4, 4)], add [(1, 4, 4, 4), (1, 1, 1, 4)]->[(1, 4, 4, 4)])": 7, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], __getitem__ [(1, 4, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 4, 256)]->[(1, 4, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)])": 7, "(transpose [(1, 4, 4, 64)]->[(1, 4, 64, 4)], matmul [(1, 4, 4, 64), (1, 4, 64, 4)]->[(1, 4, 4, 4)])": 7, "(permute [(1, 4, 4, 64)]->[(1, 4, 4, 64)], matmul [(1, 4, 4, 4), (1, 4, 4, 64)]->[(1, 4, 4, 64)])": 7}, "uer/chinese_roberta_L-8_H-512": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 8, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 8, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 8, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 8, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 8, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 8, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 8, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 8, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 8, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 16, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 16, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 15, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 8, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 8, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 21, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 21, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 21, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 7, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 7, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 7, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 7, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 7, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 7}, "uer/chinese_roberta_L-8_H-768": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 8, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 8, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 8, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 8, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 8, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 8, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 8, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 8, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 8, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 16, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 16, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 8, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 15, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 21, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 21, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 21, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 7, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 7, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 7, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 7, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 8, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 8, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 8, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 7, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 7, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "uer/roberta-tiny-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 2, 5, 5), (1, 1, 1, 5)]->[(1, 2, 5, 5)])": 2, "(add [(1, 2, 5, 5), (1, 1, 1, 5)]->[(1, 2, 5, 5)], softmax [(1, 2, 5, 5)]->[(1, 2, 5, 5)])": 2, "(softmax [(1, 2, 5, 5)]->[(1, 2, 5, 5)], Dropout [(1, 2, 5, 5)]->[(1, 2, 5, 5)])": 2, "(Dropout [(1, 2, 5, 5)]->[(1, 2, 5, 5)], matmul [(1, 2, 5, 5), (1, 2, 5, 64)]->[(1, 2, 5, 64)])": 2, "(matmul [(1, 2, 5, 5), (1, 2, 5, 64)]->[(1, 2, 5, 64)], permute [(1, 2, 5, 64)]->[(1, 5, 2, 64)])": 2, "(permute [(1, 2, 5, 64)]->[(1, 5, 2, 64)], contiguous [(1, 5, 2, 64)]->[(1, 5, 2, 64)])": 2, "(contiguous [(1, 5, 2, 64)]->[(1, 5, 2, 64)], view [(1, 5, 2, 64)]->[(1, 5, 128)])": 2, "(view [(1, 5, 2, 64)]->[(1, 5, 128)], Linear [(1, 5, 128)]->[(1, 5, 128)])": 2, "(Linear [(1, 5, 128)]->[(1, 5, 128)], Dropout [(1, 5, 128)]->[(1, 5, 128)])": 2, "(Dropout [(1, 5, 128)]->[(1, 5, 128)], add [(1, 5, 128), (1, 5, 128)]->[(1, 5, 128)])": 4, "(add [(1, 5, 128), (1, 5, 128)]->[(1, 5, 128)], LayerNorm [(1, 5, 128)]->[(1, 5, 128)])": 4, "(LayerNorm [(1, 5, 128)]->[(1, 5, 128)], Linear [(1, 5, 128)]->[(1, 5, 512)])": 2, "(LayerNorm [(1, 5, 128)]->[(1, 5, 128)], add [(1, 5, 128), (1, 5, 128)]->[(1, 5, 128)])": 3, "(LayerNorm [(1, 5, 128)]->[(1, 5, 128)], __getitem__ [(1, 5, 128)]->[(1, 128)])": 1, "(LayerNorm [(1, 5, 128)]->[(1, 5, 128)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 128)]->[(1, 128)], Linear [(1, 128)]->[(1, 128)])": 1, "(Linear [(1, 128)]->[(1, 128)], Tanh [(1, 128)]->[(1, 128)])": 1, "(Tanh [(1, 128)]->[(1, 128)], [OUTPUT])": 1, "(Linear [(1, 5, 128)]->[(1, 5, 512)], GELUActivation [(1, 5, 512)]->[(1, 5, 512)])": 2, "(GELUActivation [(1, 5, 512)]->[(1, 5, 512)], Linear [(1, 5, 512)]->[(1, 5, 128)])": 2, "(Linear [(1, 5, 512)]->[(1, 5, 128)], Dropout [(1, 5, 128)]->[(1, 5, 128)])": 2, "(LayerNorm [(1, 5, 128)]->[(1, 5, 128)], Linear [(1, 5, 128)]->[(1, 5, 128)])": 3, "(Linear [(1, 5, 128)]->[(1, 5, 128)], view [(1, 5, 128)]->[(1, 5, 2, 64)])": 3, "(view [(1, 5, 128)]->[(1, 5, 2, 64)], permute [(1, 5, 2, 64)]->[(1, 2, 5, 64)])": 3, "(permute [(1, 5, 2, 64)]->[(1, 2, 5, 64)], transpose [(1, 2, 5, 64)]->[(1, 2, 64, 5)])": 1, "(transpose [(1, 2, 5, 64)]->[(1, 2, 64, 5)], matmul [(1, 2, 5, 64), (1, 2, 64, 5)]->[(1, 2, 5, 5)])": 1, "(matmul [(1, 2, 5, 64), (1, 2, 64, 5)]->[(1, 2, 5, 5)], div [(1, 2, 5, 5)]->[(1, 2, 5, 5)])": 1, "(div [(1, 2, 5, 5)]->[(1, 2, 5, 5)], add [(1, 2, 5, 5), (1, 1, 1, 5)]->[(1, 2, 5, 5)])": 1, "(permute [(1, 5, 2, 64)]->[(1, 2, 5, 64)], matmul [(1, 2, 5, 64), (1, 2, 64, 5)]->[(1, 2, 5, 5)])": 1, "(permute [(1, 5, 2, 64)]->[(1, 2, 5, 64)], matmul [(1, 2, 5, 5), (1, 2, 5, 64)]->[(1, 2, 5, 64)])": 1}, "uer/roberta-mini-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 4, 5, 5), (1, 1, 1, 5)]->[(1, 4, 5, 5)])": 4, "(add [(1, 4, 5, 5), (1, 1, 1, 5)]->[(1, 4, 5, 5)], softmax [(1, 4, 5, 5)]->[(1, 4, 5, 5)])": 4, "(softmax [(1, 4, 5, 5)]->[(1, 4, 5, 5)], Dropout [(1, 4, 5, 5)]->[(1, 4, 5, 5)])": 4, "(Dropout [(1, 4, 5, 5)]->[(1, 4, 5, 5)], matmul [(1, 4, 5, 5), (1, 4, 5, 64)]->[(1, 4, 5, 64)])": 4, "(matmul [(1, 4, 5, 5), (1, 4, 5, 64)]->[(1, 4, 5, 64)], permute [(1, 4, 5, 64)]->[(1, 5, 4, 64)])": 4, "(permute [(1, 4, 5, 64)]->[(1, 5, 4, 64)], contiguous [(1, 5, 4, 64)]->[(1, 5, 4, 64)])": 4, "(contiguous [(1, 5, 4, 64)]->[(1, 5, 4, 64)], view [(1, 5, 4, 64)]->[(1, 5, 256)])": 4, "(view [(1, 5, 4, 64)]->[(1, 5, 256)], Linear [(1, 5, 256)]->[(1, 5, 256)])": 4, "(Linear [(1, 5, 256)]->[(1, 5, 256)], Dropout [(1, 5, 256)]->[(1, 5, 256)])": 4, "(Dropout [(1, 5, 256)]->[(1, 5, 256)], add [(1, 5, 256), (1, 5, 256)]->[(1, 5, 256)])": 8, "(add [(1, 5, 256), (1, 5, 256)]->[(1, 5, 256)], LayerNorm [(1, 5, 256)]->[(1, 5, 256)])": 8, "(LayerNorm [(1, 5, 256)]->[(1, 5, 256)], Linear [(1, 5, 256)]->[(1, 5, 1024)])": 4, "(LayerNorm [(1, 5, 256)]->[(1, 5, 256)], add [(1, 5, 256), (1, 5, 256)]->[(1, 5, 256)])": 7, "(LayerNorm [(1, 5, 256)]->[(1, 5, 256)], Linear [(1, 5, 256)]->[(1, 5, 256)])": 9, "(Linear [(1, 5, 256)]->[(1, 5, 256)], view [(1, 5, 256)]->[(1, 5, 4, 64)])": 9, "(view [(1, 5, 256)]->[(1, 5, 4, 64)], permute [(1, 5, 4, 64)]->[(1, 4, 5, 64)])": 9, "(permute [(1, 5, 4, 64)]->[(1, 4, 5, 64)], transpose [(1, 4, 5, 64)]->[(1, 4, 64, 5)])": 3, "(transpose [(1, 4, 5, 64)]->[(1, 4, 64, 5)], matmul [(1, 4, 5, 64), (1, 4, 64, 5)]->[(1, 4, 5, 5)])": 3, "(matmul [(1, 4, 5, 64), (1, 4, 64, 5)]->[(1, 4, 5, 5)], div [(1, 4, 5, 5)]->[(1, 4, 5, 5)])": 3, "(div [(1, 4, 5, 5)]->[(1, 4, 5, 5)], add [(1, 4, 5, 5), (1, 1, 1, 5)]->[(1, 4, 5, 5)])": 3, "(Linear [(1, 5, 256)]->[(1, 5, 1024)], GELUActivation [(1, 5, 1024)]->[(1, 5, 1024)])": 4, "(GELUActivation [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 256)])": 4, "(Linear [(1, 5, 1024)]->[(1, 5, 256)], Dropout [(1, 5, 256)]->[(1, 5, 256)])": 4, "(LayerNorm [(1, 5, 256)]->[(1, 5, 256)], __getitem__ [(1, 5, 256)]->[(1, 256)])": 1, "(LayerNorm [(1, 5, 256)]->[(1, 5, 256)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 256)]->[(1, 256)], Linear [(1, 256)]->[(1, 256)])": 1, "(Linear [(1, 256)]->[(1, 256)], Tanh [(1, 256)]->[(1, 256)])": 1, "(Tanh [(1, 256)]->[(1, 256)], [OUTPUT])": 1, "(permute [(1, 5, 4, 64)]->[(1, 4, 5, 64)], matmul [(1, 4, 5, 64), (1, 4, 64, 5)]->[(1, 4, 5, 5)])": 3, "(permute [(1, 5, 4, 64)]->[(1, 4, 5, 64)], matmul [(1, 4, 5, 5), (1, 4, 5, 64)]->[(1, 4, 5, 64)])": 3}, "uer/roberta-small-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 8, 5, 5), (1, 1, 1, 5)]->[(1, 8, 5, 5)])": 4, "(add [(1, 8, 5, 5), (1, 1, 1, 5)]->[(1, 8, 5, 5)], softmax [(1, 8, 5, 5)]->[(1, 8, 5, 5)])": 4, "(softmax [(1, 8, 5, 5)]->[(1, 8, 5, 5)], Dropout [(1, 8, 5, 5)]->[(1, 8, 5, 5)])": 4, "(Dropout [(1, 8, 5, 5)]->[(1, 8, 5, 5)], matmul [(1, 8, 5, 5), (1, 8, 5, 64)]->[(1, 8, 5, 64)])": 4, "(matmul [(1, 8, 5, 5), (1, 8, 5, 64)]->[(1, 8, 5, 64)], permute [(1, 8, 5, 64)]->[(1, 5, 8, 64)])": 4, "(permute [(1, 8, 5, 64)]->[(1, 5, 8, 64)], contiguous [(1, 5, 8, 64)]->[(1, 5, 8, 64)])": 4, "(contiguous [(1, 5, 8, 64)]->[(1, 5, 8, 64)], view [(1, 5, 8, 64)]->[(1, 5, 512)])": 4, "(view [(1, 5, 8, 64)]->[(1, 5, 512)], Linear [(1, 5, 512)]->[(1, 5, 512)])": 4, "(Linear [(1, 5, 512)]->[(1, 5, 512)], Dropout [(1, 5, 512)]->[(1, 5, 512)])": 4, "(Dropout [(1, 5, 512)]->[(1, 5, 512)], add [(1, 5, 512), (1, 5, 512)]->[(1, 5, 512)])": 8, "(add [(1, 5, 512), (1, 5, 512)]->[(1, 5, 512)], LayerNorm [(1, 5, 512)]->[(1, 5, 512)])": 8, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], Linear [(1, 5, 512)]->[(1, 5, 2048)])": 4, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], add [(1, 5, 512), (1, 5, 512)]->[(1, 5, 512)])": 7, "(Linear [(1, 5, 512)]->[(1, 5, 2048)], GELUActivation [(1, 5, 2048)]->[(1, 5, 2048)])": 4, "(GELUActivation [(1, 5, 2048)]->[(1, 5, 2048)], Linear [(1, 5, 2048)]->[(1, 5, 512)])": 4, "(Linear [(1, 5, 2048)]->[(1, 5, 512)], Dropout [(1, 5, 512)]->[(1, 5, 512)])": 4, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], Linear [(1, 5, 512)]->[(1, 5, 512)])": 9, "(Linear [(1, 5, 512)]->[(1, 5, 512)], view [(1, 5, 512)]->[(1, 5, 8, 64)])": 9, "(view [(1, 5, 512)]->[(1, 5, 8, 64)], permute [(1, 5, 8, 64)]->[(1, 8, 5, 64)])": 9, "(permute [(1, 5, 8, 64)]->[(1, 8, 5, 64)], transpose [(1, 8, 5, 64)]->[(1, 8, 64, 5)])": 3, "(transpose [(1, 8, 5, 64)]->[(1, 8, 64, 5)], matmul [(1, 8, 5, 64), (1, 8, 64, 5)]->[(1, 8, 5, 5)])": 3, "(matmul [(1, 8, 5, 64), (1, 8, 64, 5)]->[(1, 8, 5, 5)], div [(1, 8, 5, 5)]->[(1, 8, 5, 5)])": 3, "(div [(1, 8, 5, 5)]->[(1, 8, 5, 5)], add [(1, 8, 5, 5), (1, 1, 1, 5)]->[(1, 8, 5, 5)])": 3, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], __getitem__ [(1, 5, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(permute [(1, 5, 8, 64)]->[(1, 8, 5, 64)], matmul [(1, 8, 5, 64), (1, 8, 64, 5)]->[(1, 8, 5, 5)])": 3, "(permute [(1, 5, 8, 64)]->[(1, 8, 5, 64)], matmul [(1, 8, 5, 5), (1, 8, 5, 64)]->[(1, 8, 5, 64)])": 3}, "uer/roberta-medium-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 8, 5, 5), (1, 1, 1, 5)]->[(1, 8, 5, 5)])": 8, "(add [(1, 8, 5, 5), (1, 1, 1, 5)]->[(1, 8, 5, 5)], softmax [(1, 8, 5, 5)]->[(1, 8, 5, 5)])": 8, "(softmax [(1, 8, 5, 5)]->[(1, 8, 5, 5)], Dropout [(1, 8, 5, 5)]->[(1, 8, 5, 5)])": 8, "(Dropout [(1, 8, 5, 5)]->[(1, 8, 5, 5)], matmul [(1, 8, 5, 5), (1, 8, 5, 64)]->[(1, 8, 5, 64)])": 8, "(matmul [(1, 8, 5, 5), (1, 8, 5, 64)]->[(1, 8, 5, 64)], permute [(1, 8, 5, 64)]->[(1, 5, 8, 64)])": 8, "(permute [(1, 8, 5, 64)]->[(1, 5, 8, 64)], contiguous [(1, 5, 8, 64)]->[(1, 5, 8, 64)])": 8, "(contiguous [(1, 5, 8, 64)]->[(1, 5, 8, 64)], view [(1, 5, 8, 64)]->[(1, 5, 512)])": 8, "(view [(1, 5, 8, 64)]->[(1, 5, 512)], Linear [(1, 5, 512)]->[(1, 5, 512)])": 8, "(Linear [(1, 5, 512)]->[(1, 5, 512)], Dropout [(1, 5, 512)]->[(1, 5, 512)])": 8, "(Dropout [(1, 5, 512)]->[(1, 5, 512)], add [(1, 5, 512), (1, 5, 512)]->[(1, 5, 512)])": 16, "(add [(1, 5, 512), (1, 5, 512)]->[(1, 5, 512)], LayerNorm [(1, 5, 512)]->[(1, 5, 512)])": 16, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], Linear [(1, 5, 512)]->[(1, 5, 2048)])": 8, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], add [(1, 5, 512), (1, 5, 512)]->[(1, 5, 512)])": 15, "(Linear [(1, 5, 512)]->[(1, 5, 2048)], GELUActivation [(1, 5, 2048)]->[(1, 5, 2048)])": 8, "(GELUActivation [(1, 5, 2048)]->[(1, 5, 2048)], Linear [(1, 5, 2048)]->[(1, 5, 512)])": 8, "(Linear [(1, 5, 2048)]->[(1, 5, 512)], Dropout [(1, 5, 512)]->[(1, 5, 512)])": 8, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], Linear [(1, 5, 512)]->[(1, 5, 512)])": 21, "(Linear [(1, 5, 512)]->[(1, 5, 512)], view [(1, 5, 512)]->[(1, 5, 8, 64)])": 21, "(view [(1, 5, 512)]->[(1, 5, 8, 64)], permute [(1, 5, 8, 64)]->[(1, 8, 5, 64)])": 21, "(permute [(1, 5, 8, 64)]->[(1, 8, 5, 64)], transpose [(1, 8, 5, 64)]->[(1, 8, 64, 5)])": 7, "(transpose [(1, 8, 5, 64)]->[(1, 8, 64, 5)], matmul [(1, 8, 5, 64), (1, 8, 64, 5)]->[(1, 8, 5, 5)])": 7, "(matmul [(1, 8, 5, 64), (1, 8, 64, 5)]->[(1, 8, 5, 5)], div [(1, 8, 5, 5)]->[(1, 8, 5, 5)])": 7, "(div [(1, 8, 5, 5)]->[(1, 8, 5, 5)], add [(1, 8, 5, 5), (1, 1, 1, 5)]->[(1, 8, 5, 5)])": 7, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], __getitem__ [(1, 5, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 5, 512)]->[(1, 5, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(permute [(1, 5, 8, 64)]->[(1, 8, 5, 64)], matmul [(1, 8, 5, 64), (1, 8, 64, 5)]->[(1, 8, 5, 5)])": 7, "(permute [(1, 5, 8, 64)]->[(1, 8, 5, 64)], matmul [(1, 8, 5, 5), (1, 8, 5, 64)]->[(1, 8, 5, 64)])": 7}, "uer/roberta-base-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "uer/roberta-large-wwm-chinese-cluecorpussmall": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 24, "(add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)], softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)], Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 24, "(matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)], permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)])": 24, "(permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)], contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)])": 24, "(contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)], view [(1, 5, 16, 64)]->[(1, 5, 1024)])": 24, "(view [(1, 5, 16, 64)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Dropout [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 48, "(add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)], LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)])": 48, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 4096)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 47, "(Linear [(1, 5, 1024)]->[(1, 5, 4096)], GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)])": 24, "(GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)], Linear [(1, 5, 4096)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 4096)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 69, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], view [(1, 5, 1024)]->[(1, 5, 16, 64)])": 69, "(view [(1, 5, 1024)]->[(1, 5, 16, 64)], permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)])": 69, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)])": 23, "(transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)], div [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 23, "(div [(1, 16, 5, 5)]->[(1, 16, 5, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 23, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], __getitem__ [(1, 5, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 23}, "w11wo/javanese-bert-small-imdb": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "wangfan/jdt-fin-roberta-wwm-large": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 24, "(add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)], softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)], Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 24, "(matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)], permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)])": 24, "(permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)], contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)])": 24, "(contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)], view [(1, 5, 16, 64)]->[(1, 5, 1024)])": 24, "(view [(1, 5, 16, 64)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Dropout [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 48, "(add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)], LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)])": 48, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 4096)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 47, "(Linear [(1, 5, 1024)]->[(1, 5, 4096)], GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)])": 24, "(GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)], Linear [(1, 5, 4096)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 4096)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 69, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], view [(1, 5, 1024)]->[(1, 5, 16, 64)])": 69, "(view [(1, 5, 1024)]->[(1, 5, 16, 64)], permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)])": 69, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)])": 23, "(transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)], div [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 23, "(div [(1, 16, 5, 5)]->[(1, 16, 5, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 23, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], __getitem__ [(1, 5, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 23}, "wangfan/jdt-fin-roberta-wwm": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "zjunlp/OntoProtein": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 30, "(add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)], softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 30, "(softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)], Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 30, "(Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 30, "(matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)], permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)])": 30, "(permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)], contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)])": 30, "(contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)], view [(1, 4, 16, 64)]->[(1, 4, 1024)])": 30, "(view [(1, 4, 16, 64)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 30, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 30, "(Dropout [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 60, "(add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)], LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)])": 60, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 4096)])": 30, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 59, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 87, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], view [(1, 4, 1024)]->[(1, 4, 16, 64)])": 87, "(view [(1, 4, 1024)]->[(1, 4, 16, 64)], permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)])": 87, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)])": 29, "(transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 29, "(matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)], div [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 29, "(div [(1, 16, 4, 4)]->[(1, 16, 4, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 29, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 29, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 29, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], __getitem__ [(1, 4, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 4, 1024)]->[(1, 4, 4096)], GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)])": 30, "(GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)], Linear [(1, 4, 4096)]->[(1, 4, 1024)])": 30, "(Linear [(1, 4, 4096)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 30}, "l3cube-pune/hing-bert": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "l3cube-pune/hing-mbert": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "l3cube-pune/hing-mbert-mixed": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "yarongef/DistilProtBert": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 15, "(add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)], softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 15, "(softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)], Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 15, "(Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 15, "(matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)], permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)])": 15, "(permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)], contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)])": 15, "(contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)], view [(1, 4, 16, 64)]->[(1, 4, 1024)])": 15, "(view [(1, 4, 16, 64)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 15, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 15, "(Dropout [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 30, "(add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)], LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)])": 30, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 4096)])": 15, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 29, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 42, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], view [(1, 4, 1024)]->[(1, 4, 16, 64)])": 42, "(view [(1, 4, 1024)]->[(1, 4, 16, 64)], permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)])": 42, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)])": 14, "(transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 14, "(matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)], div [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 14, "(div [(1, 16, 4, 4)]->[(1, 16, 4, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 14, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 14, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], __getitem__ [(1, 4, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 4, 1024)]->[(1, 4, 4096)], GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)])": 15, "(GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)], Linear [(1, 4, 4096)]->[(1, 4, 1024)])": 15, "(Linear [(1, 4, 4096)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 15, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 14}, "damlab/GO-language": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 32, 4, 4), (1, 1, 1, 4)]->[(1, 32, 4, 4)])": 12, "(add [(1, 32, 4, 4), (1, 1, 1, 4)]->[(1, 32, 4, 4)], softmax [(1, 32, 4, 4)]->[(1, 32, 4, 4)])": 12, "(softmax [(1, 32, 4, 4)]->[(1, 32, 4, 4)], Dropout [(1, 32, 4, 4)]->[(1, 32, 4, 4)])": 12, "(Dropout [(1, 32, 4, 4)]->[(1, 32, 4, 4)], matmul [(1, 32, 4, 4), (1, 32, 4, 32)]->[(1, 32, 4, 32)])": 12, "(matmul [(1, 32, 4, 4), (1, 32, 4, 32)]->[(1, 32, 4, 32)], permute [(1, 32, 4, 32)]->[(1, 4, 32, 32)])": 12, "(permute [(1, 32, 4, 32)]->[(1, 4, 32, 32)], contiguous [(1, 4, 32, 32)]->[(1, 4, 32, 32)])": 12, "(contiguous [(1, 4, 32, 32)]->[(1, 4, 32, 32)], view [(1, 4, 32, 32)]->[(1, 4, 1024)])": 12, "(view [(1, 4, 32, 32)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 12, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 12, "(Dropout [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 24, "(add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)], LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 23, "(Linear [(1, 4, 1024)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 1024)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 12, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 33, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], view [(1, 4, 1024)]->[(1, 4, 32, 32)])": 33, "(view [(1, 4, 1024)]->[(1, 4, 32, 32)], permute [(1, 4, 32, 32)]->[(1, 32, 4, 32)])": 33, "(permute [(1, 4, 32, 32)]->[(1, 32, 4, 32)], matmul [(1, 32, 4, 32), (1, 32, 32, 4)]->[(1, 32, 4, 4)])": 11, "(matmul [(1, 32, 4, 32), (1, 32, 32, 4)]->[(1, 32, 4, 4)], div [(1, 32, 4, 4)]->[(1, 32, 4, 4)])": 11, "(div [(1, 32, 4, 4)]->[(1, 32, 4, 4)], add [(1, 32, 4, 4), (1, 1, 1, 4)]->[(1, 32, 4, 4)])": 11, "(permute [(1, 4, 32, 32)]->[(1, 32, 4, 32)], transpose [(1, 32, 4, 32)]->[(1, 32, 32, 4)])": 11, "(transpose [(1, 32, 4, 32)]->[(1, 32, 32, 4)], matmul [(1, 32, 4, 32), (1, 32, 32, 4)]->[(1, 32, 4, 4)])": 11, "(permute [(1, 4, 32, 32)]->[(1, 32, 4, 32)], matmul [(1, 32, 4, 4), (1, 32, 4, 32)]->[(1, 32, 4, 32)])": 11, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], __getitem__ [(1, 4, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1}, "MLRS/BERTu": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "MLRS/mBERTu": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "enoriega/kw_pubmed_1000_0.0003": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "mayankb96/bert-base-uncased-finetuned-lexglue": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "enoriega/kw_pubmed_vanilla_sentence_10000_0.0003_2": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "egumasa/bert-base-uncased-finetuned-academic": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "ysnow9876/alephbert-base-finetuned-for-shut": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "vasugoel/K-12BERT": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "rufimelo/Legal-BERTimbau-large": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "rufimelo/Legal-BERTimbau-base": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "rufimelo/Legal-BERTimbau-large-v2": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}, "muhtasham/bert-small-finetuned-legal-contracts10train10val": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 4, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 4, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 4, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 4, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 4, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 8, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 7, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 4, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 9, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 9, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 3, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 3, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3}, "muhtasham/bert-small-finetuned-legal-contracts-larger4010": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 4, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 4, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 4, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 4, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 4, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 8, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 7, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 4, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 9, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 9, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 3, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 3, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3}, "muhtasham/bert-small-finetuned-legal-contracts-larger20-5-1": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 4, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 4, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 4, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 4, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 4, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 8, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 7, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 4, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 9, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 9, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 3, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 3, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3}, "muhtasham/bert-small-finetuned-legal-definitions": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 4, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 4, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 4, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 4, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 4, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 8, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 7, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 4, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 9, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 9, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 3, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 3, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3}, "muhtasham/bert-small-finetuned-legal-definitions-longer": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 4, "(add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)], softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(softmax [(1, 8, 4, 4)]->[(1, 8, 4, 4)], Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 4, "(Dropout [(1, 8, 4, 4)]->[(1, 8, 4, 4)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 4, "(matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)], permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)])": 4, "(permute [(1, 8, 4, 64)]->[(1, 4, 8, 64)], contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)])": 4, "(contiguous [(1, 4, 8, 64)]->[(1, 4, 8, 64)], view [(1, 4, 8, 64)]->[(1, 4, 512)])": 4, "(view [(1, 4, 8, 64)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 512)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(Dropout [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 8, "(add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)], LayerNorm [(1, 4, 512)]->[(1, 4, 512)])": 8, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 2048)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], add [(1, 4, 512), (1, 4, 512)]->[(1, 4, 512)])": 7, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], __getitem__ [(1, 4, 512)]->[(1, 512)])": 1, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 512)]->[(1, 512)], Linear [(1, 512)]->[(1, 512)])": 1, "(Linear [(1, 512)]->[(1, 512)], Tanh [(1, 512)]->[(1, 512)])": 1, "(Tanh [(1, 512)]->[(1, 512)], [OUTPUT])": 1, "(Linear [(1, 4, 512)]->[(1, 4, 2048)], GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)])": 4, "(GELUActivation [(1, 4, 2048)]->[(1, 4, 2048)], Linear [(1, 4, 2048)]->[(1, 4, 512)])": 4, "(Linear [(1, 4, 2048)]->[(1, 4, 512)], Dropout [(1, 4, 512)]->[(1, 4, 512)])": 4, "(LayerNorm [(1, 4, 512)]->[(1, 4, 512)], Linear [(1, 4, 512)]->[(1, 4, 512)])": 9, "(Linear [(1, 4, 512)]->[(1, 4, 512)], view [(1, 4, 512)]->[(1, 4, 8, 64)])": 9, "(view [(1, 4, 512)]->[(1, 4, 8, 64)], permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)])": 9, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)])": 3, "(transpose [(1, 8, 4, 64)]->[(1, 8, 64, 4)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3, "(matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)], div [(1, 8, 4, 4)]->[(1, 8, 4, 4)])": 3, "(div [(1, 8, 4, 4)]->[(1, 8, 4, 4)], add [(1, 8, 4, 4), (1, 1, 1, 4)]->[(1, 8, 4, 4)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 4), (1, 8, 4, 64)]->[(1, 8, 4, 64)])": 3, "(permute [(1, 4, 8, 64)]->[(1, 8, 4, 64)], matmul [(1, 8, 4, 64), (1, 8, 64, 4)]->[(1, 8, 4, 4)])": 3}, "GabrielDGC/bert-base-spanish-wwm-uncased-finetuned-imdb-spanish": {"([INPUT], __getitem__ [(1, 6)]->[(1, 1, 1, 6)])": 1, "(__getitem__ [(1, 6)]->[(1, 1, 1, 6)], to [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(to [(1, 1, 1, 6)]->[(1, 1, 1, 6)], __rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(__rsub__ [(1, 1, 1, 6)]->[(1, 1, 1, 6)], mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)])": 1, "(mul [(1, 1, 1, 6)]->[(1, 1, 1, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 12, "(add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)], softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(softmax [(1, 12, 6, 6)]->[(1, 12, 6, 6)], Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 12, "(Dropout [(1, 12, 6, 6)]->[(1, 12, 6, 6)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 12, "(matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)], permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)])": 12, "(permute [(1, 12, 6, 64)]->[(1, 6, 12, 64)], contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)])": 12, "(contiguous [(1, 6, 12, 64)]->[(1, 6, 12, 64)], view [(1, 6, 12, 64)]->[(1, 6, 768)])": 12, "(view [(1, 6, 12, 64)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 768)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(Dropout [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 24, "(add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)], LayerNorm [(1, 6, 768)]->[(1, 6, 768)])": 24, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 3072)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], add [(1, 6, 768), (1, 6, 768)]->[(1, 6, 768)])": 23, "(Linear [(1, 6, 768)]->[(1, 6, 3072)], GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)])": 12, "(GELUActivation [(1, 6, 3072)]->[(1, 6, 3072)], Linear [(1, 6, 3072)]->[(1, 6, 768)])": 12, "(Linear [(1, 6, 3072)]->[(1, 6, 768)], Dropout [(1, 6, 768)]->[(1, 6, 768)])": 12, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], Linear [(1, 6, 768)]->[(1, 6, 768)])": 33, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], __getitem__ [(1, 6, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 6, 768)]->[(1, 6, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 6, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 6, 768)]->[(1, 6, 768)], view [(1, 6, 768)]->[(1, 6, 12, 64)])": 33, "(view [(1, 6, 768)]->[(1, 6, 12, 64)], permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)])": 33, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11, "(matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)], div [(1, 12, 6, 6)]->[(1, 12, 6, 6)])": 11, "(div [(1, 12, 6, 6)]->[(1, 12, 6, 6)], add [(1, 12, 6, 6), (1, 1, 1, 6)]->[(1, 12, 6, 6)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], matmul [(1, 12, 6, 6), (1, 12, 6, 64)]->[(1, 12, 6, 64)])": 11, "(permute [(1, 6, 12, 64)]->[(1, 12, 6, 64)], transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)])": 11, "(transpose [(1, 12, 6, 64)]->[(1, 12, 64, 6)], matmul [(1, 12, 6, 64), (1, 12, 64, 6)]->[(1, 12, 6, 6)])": 11}, "Luciano/bertimbau-base-finetuned-lener-br": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 12, "(add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)], softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(softmax [(1, 12, 7, 7)]->[(1, 12, 7, 7)], Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 12, "(Dropout [(1, 12, 7, 7)]->[(1, 12, 7, 7)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 12, "(matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)], permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)])": 12, "(permute [(1, 12, 7, 64)]->[(1, 7, 12, 64)], contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)])": 12, "(contiguous [(1, 7, 12, 64)]->[(1, 7, 12, 64)], view [(1, 7, 12, 64)]->[(1, 7, 768)])": 12, "(view [(1, 7, 12, 64)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 768)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(Dropout [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 24, "(add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)], LayerNorm [(1, 7, 768)]->[(1, 7, 768)])": 24, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 3072)])": 12, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], add [(1, 7, 768), (1, 7, 768)]->[(1, 7, 768)])": 23, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], Linear [(1, 7, 768)]->[(1, 7, 768)])": 33, "(Linear [(1, 7, 768)]->[(1, 7, 768)], view [(1, 7, 768)]->[(1, 7, 12, 64)])": 33, "(view [(1, 7, 768)]->[(1, 7, 12, 64)], permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)])": 33, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11, "(matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)], div [(1, 12, 7, 7)]->[(1, 12, 7, 7)])": 11, "(div [(1, 12, 7, 7)]->[(1, 12, 7, 7)], add [(1, 12, 7, 7), (1, 1, 1, 7)]->[(1, 12, 7, 7)])": 11, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], matmul [(1, 12, 7, 7), (1, 12, 7, 64)]->[(1, 12, 7, 64)])": 11, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], __getitem__ [(1, 7, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 7, 768)]->[(1, 7, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(Linear [(1, 7, 768)]->[(1, 7, 3072)], GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)])": 12, "(GELUActivation [(1, 7, 3072)]->[(1, 7, 3072)], Linear [(1, 7, 3072)]->[(1, 7, 768)])": 12, "(Linear [(1, 7, 3072)]->[(1, 7, 768)], Dropout [(1, 7, 768)]->[(1, 7, 768)])": 12, "(permute [(1, 7, 12, 64)]->[(1, 12, 7, 64)], transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)])": 11, "(transpose [(1, 12, 7, 64)]->[(1, 12, 64, 7)], matmul [(1, 12, 7, 64), (1, 12, 64, 7)]->[(1, 12, 7, 7)])": 11}, "Luciano/bert-base-multilingual-cased-finetuned-lener_br": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 12, "(add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)], softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(softmax [(1, 12, 5, 5)]->[(1, 12, 5, 5)], Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 12, "(Dropout [(1, 12, 5, 5)]->[(1, 12, 5, 5)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 12, "(matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)], permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)])": 12, "(permute [(1, 12, 5, 64)]->[(1, 5, 12, 64)], contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)])": 12, "(contiguous [(1, 5, 12, 64)]->[(1, 5, 12, 64)], view [(1, 5, 12, 64)]->[(1, 5, 768)])": 12, "(view [(1, 5, 12, 64)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 768)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(Dropout [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 24, "(add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)], LayerNorm [(1, 5, 768)]->[(1, 5, 768)])": 24, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 3072)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], add [(1, 5, 768), (1, 5, 768)]->[(1, 5, 768)])": 23, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], Linear [(1, 5, 768)]->[(1, 5, 768)])": 33, "(Linear [(1, 5, 768)]->[(1, 5, 768)], view [(1, 5, 768)]->[(1, 5, 12, 64)])": 33, "(view [(1, 5, 768)]->[(1, 5, 12, 64)], permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)])": 33, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)], div [(1, 12, 5, 5)]->[(1, 12, 5, 5)])": 11, "(div [(1, 12, 5, 5)]->[(1, 12, 5, 5)], add [(1, 12, 5, 5), (1, 1, 1, 5)]->[(1, 12, 5, 5)])": 11, "(Linear [(1, 5, 768)]->[(1, 5, 3072)], GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)])": 12, "(GELUActivation [(1, 5, 3072)]->[(1, 5, 3072)], Linear [(1, 5, 3072)]->[(1, 5, 768)])": 12, "(Linear [(1, 5, 3072)]->[(1, 5, 768)], Dropout [(1, 5, 768)]->[(1, 5, 768)])": 12, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], __getitem__ [(1, 5, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 5, 768)]->[(1, 5, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)])": 11, "(transpose [(1, 12, 5, 64)]->[(1, 12, 64, 5)], matmul [(1, 12, 5, 64), (1, 12, 64, 5)]->[(1, 12, 5, 5)])": 11, "(permute [(1, 5, 12, 64)]->[(1, 12, 5, 64)], matmul [(1, 12, 5, 5), (1, 12, 5, 64)]->[(1, 12, 5, 64)])": 11}, "AndyChiang/cdgp-csg-bert-cloth": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "AndyChiang/cdgp-csg-scibert-cloth": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "AndyChiang/cdgp-csg-bert-dgen": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "AndyChiang/cdgp-csg-scibert-dgen": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "Aunsiels/ChildBERT": {"([INPUT], __getitem__ [(1, 5)]->[(1, 1, 1, 5)])": 1, "(__getitem__ [(1, 5)]->[(1, 1, 1, 5)], to [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(to [(1, 1, 1, 5)]->[(1, 1, 1, 5)], __rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(__rsub__ [(1, 1, 1, 5)]->[(1, 1, 1, 5)], mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)])": 1, "(mul [(1, 1, 1, 5)]->[(1, 1, 1, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 24, "(add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)], softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(softmax [(1, 16, 5, 5)]->[(1, 16, 5, 5)], Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 24, "(Dropout [(1, 16, 5, 5)]->[(1, 16, 5, 5)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 24, "(matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)], permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)])": 24, "(permute [(1, 16, 5, 64)]->[(1, 5, 16, 64)], contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)])": 24, "(contiguous [(1, 5, 16, 64)]->[(1, 5, 16, 64)], view [(1, 5, 16, 64)]->[(1, 5, 1024)])": 24, "(view [(1, 5, 16, 64)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(Dropout [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 48, "(add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)], LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)])": 48, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 4096)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], add [(1, 5, 1024), (1, 5, 1024)]->[(1, 5, 1024)])": 47, "(Linear [(1, 5, 1024)]->[(1, 5, 4096)], GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)])": 24, "(GELUActivation [(1, 5, 4096)]->[(1, 5, 4096)], Linear [(1, 5, 4096)]->[(1, 5, 1024)])": 24, "(Linear [(1, 5, 4096)]->[(1, 5, 1024)], Dropout [(1, 5, 1024)]->[(1, 5, 1024)])": 24, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], Linear [(1, 5, 1024)]->[(1, 5, 1024)])": 69, "(Linear [(1, 5, 1024)]->[(1, 5, 1024)], view [(1, 5, 1024)]->[(1, 5, 16, 64)])": 69, "(view [(1, 5, 1024)]->[(1, 5, 16, 64)], permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)])": 69, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)])": 23, "(transpose [(1, 16, 5, 64)]->[(1, 16, 64, 5)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)], div [(1, 16, 5, 5)]->[(1, 16, 5, 5)])": 23, "(div [(1, 16, 5, 5)]->[(1, 16, 5, 5)], add [(1, 16, 5, 5), (1, 1, 1, 5)]->[(1, 16, 5, 5)])": 23, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 64), (1, 16, 64, 5)]->[(1, 16, 5, 5)])": 23, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], __getitem__ [(1, 5, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 5, 1024)]->[(1, 5, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 5, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 5, 16, 64)]->[(1, 16, 5, 64)], matmul [(1, 16, 5, 5), (1, 16, 5, 64)]->[(1, 16, 5, 64)])": 23}, "KennethEnevoldsen/dfm-bert-large-v1-2048bsz-1Msteps": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 24, "(add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)], softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 24, "(softmax [(1, 16, 4, 4)]->[(1, 16, 4, 4)], Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 24, "(Dropout [(1, 16, 4, 4)]->[(1, 16, 4, 4)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 24, "(matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)], permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)])": 24, "(permute [(1, 16, 4, 64)]->[(1, 4, 16, 64)], contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)])": 24, "(contiguous [(1, 4, 16, 64)]->[(1, 4, 16, 64)], view [(1, 4, 16, 64)]->[(1, 4, 1024)])": 24, "(view [(1, 4, 16, 64)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(Dropout [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 48, "(add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)], LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)])": 48, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 4096)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], add [(1, 4, 1024), (1, 4, 1024)]->[(1, 4, 1024)])": 47, "(Linear [(1, 4, 1024)]->[(1, 4, 4096)], GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)])": 24, "(GELUActivation [(1, 4, 4096)]->[(1, 4, 4096)], Linear [(1, 4, 4096)]->[(1, 4, 1024)])": 24, "(Linear [(1, 4, 4096)]->[(1, 4, 1024)], Dropout [(1, 4, 1024)]->[(1, 4, 1024)])": 24, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], Linear [(1, 4, 1024)]->[(1, 4, 1024)])": 69, "(Linear [(1, 4, 1024)]->[(1, 4, 1024)], view [(1, 4, 1024)]->[(1, 4, 16, 64)])": 69, "(view [(1, 4, 1024)]->[(1, 4, 16, 64)], permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)])": 69, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 4), (1, 16, 4, 64)]->[(1, 16, 4, 64)])": 23, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], __getitem__ [(1, 4, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 4, 1024)]->[(1, 4, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)])": 23, "(transpose [(1, 16, 4, 64)]->[(1, 16, 64, 4)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 23, "(matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)], div [(1, 16, 4, 4)]->[(1, 16, 4, 4)])": 23, "(div [(1, 16, 4, 4)]->[(1, 16, 4, 4)], add [(1, 16, 4, 4), (1, 1, 1, 4)]->[(1, 16, 4, 4)])": 23, "(permute [(1, 4, 16, 64)]->[(1, 16, 4, 64)], matmul [(1, 16, 4, 64), (1, 16, 64, 4)]->[(1, 16, 4, 4)])": 23}, "alanila/autotrain-acc_keys-2347073860": {"([INPUT], __getitem__ [(1, 4)]->[(1, 1, 1, 4)])": 1, "(__getitem__ [(1, 4)]->[(1, 1, 1, 4)], to [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(to [(1, 1, 1, 4)]->[(1, 1, 1, 4)], __rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(__rsub__ [(1, 1, 1, 4)]->[(1, 1, 1, 4)], mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)])": 1, "(mul [(1, 1, 1, 4)]->[(1, 1, 1, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 12, "(add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)], softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(softmax [(1, 12, 4, 4)]->[(1, 12, 4, 4)], Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 12, "(Dropout [(1, 12, 4, 4)]->[(1, 12, 4, 4)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 12, "(matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)], permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)])": 12, "(permute [(1, 12, 4, 64)]->[(1, 4, 12, 64)], contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)])": 12, "(contiguous [(1, 4, 12, 64)]->[(1, 4, 12, 64)], view [(1, 4, 12, 64)]->[(1, 4, 768)])": 12, "(view [(1, 4, 12, 64)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 768)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(Dropout [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 24, "(add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)], LayerNorm [(1, 4, 768)]->[(1, 4, 768)])": 24, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 3072)])": 12, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], add [(1, 4, 768), (1, 4, 768)]->[(1, 4, 768)])": 23, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], Linear [(1, 4, 768)]->[(1, 4, 768)])": 33, "(Linear [(1, 4, 768)]->[(1, 4, 768)], view [(1, 4, 768)]->[(1, 4, 12, 64)])": 33, "(view [(1, 4, 768)]->[(1, 4, 12, 64)], permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)])": 33, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)])": 11, "(transpose [(1, 12, 4, 64)]->[(1, 12, 64, 4)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)], div [(1, 12, 4, 4)]->[(1, 12, 4, 4)])": 11, "(div [(1, 12, 4, 4)]->[(1, 12, 4, 4)], add [(1, 12, 4, 4), (1, 1, 1, 4)]->[(1, 12, 4, 4)])": 11, "(Linear [(1, 4, 768)]->[(1, 4, 3072)], GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)])": 12, "(GELUActivation [(1, 4, 3072)]->[(1, 4, 3072)], Linear [(1, 4, 3072)]->[(1, 4, 768)])": 12, "(Linear [(1, 4, 3072)]->[(1, 4, 768)], Dropout [(1, 4, 768)]->[(1, 4, 768)])": 12, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 4), (1, 12, 4, 64)]->[(1, 12, 4, 64)])": 11, "(permute [(1, 4, 12, 64)]->[(1, 12, 4, 64)], matmul [(1, 12, 4, 64), (1, 12, 64, 4)]->[(1, 12, 4, 4)])": 11, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], __getitem__ [(1, 4, 768)]->[(1, 768)])": 1, "(LayerNorm [(1, 4, 768)]->[(1, 4, 768)], [OUTPUT])": 1, "(__getitem__ [(1, 4, 768)]->[(1, 768)], Linear [(1, 768)]->[(1, 768)])": 1, "(Linear [(1, 768)]->[(1, 768)], Tanh [(1, 768)]->[(1, 768)])": 1, "(Tanh [(1, 768)]->[(1, 768)], [OUTPUT])": 1}, "stjiris/bert-large-portuguese-cased-legal-mlm": {"([INPUT], __getitem__ [(1, 7)]->[(1, 1, 1, 7)])": 1, "(__getitem__ [(1, 7)]->[(1, 1, 1, 7)], to [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(to [(1, 1, 1, 7)]->[(1, 1, 1, 7)], __rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(__rsub__ [(1, 1, 1, 7)]->[(1, 1, 1, 7)], mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)])": 1, "(mul [(1, 1, 1, 7)]->[(1, 1, 1, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 24, "(add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)], softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(softmax [(1, 16, 7, 7)]->[(1, 16, 7, 7)], Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 24, "(Dropout [(1, 16, 7, 7)]->[(1, 16, 7, 7)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 24, "(matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)], permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)])": 24, "(permute [(1, 16, 7, 64)]->[(1, 7, 16, 64)], contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)])": 24, "(contiguous [(1, 7, 16, 64)]->[(1, 7, 16, 64)], view [(1, 7, 16, 64)]->[(1, 7, 1024)])": 24, "(view [(1, 7, 16, 64)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(Dropout [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 48, "(add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)], LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)])": 48, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 4096)])": 24, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], add [(1, 7, 1024), (1, 7, 1024)]->[(1, 7, 1024)])": 47, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], Linear [(1, 7, 1024)]->[(1, 7, 1024)])": 69, "(Linear [(1, 7, 1024)]->[(1, 7, 1024)], view [(1, 7, 1024)]->[(1, 7, 16, 64)])": 69, "(view [(1, 7, 1024)]->[(1, 7, 16, 64)], permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)])": 69, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 7), (1, 16, 7, 64)]->[(1, 16, 7, 64)])": 23, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], __getitem__ [(1, 7, 1024)]->[(1, 1024)])": 1, "(LayerNorm [(1, 7, 1024)]->[(1, 7, 1024)], [OUTPUT])": 1, "(__getitem__ [(1, 7, 1024)]->[(1, 1024)], Linear [(1, 1024)]->[(1, 1024)])": 1, "(Linear [(1, 1024)]->[(1, 1024)], Tanh [(1, 1024)]->[(1, 1024)])": 1, "(Tanh [(1, 1024)]->[(1, 1024)], [OUTPUT])": 1, "(Linear [(1, 7, 1024)]->[(1, 7, 4096)], GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)])": 24, "(GELUActivation [(1, 7, 4096)]->[(1, 7, 4096)], Linear [(1, 7, 4096)]->[(1, 7, 1024)])": 24, "(Linear [(1, 7, 4096)]->[(1, 7, 1024)], Dropout [(1, 7, 1024)]->[(1, 7, 1024)])": 24, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23, "(matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)], div [(1, 16, 7, 7)]->[(1, 16, 7, 7)])": 23, "(div [(1, 16, 7, 7)]->[(1, 16, 7, 7)], add [(1, 16, 7, 7), (1, 1, 1, 7)]->[(1, 16, 7, 7)])": 23, "(permute [(1, 7, 16, 64)]->[(1, 16, 7, 64)], transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)])": 23, "(transpose [(1, 16, 7, 64)]->[(1, 16, 64, 7)], matmul [(1, 16, 7, 64), (1, 16, 64, 7)]->[(1, 16, 7, 7)])": 23}}