/home/kim3118/.local/lib/python3.11/site-packages/huggingface_hub/file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.
  warnings.warn(
2024-08-16 11:30:59.682 | INFO     | __main__:main:747 - tau: 50
2024-08-16 11:30:59.682 | INFO     | __main__:main:758 - Single-label training mode. model_type
2024-08-16 11:31:02.717 | INFO     | __main__:train:144 - Training with model: longformer, lr: 5e-05, batch_size: 32, epoch: 30, loss_fn:CLCE, lambd:0.3
2024-08-16 11:31:02.718 | INFO     | __main__:train:159 - ====epoch #1====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:04<06:09,  4.40s/it]
Training:   2%|▏         | 2/85 [00:07<05:16,  3.81s/it]
Training:   4%|▎         | 3/85 [00:11<04:58,  3.64s/it]
Training:   5%|▍         | 4/85 [00:14<04:47,  3.56s/it]
Training:   6%|▌         | 5/85 [00:18<04:40,  3.50s/it]
Training:   7%|▋         | 6/85 [00:21<04:34,  3.47s/it]
Training:   8%|▊         | 7/85 [00:24<04:29,  3.45s/it]
Training:   9%|▉         | 8/85 [00:28<04:24,  3.43s/it]
Training:  11%|█         | 9/85 [00:31<04:19,  3.42s/it]
Training:  12%|█▏        | 10/85 [00:35<04:16,  3.42s/it]
Training:  13%|█▎        | 11/85 [00:38<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:41<04:08,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:45<04:05,  3.41s/it]
Training:  16%|█▋        | 14/85 [00:48<04:01,  3.40s/it]
Training:  18%|█▊        | 15/85 [00:52<03:58,  3.40s/it]
Training:  19%|█▉        | 16/85 [00:55<03:54,  3.40s/it]
Training:  20%|██        | 17/85 [00:59<03:59,  3.52s/it]
Training:  21%|██        | 18/85 [01:02<03:53,  3.49s/it]
Training:  22%|██▏       | 19/85 [01:06<03:48,  3.46s/it]
Training:  24%|██▎       | 20/85 [01:09<03:43,  3.44s/it]
Training:  25%|██▍       | 21/85 [01:12<03:39,  3.43s/it]
Training:  26%|██▌       | 22/85 [01:16<03:35,  3.42s/it]
Training:  27%|██▋       | 23/85 [01:19<03:32,  3.42s/it]
Training:  28%|██▊       | 24/85 [01:23<03:28,  3.42s/it]
Training:  29%|██▉       | 25/85 [01:26<03:24,  3.42s/it]
Training:  31%|███       | 26/85 [01:29<03:21,  3.41s/it]
Training:  32%|███▏      | 27/85 [01:33<03:17,  3.41s/it]
Training:  33%|███▎      | 28/85 [01:36<03:14,  3.41s/it]
Training:  34%|███▍      | 29/85 [01:40<03:11,  3.42s/it]
Training:  35%|███▌      | 30/85 [01:43<03:07,  3.41s/it]
Training:  36%|███▋      | 31/85 [01:46<03:04,  3.41s/it]
Training:  38%|███▊      | 32/85 [01:50<03:00,  3.41s/it]
Training:  39%|███▉      | 33/85 [01:53<02:57,  3.41s/it]
Training:  40%|████      | 34/85 [01:57<02:53,  3.41s/it]
Training:  41%|████      | 35/85 [02:00<02:50,  3.41s/it]
Training:  42%|████▏     | 36/85 [02:04<02:47,  3.41s/it]
Training:  44%|████▎     | 37/85 [02:07<02:43,  3.41s/it]
Training:  45%|████▍     | 38/85 [02:10<02:40,  3.41s/it]
Training:  46%|████▌     | 39/85 [02:14<02:36,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:17<02:33,  3.41s/it]
Training:  48%|████▊     | 41/85 [02:21<02:30,  3.41s/it]
Training:  49%|████▉     | 42/85 [02:24<02:26,  3.41s/it]
Training:  51%|█████     | 43/85 [02:27<02:23,  3.41s/it]
Training:  52%|█████▏    | 44/85 [02:31<02:19,  3.41s/it]
Training:  53%|█████▎    | 45/85 [02:34<02:16,  3.41s/it]
Training:  54%|█████▍    | 46/85 [02:38<02:13,  3.41s/it]
Training:  55%|█████▌    | 47/85 [02:41<02:09,  3.41s/it]
Training:  56%|█████▋    | 48/85 [02:44<02:06,  3.41s/it]
Training:  58%|█████▊    | 49/85 [02:48<02:02,  3.41s/it]
Training:  59%|█████▉    | 50/85 [02:51<01:59,  3.41s/it]
Training:  60%|██████    | 51/85 [02:55<01:56,  3.42s/it]
Training:  61%|██████    | 52/85 [02:58<01:52,  3.41s/it]
Training:  62%|██████▏   | 53/85 [03:02<01:49,  3.42s/it]
Training:  64%|██████▎   | 54/85 [03:05<01:45,  3.41s/it]
Training:  65%|██████▍   | 55/85 [03:08<01:42,  3.41s/it]
Training:  66%|██████▌   | 56/85 [03:12<01:38,  3.41s/it]
Training:  67%|██████▋   | 57/85 [03:15<01:35,  3.41s/it]
Training:  68%|██████▊   | 58/85 [03:19<01:32,  3.41s/it]
Training:  69%|██████▉   | 59/85 [03:22<01:28,  3.41s/it]
Training:  71%|███████   | 60/85 [03:25<01:25,  3.40s/it]
Training:  72%|███████▏  | 61/85 [03:29<01:21,  3.41s/it]
Training:  73%|███████▎  | 62/85 [03:32<01:18,  3.41s/it]
Training:  74%|███████▍  | 63/85 [03:36<01:14,  3.41s/it]
Training:  75%|███████▌  | 64/85 [03:39<01:11,  3.41s/it]
Training:  76%|███████▋  | 65/85 [03:42<01:08,  3.41s/it]
Training:  78%|███████▊  | 66/85 [03:46<01:04,  3.41s/it]
Training:  79%|███████▉  | 67/85 [03:49<01:01,  3.41s/it]
Training:  80%|████████  | 68/85 [03:53<00:58,  3.41s/it]
Training:  81%|████████  | 69/85 [03:56<00:54,  3.41s/it]
Training:  82%|████████▏ | 70/85 [03:59<00:51,  3.40s/it]
Training:  84%|████████▎ | 71/85 [04:03<00:47,  3.40s/it]
Training:  85%|████████▍ | 72/85 [04:06<00:44,  3.41s/it]
Training:  86%|████████▌ | 73/85 [04:10<00:40,  3.41s/it]
Training:  87%|████████▋ | 74/85 [04:13<00:37,  3.41s/it]
Training:  88%|████████▊ | 75/85 [04:17<00:34,  3.41s/it]
Training:  89%|████████▉ | 76/85 [04:20<00:30,  3.42s/it]
Training:  91%|█████████ | 77/85 [04:23<00:27,  3.40s/it]
Training:  92%|█████████▏| 78/85 [04:27<00:23,  3.41s/it]
Training:  93%|█████████▎| 79/85 [04:30<00:20,  3.41s/it]
Training:  94%|█████████▍| 80/85 [04:34<00:17,  3.41s/it]
Training:  95%|█████████▌| 81/85 [04:37<00:13,  3.40s/it]
Training:  96%|█████████▋| 82/85 [04:40<00:10,  3.41s/it]
Training:  98%|█████████▊| 83/85 [04:44<00:06,  3.41s/it]
Training:  99%|█████████▉| 84/85 [04:47<00:03,  3.40s/it]
Training: 100%|██████████| 85/85 [04:51<00:00,  3.41s/it]
Training: 100%|██████████| 85/85 [04:51<00:00,  3.43s/it]
2024-08-16 11:35:53.850 | INFO     | __main__:train:207 - Epoch 1 Average Loss: 6.65706
2024-08-16 11:35:54.604 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL1*****
2024-08-16 11:35:54.604 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 11:35:54.604 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.02it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.15it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.29it/s]
2024-08-16 11:36:11.617 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     0.8889    0.9697    0.9275        33
audio-spectrogram-transformer     0.4545    1.0000    0.6250         5
                         bart     0.7097    1.0000    0.8302        22
                         beit     0.6667    0.6667    0.6667         6
                         bert     0.7294    0.8986    0.8052        69
                     big_bird        nan    0.0000       nan        22
              bigbird_pegasus     0.8889    1.0000    0.9412         8
                   blenderbot     1.0000    0.8000    0.8889         5
                    camembert     0.0000    0.0000       nan        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    0.2500    0.4000         4
                      codegen        nan    0.0000       nan         4
                     convnext     0.7000    1.0000    0.8235         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl        nan    0.0000       nan         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     0.9600    0.9231    0.9412        26
                         detr        nan    0.0000       nan         3
                   distilbert     0.7500    0.9429    0.8354        35
                          dpr        nan    0.0000       nan         9
                      electra     0.2927    0.3871    0.3333        31
                          esm     1.0000    0.5714    0.7273         7
                         fnet        nan    0.0000       nan         2
                         glpn        nan    0.0000       nan         1
                         gpt2        nan    0.0000       nan         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.5000    0.3333    0.4000         3
                     gpt_neox        nan    0.0000       nan         2
                         gptj        nan    0.0000       nan         6
                     layoutlm        nan    0.0000       nan         1
                   layoutlmv3        nan    0.0000       nan         2
                          led        nan    0.0000       nan         5
                         lilt        nan    0.0000       nan         4
                        llama        nan    0.0000       nan         3
                   longformer     0.5750    1.0000    0.7302        23
                       longt5        nan    0.0000       nan         3
                      m2m_100        nan    0.0000       nan         4
                       marian     1.0000    0.8000    0.8889         5
                  mask2former        nan    0.0000       nan         8
                   maskformer        nan    0.0000       nan         5
                        mbart        nan    0.0000       nan         2
                   mobilebert        nan    0.0000       nan         5
                 mobilenet_v2        nan    0.0000       nan         4
                    mobilevit        nan    0.0000       nan         1
                        mpnet     1.0000    0.3529    0.5217        17
                          mpt        nan    0.0000       nan         6
                          mt5        nan    0.0000       nan         6
                          opt     0.3333    0.6000    0.4286         5
                      pegasus     0.0000    0.0000       nan         7
                    pegasus_x        nan    0.0000       nan         1
                       plbart     0.8000    0.6667    0.7273         6
                       regnet     0.2143    1.0000    0.3529         3
                       resnet        nan    0.0000       nan         4
                      roberta     0.2897    0.8077    0.4264        52
                         rwkv        nan    0.0000       nan         5
                          sam        nan    0.0000       nan         2
                    segformer     0.7500    1.0000    0.8571         3
               speech_to_text     1.0000    0.2500    0.4000         4
                     speecht5        nan    0.0000       nan         2
                         swin     0.3333    1.0000    0.5000         6
                           t5     0.4138    0.8571    0.5581        14
                    unispeech        nan    0.0000       nan         4
                unispeech-sat     0.0000    0.0000       nan         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit        nan    0.0000       nan         3
                     wav2vec2     0.3571    0.3571    0.3571        28
                        wavlm     0.3448    0.8333    0.4878        12
                      whisper     1.0000    0.1250    0.2222         8
                         xglm     0.7500    0.7500    0.7500         4
                  xlm-roberta        nan    0.0000       nan        30
                        xlnet     0.9091    0.9091    0.9091        11
                        yolos        nan    0.0000       nan         3

                     accuracy                         0.5565       681
                    macro avg     0.6559    0.3479    0.6746       681
                 weighted avg     0.6154    0.5565    0.6771       681

2024-08-16 11:36:11.617 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.5565
2024-08-16 11:36:11.629 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 11:36:11.629 | INFO     | __main__:eval:454 - Validation loss: 7.4331487959081475
2024-08-16 11:36:11.634 | INFO     | __main__:train:256 - epochs: 1
2024-08-16 11:36:11.635 | INFO     | __main__:train:257 - train_loss: [6.657064679089714]
2024-08-16 11:36:11.635 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475]
2024-08-16 11:36:11.635 | INFO     | __main__:train:159 - ====epoch #2====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:59,  3.57s/it]
Training:   2%|▏         | 2/85 [00:06<04:48,  3.47s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.44s/it]
Training:   5%|▍         | 4/85 [00:13<04:37,  3.42s/it]
Training:   6%|▌         | 5/85 [00:17<04:33,  3.42s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.42s/it]
Training:   8%|▊         | 7/85 [00:24<04:26,  3.42s/it]
Training:   9%|▉         | 8/85 [00:27<04:22,  3.41s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.41s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.41s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:41<04:08,  3.40s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.40s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.40s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.40s/it]
Training:  19%|█▉        | 16/85 [00:54<03:54,  3.41s/it]
Training:  20%|██        | 17/85 [00:58<03:51,  3.41s/it]
Training:  21%|██        | 18/85 [01:01<03:48,  3.41s/it]
Training:  22%|██▏       | 19/85 [01:04<03:45,  3.41s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.41s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.41s/it]
Training:  26%|██▌       | 22/85 [01:15<03:35,  3.41s/it]
Training:  27%|██▋       | 23/85 [01:18<03:31,  3.41s/it]
Training:  28%|██▊       | 24/85 [01:21<03:27,  3.41s/it]
Training:  29%|██▉       | 25/85 [01:25<03:24,  3.41s/it]
Training:  31%|███       | 26/85 [01:28<03:21,  3.41s/it]
Training:  32%|███▏      | 27/85 [01:32<03:17,  3.41s/it]
Training:  33%|███▎      | 28/85 [01:35<03:14,  3.41s/it]
Training:  34%|███▍      | 29/85 [01:39<03:11,  3.42s/it]
Training:  35%|███▌      | 30/85 [01:42<03:07,  3.42s/it]
Training:  36%|███▋      | 31/85 [01:45<03:04,  3.42s/it]
Training:  38%|███▊      | 32/85 [01:49<03:00,  3.41s/it]
Training:  39%|███▉      | 33/85 [01:52<02:57,  3.41s/it]
Training:  40%|████      | 34/85 [01:56<02:54,  3.41s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.41s/it]
Training:  42%|████▏     | 36/85 [02:02<02:47,  3.41s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.41s/it]
Training:  45%|████▍     | 38/85 [02:09<02:40,  3.41s/it]
Training:  46%|████▌     | 39/85 [02:13<02:36,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.41s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.41s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.41s/it]
Training:  51%|█████     | 43/85 [02:26<02:23,  3.41s/it]
Training:  52%|█████▏    | 44/85 [02:30<02:19,  3.41s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.41s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.41s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.41s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:06,  3.41s/it]
Training:  58%|█████▊    | 49/85 [02:47<02:02,  3.41s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:59,  3.41s/it]
Training:  60%|██████    | 51/85 [02:54<01:55,  3.41s/it]
Training:  61%|██████    | 52/85 [02:57<01:52,  3.40s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.41s/it]
Training:  64%|██████▎   | 54/85 [03:04<01:45,  3.41s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:42,  3.41s/it]
Training:  66%|██████▌   | 56/85 [03:11<01:38,  3.40s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.40s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.41s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.40s/it]
Training:  71%|███████   | 60/85 [03:24<01:25,  3.41s/it]
Training:  72%|███████▏  | 61/85 [03:28<01:21,  3.41s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.41s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.41s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:11,  3.40s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:08,  3.40s/it]
Training:  78%|███████▊  | 66/85 [03:45<01:04,  3.40s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:01,  3.40s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.41s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.40s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:51,  3.40s/it]
Training:  84%|████████▎ | 71/85 [04:02<00:47,  3.41s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.40s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.40s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.41s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:34,  3.41s/it]
Training:  89%|████████▉ | 76/85 [04:19<00:30,  3.41s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.41s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.41s/it]
Training:  93%|█████████▎| 79/85 [04:29<00:20,  3.41s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:17,  3.41s/it]
Training:  95%|█████████▌| 81/85 [04:36<00:13,  3.41s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.41s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.41s/it]
Training:  99%|█████████▉| 84/85 [04:46<00:03,  3.41s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.41s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.41s/it]
2024-08-16 11:41:01.460 | INFO     | __main__:train:207 - Epoch 2 Average Loss: 5.36116
2024-08-16 11:41:02.163 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL2*****
2024-08-16 11:41:02.163 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 11:41:02.163 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.04it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.15it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.19it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.21it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.23it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.23it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.24it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.25it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.25it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 11:41:19.228 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     0.9697    0.9697    0.9697        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     0.6667    0.6667    0.6667         6
                         bert     0.9231    0.8696    0.8955        69
                     big_bird     0.9524    0.9091    0.9302        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    0.8000    0.8889         5
                    camembert     0.2656    0.6800    0.3820        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    0.2500    0.4000         4
                      codegen        nan    0.0000       nan         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl        nan    0.0000       nan         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    0.9231    0.9600        26
                         detr        nan    0.0000       nan         3
                   distilbert     1.0000    0.9429    0.9706        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.5263    0.3226    0.4000        31
                          esm     0.7778    1.0000    0.8750         7
                         fnet        nan    0.0000       nan         2
                         glpn        nan    0.0000       nan         1
                         gpt2        nan    0.0000       nan         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.5000    1.0000    0.6667         3
                     gpt_neox        nan    0.0000       nan         2
                         gptj     0.6667    0.3333    0.4444         6
                     layoutlm        nan    0.0000       nan         1
                   layoutlmv3        nan    0.0000       nan         2
                          led     0.6250    1.0000    0.7692         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    0.6667    0.8000         3
                   longformer     1.0000    0.9130    0.9545        23
                       longt5     0.5000    0.6667    0.5714         3
                      m2m_100     1.0000    0.5000    0.6667         4
                       marian     0.5556    1.0000    0.7143         5
                  mask2former     0.7500    0.7500    0.7500         8
                   maskformer     0.7500    0.6000    0.6667         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     1.0000    0.4706    0.6400        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     0.4167    1.0000    0.5882         5
                      pegasus     1.0000    0.8571    0.9231         7
                    pegasus_x        nan    0.0000       nan         1
                       plbart     0.8571    1.0000    0.9231         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     0.6667    1.0000    0.8000         4
                      roberta     0.5294    0.5192    0.5243        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam        nan    0.0000       nan         2
                    segformer     0.7500    1.0000    0.8571         3
               speech_to_text     0.7500    0.7500    0.7500         4
                     speecht5        nan    0.0000       nan         2
                         swin     0.5455    1.0000    0.7059         6
                           t5     0.7222    0.9286    0.8125        14
                    unispeech        nan    0.0000       nan         4
                unispeech-sat     0.1429    0.5000    0.2222         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    0.6667    0.8000         3
                     wav2vec2     0.5714    0.8571    0.6857        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    0.7500    0.8571         8
                         xglm     0.6000    0.7500    0.6667         4
                  xlm-roberta     0.4286    0.4000    0.4138        30
                        xlnet     0.7857    1.0000    0.8800        11
                        yolos     1.0000    1.0000    1.0000         3

                     accuracy                         0.7445       681
                    macro avg     0.8217    0.6391    0.8051       681
                 weighted avg     0.7974    0.7445    0.7803       681

2024-08-16 11:41:19.229 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.7445
2024-08-16 11:41:19.233 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 11:41:19.233 | INFO     | __main__:eval:454 - Validation loss: 5.342955383387479
2024-08-16 11:41:19.238 | INFO     | __main__:train:256 - epochs: 2
2024-08-16 11:41:19.239 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022]
2024-08-16 11:41:19.239 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479]
2024-08-16 11:41:19.239 | INFO     | __main__:train:159 - ====epoch #3====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<05:04,  3.63s/it]
Training:   2%|▏         | 2/85 [00:07<04:50,  3.50s/it]
Training:   4%|▎         | 3/85 [00:10<04:42,  3.45s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.44s/it]
Training:   6%|▌         | 5/85 [00:17<04:33,  3.42s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.42s/it]
Training:   8%|▊         | 7/85 [00:24<04:26,  3.41s/it]
Training:   9%|▉         | 8/85 [00:27<04:22,  3.41s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.41s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.40s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:41<04:08,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:44<04:05,  3.41s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.41s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.41s/it]
Training:  19%|█▉        | 16/85 [00:54<03:55,  3.41s/it]
Training:  20%|██        | 17/85 [00:58<03:51,  3.40s/it]
Training:  21%|██        | 18/85 [01:01<03:48,  3.41s/it]
Training:  22%|██▏       | 19/85 [01:04<03:44,  3.41s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.41s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.41s/it]
Training:  26%|██▌       | 22/85 [01:15<03:34,  3.40s/it]
Training:  27%|██▋       | 23/85 [01:18<03:31,  3.41s/it]
Training:  28%|██▊       | 24/85 [01:21<03:27,  3.40s/it]
Training:  29%|██▉       | 25/85 [01:25<03:23,  3.40s/it]
Training:  31%|███       | 26/85 [01:28<03:20,  3.40s/it]
Training:  32%|███▏      | 27/85 [01:32<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.40s/it]
Training:  34%|███▍      | 29/85 [01:38<03:10,  3.40s/it]
Training:  35%|███▌      | 30/85 [01:42<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:49<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.40s/it]
Training:  40%|████      | 34/85 [01:55<02:53,  3.40s/it]
Training:  41%|████      | 35/85 [01:59<02:49,  3.40s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.40s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.40s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.40s/it]
Training:  47%|████▋     | 40/85 [02:16<02:32,  3.40s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.40s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.40s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:19,  3.40s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:15,  3.40s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.40s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:02,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:57<01:52,  3.40s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.40s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.40s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:41,  3.40s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:39,  3.44s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.43s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:32,  3.41s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.41s/it]
Training:  71%|███████   | 60/85 [03:24<01:25,  3.41s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.41s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.41s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.40s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.40s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:08,  3.40s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.40s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:01,  3.40s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.40s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.40s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:50,  3.40s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.39s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.40s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.40s/it]
Training:  87%|████████▋ | 74/85 [04:11<00:37,  3.40s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:34,  3.40s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.40s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.40s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.40s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.40s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:17,  3.40s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.40s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.40s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.40s/it]
Training:  99%|█████████▉| 84/85 [04:45<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.40s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.40s/it]
2024-08-16 11:46:08.593 | INFO     | __main__:train:207 - Epoch 3 Average Loss: 4.62754
2024-08-16 11:46:09.292 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL3*****
2024-08-16 11:46:09.292 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 11:46:09.293 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.02it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.14it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:16,  1.18it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.21it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.23it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.23it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.24it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.24it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.25it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.25it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.26it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.25it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.24it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.61it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.28it/s]
2024-08-16 11:46:26.479 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     0.9697    0.9697    0.9697        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9265    0.9130    0.9197        69
                     big_bird     0.9130    0.9545    0.9333        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert        nan    0.0000       nan        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     0.6667    1.0000    0.8000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl        nan    0.0000       nan         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    0.9231    0.9600        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.3529    0.3871    0.3692        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet        nan    0.0000       nan         2
                         glpn        nan    0.0000       nan         1
                         gpt2        nan    0.0000       nan         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.6000    1.0000    0.7500         3
                     gpt_neox        nan    0.0000       nan         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm        nan    0.0000       nan         1
                   layoutlmv3     0.6667    1.0000    0.8000         2
                          led     0.6250    1.0000    0.7692         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    0.9130    0.9545        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    0.7500    0.8571         8
                   maskformer     1.0000    0.6000    0.7500         5
                        mbart     0.6667    1.0000    0.8000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8333    0.8824    0.8571        17
                          mpt     1.0000    0.8333    0.9091         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     0.8333    1.0000    0.9091         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x        nan    0.0000       nan         1
                       plbart     1.0000    0.8333    0.9091         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     0.6667    1.0000    0.8000         4
                      roberta     0.3652    0.8077    0.5030        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam        nan    0.0000       nan         2
                    segformer     0.7500    1.0000    0.8571         3
               speech_to_text     0.8000    1.0000    0.8889         4
                     speecht5        nan    0.0000       nan         2
                         swin     0.7500    1.0000    0.8571         6
                           t5     0.9231    0.8571    0.8889        14
                    unispeech     0.6000    0.7500    0.6667         4
                unispeech-sat     0.0000    0.0000       nan         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    0.6667    0.8000         3
                     wav2vec2     0.5714    0.8571    0.6857        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     0.8000    1.0000    0.8889         4
                  xlm-roberta        nan    0.0000       nan        30
                        xlnet     0.7333    1.0000    0.8462        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.7753       681
                    macro avg     0.8679    0.7168    0.8900       681
                 weighted avg     0.8362    0.7753    0.8514       681

2024-08-16 11:46:26.479 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.7753
2024-08-16 11:46:26.482 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 11:46:26.482 | INFO     | __main__:eval:454 - Validation loss: 5.095791112292897
2024-08-16 11:46:26.500 | INFO     | __main__:train:256 - epochs: 3
2024-08-16 11:46:26.501 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032]
2024-08-16 11:46:26.501 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897]
2024-08-16 11:46:26.501 | INFO     | __main__:train:159 - ====epoch #4====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:56,  3.53s/it]
Training:   2%|▏         | 2/85 [00:06<04:47,  3.46s/it]
Training:   4%|▎         | 3/85 [00:10<04:42,  3.44s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.44s/it]
Training:   6%|▌         | 5/85 [00:17<04:33,  3.42s/it]
Training:   7%|▋         | 6/85 [00:20<04:29,  3.41s/it]
Training:   8%|▊         | 7/85 [00:23<04:25,  3.41s/it]
Training:   9%|▉         | 8/85 [00:27<04:22,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.40s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.40s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.40s/it]
Training:  14%|█▍        | 12/85 [00:40<04:08,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:44<04:05,  3.41s/it]
Training:  16%|█▋        | 14/85 [00:47<04:02,  3.41s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.41s/it]
Training:  19%|█▉        | 16/85 [00:54<03:55,  3.41s/it]
Training:  20%|██        | 17/85 [00:58<03:51,  3.41s/it]
Training:  21%|██        | 18/85 [01:01<03:48,  3.42s/it]
Training:  22%|██▏       | 19/85 [01:04<03:45,  3.41s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.41s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.41s/it]
Training:  26%|██▌       | 22/85 [01:15<03:34,  3.40s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.40s/it]
Training:  28%|██▊       | 24/85 [01:21<03:27,  3.40s/it]
Training:  29%|██▉       | 25/85 [01:25<03:24,  3.40s/it]
Training:  31%|███       | 26/85 [01:28<03:20,  3.40s/it]
Training:  32%|███▏      | 27/85 [01:32<03:17,  3.40s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.40s/it]
Training:  34%|███▍      | 29/85 [01:38<03:10,  3.40s/it]
Training:  35%|███▌      | 30/85 [01:42<03:07,  3.40s/it]
Training:  36%|███▋      | 31/85 [01:45<03:03,  3.40s/it]
Training:  38%|███▊      | 32/85 [01:49<03:00,  3.40s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.40s/it]
Training:  40%|████      | 34/85 [01:55<02:53,  3.40s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.40s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.41s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.41s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.40s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.41s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.40s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.41s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.40s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:19,  3.40s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.41s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:13,  3.41s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.41s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:06,  3.41s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:02,  3.41s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:59,  3.40s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.40s/it]
Training:  61%|██████    | 52/85 [02:57<01:52,  3.40s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.41s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.40s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:42,  3.40s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.40s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.40s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.40s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.40s/it]
Training:  71%|███████   | 60/85 [03:24<01:25,  3.40s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.40s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.40s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.41s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:11,  3.41s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:08,  3.41s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.41s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:01,  3.41s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.41s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.41s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:51,  3.41s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.40s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.40s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.40s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.40s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:34,  3.41s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.41s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.41s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.41s/it]
Training:  93%|█████████▎| 79/85 [04:29<00:20,  3.41s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:17,  3.41s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.41s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.40s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.41s/it]
Training:  99%|█████████▉| 84/85 [04:46<00:03,  3.41s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.40s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.41s/it]
2024-08-16 11:51:16.087 | INFO     | __main__:train:207 - Epoch 4 Average Loss: 4.48448
2024-08-16 11:51:16.790 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL4*****
2024-08-16 11:51:16.790 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 11:51:16.790 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.03it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.15it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.19it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.24it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 11:51:33.839 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     0.9697    0.9697    0.9697        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.7356    0.9275    0.8205        69
                     big_bird     0.9130    0.9545    0.9333        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert        nan    0.0000       nan        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     0.7500    0.7500    0.7500         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl        nan    0.0000       nan         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    0.9231    0.9600        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra        nan    0.0000       nan        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn        nan    0.0000       nan         1
                         gpt2        nan    0.0000       nan         1
                  gpt_bigcode     0.0000    0.0000       nan         1
                      gpt_neo     0.6000    1.0000    0.7500         3
                     gpt_neox     0.5000    0.5000    0.5000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm        nan    0.0000       nan         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     0.6250    1.0000    0.7692         5
                  mask2former     1.0000    0.7500    0.8571         8
                   maskformer     0.7500    0.6000    0.6667         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8421    0.9412    0.8889        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     1.0000    0.8571    0.9231         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     0.6667    1.0000    0.8000         4
                      roberta     0.3853    0.8077    0.5217        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam        nan    0.0000       nan         2
                    segformer     0.7500    1.0000    0.8571         3
               speech_to_text     0.7500    0.7500    0.7500         4
                     speecht5        nan    0.0000       nan         2
                         swin     0.7500    1.0000    0.8571         6
                           t5     0.9333    1.0000    0.9655        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    0.6667    0.8000         3
                     wav2vec2     0.6154    0.8571    0.7164        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     0.5714    1.0000    0.7273         4
                  xlm-roberta     0.6111    0.3667    0.4583        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.5000    1.0000    0.6667         3

                     accuracy                         0.7871       681
                    macro avg     0.8752    0.7531    0.8815       681
                 weighted avg     0.8401    0.7871    0.8526       681

2024-08-16 11:51:33.839 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.7871
2024-08-16 11:51:33.842 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 11:51:33.842 | INFO     | __main__:eval:454 - Validation loss: 4.98743457143957
2024-08-16 11:51:33.852 | INFO     | __main__:train:256 - epochs: 4
2024-08-16 11:51:33.853 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312]
2024-08-16 11:51:33.853 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957]
2024-08-16 11:51:33.853 | INFO     | __main__:train:159 - ====epoch #5====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:54,  3.50s/it]
Training:   2%|▏         | 2/85 [00:06<04:47,  3.46s/it]
Training:   4%|▎         | 3/85 [00:10<04:42,  3.45s/it]
Training:   5%|▍         | 4/85 [00:13<04:37,  3.43s/it]
Training:   6%|▌         | 5/85 [00:17<04:34,  3.43s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.43s/it]
Training:   8%|▊         | 7/85 [00:24<04:27,  3.43s/it]
Training:   9%|▉         | 8/85 [00:27<04:23,  3.43s/it]
Training:  11%|█         | 9/85 [00:30<04:20,  3.42s/it]
Training:  12%|█▏        | 10/85 [00:34<04:16,  3.43s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:41<04:08,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:44<04:05,  3.40s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.40s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.39s/it]
Training:  20%|██        | 17/85 [00:58<03:51,  3.41s/it]
Training:  21%|██        | 18/85 [01:01<03:48,  3.41s/it]
Training:  22%|██▏       | 19/85 [01:04<03:45,  3.41s/it]
Training:  24%|██▎       | 20/85 [01:08<03:42,  3.42s/it]
Training:  25%|██▍       | 21/85 [01:11<03:39,  3.42s/it]
Training:  26%|██▌       | 22/85 [01:15<03:35,  3.42s/it]
Training:  27%|██▋       | 23/85 [01:18<03:31,  3.41s/it]
Training:  28%|██▊       | 24/85 [01:21<03:27,  3.40s/it]
Training:  29%|██▉       | 25/85 [01:25<03:23,  3.40s/it]
Training:  31%|███       | 26/85 [01:28<03:20,  3.40s/it]
Training:  32%|███▏      | 27/85 [01:32<03:17,  3.40s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:42<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:03,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:49<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:52<02:55,  3.38s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.38s/it]
Training:  41%|████      | 35/85 [01:59<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.40s/it]
Training:  45%|████▍     | 38/85 [02:09<02:40,  3.41s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:16<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:23<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.38s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.38s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:15,  3.38s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.38s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:58,  3.38s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.38s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.40s/it]
Training:  71%|███████   | 60/85 [03:24<01:25,  3.40s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.40s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:18,  3.40s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.39s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.38s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.38s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:11<00:37,  3.38s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.38s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.38s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.38s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.38s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:45<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.40s/it]
2024-08-16 11:56:22.441 | INFO     | __main__:train:207 - Epoch 5 Average Loss: 4.46090
2024-08-16 11:56:23.159 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL5*****
2024-08-16 11:56:23.160 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 11:56:23.160 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:01<00:21,  1.02s/it]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.13it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:16,  1.19it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.21it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.23it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.24it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 11:56:40.262 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9697    0.9275    0.9481        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.2000    0.0400    0.0667        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     0.7500    0.7500    0.7500         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl        nan    0.0000       nan         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.5106    0.7742    0.6154        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn        nan    0.0000       nan         1
                         gpt2     1.0000    1.0000    1.0000         1
                  gpt_bigcode     0.0000    0.0000       nan         1
                      gpt_neo     0.6000    1.0000    0.7500         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm        nan    0.0000       nan         1
                   layoutlmv3     0.6667    1.0000    0.8000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     0.8333    1.0000    0.9091         5
                  mask2former     1.0000    0.7500    0.8571         8
                   maskformer     0.7500    0.6000    0.6667         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     1.0000    0.8571    0.9231         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     0.6667    1.0000    0.8000         4
                      roberta     0.5063    0.7692    0.6107        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam        nan    0.0000       nan         2
                    segformer     0.7500    1.0000    0.8571         3
               speech_to_text     0.8000    1.0000    0.8889         4
                     speecht5        nan    0.0000       nan         2
                         swin     0.7500    1.0000    0.8571         6
                           t5     0.9333    1.0000    0.9655        14
                    unispeech     1.0000    0.5000    0.6667         4
                unispeech-sat     0.0000    0.0000       nan         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    0.6667    0.8000         3
                     wav2vec2     0.7692    0.7143    0.7407        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     0.8000    1.0000    0.8889         4
                  xlm-roberta     0.7143    0.3333    0.4545        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8399       681
                    macro avg     0.8708    0.7968    0.8930       681
                 weighted avg     0.8468    0.8399    0.8423       681

2024-08-16 11:56:40.262 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8399
2024-08-16 11:56:40.268 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 11:56:40.268 | INFO     | __main__:eval:454 - Validation loss: 4.927706794305281
2024-08-16 11:56:40.276 | INFO     | __main__:train:256 - epochs: 5
2024-08-16 11:56:40.277 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316]
2024-08-16 11:56:40.277 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281]
2024-08-16 11:56:40.277 | INFO     | __main__:train:159 - ====epoch #6====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:57,  3.54s/it]
Training:   2%|▏         | 2/85 [00:06<04:46,  3.45s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.43s/it]
Training:   5%|▍         | 4/85 [00:13<04:36,  3.41s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.41s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.40s/it]
Training:   8%|▊         | 7/85 [00:23<04:25,  3.40s/it]
Training:   9%|▉         | 8/85 [00:27<04:22,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.41s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.41s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:40<04:08,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:44<04:05,  3.41s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.41s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.40s/it]
Training:  19%|█▉        | 16/85 [00:54<03:55,  3.41s/it]
Training:  20%|██        | 17/85 [00:57<03:51,  3.40s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.40s/it]
Training:  22%|██▏       | 19/85 [01:04<03:44,  3.40s/it]
Training:  24%|██▎       | 20/85 [01:08<03:40,  3.40s/it]
Training:  25%|██▍       | 21/85 [01:11<03:37,  3.40s/it]
Training:  26%|██▌       | 22/85 [01:14<03:34,  3.40s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.40s/it]
Training:  28%|██▊       | 24/85 [01:21<03:27,  3.40s/it]
Training:  29%|██▉       | 25/85 [01:25<03:24,  3.40s/it]
Training:  31%|███       | 26/85 [01:28<03:20,  3.40s/it]
Training:  32%|███▏      | 27/85 [01:31<03:17,  3.40s/it]
Training:  33%|███▎      | 28/85 [01:35<03:14,  3.41s/it]
Training:  34%|███▍      | 29/85 [01:38<03:10,  3.41s/it]
Training:  35%|███▌      | 30/85 [01:42<03:07,  3.40s/it]
Training:  36%|███▋      | 31/85 [01:45<03:03,  3.40s/it]
Training:  38%|███▊      | 32/85 [01:49<03:00,  3.40s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.40s/it]
Training:  40%|████      | 34/85 [01:55<02:53,  3.40s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.41s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.41s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.40s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.40s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.40s/it]
Training:  47%|████▋     | 40/85 [02:16<02:32,  3.40s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.40s/it]
Training:  49%|████▉     | 42/85 [02:23<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.40s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:19,  3.41s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.40s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.41s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.40s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.40s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:02,  3.40s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:59,  3.40s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:57<01:52,  3.39s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.40s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.40s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:41,  3.40s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.40s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.40s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.39s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.39s/it]
Training:  71%|███████   | 60/85 [03:24<01:24,  3.40s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.40s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:18,  3.40s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.40s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.40s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:08,  3.40s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.40s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:01,  3.40s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.41s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.40s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:50,  3.40s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.40s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.40s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.40s/it]
Training:  87%|████████▋ | 74/85 [04:11<00:37,  3.40s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:33,  3.40s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.40s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.40s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.41s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.41s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:17,  3.40s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.40s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.40s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.40s/it]
Training:  99%|█████████▉| 84/85 [04:45<00:03,  3.41s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.41s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.40s/it]
2024-08-16 12:01:29.593 | INFO     | __main__:train:207 - Epoch 6 Average Loss: 4.29832
2024-08-16 12:01:30.297 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL6*****
2024-08-16 12:01:30.297 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:01:30.297 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.01it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.14it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.19it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.21it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.23it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.24it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 12:01:47.378 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     0.9565    1.0000    0.9778        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9545    0.9130    0.9333        69
                     big_bird     0.9565    1.0000    0.9778        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.2000    0.0400    0.0667        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     0.6667    1.0000    0.8000         4
                      codegen     0.7500    0.7500    0.7500         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl        nan    0.0000       nan         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7917    0.6129    0.6909        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     1.0000    1.0000    1.0000         1
                  gpt_bigcode     0.3333    1.0000    0.5000         1
                      gpt_neo     1.0000    0.6667    0.8000         3
                     gpt_neox     0.5000    0.5000    0.5000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm        nan    0.0000       nan         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    0.6667    0.8000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    0.8750    0.9333         8
                   maskformer     1.0000    0.8000    0.8889         5
                        mbart     0.6667    1.0000    0.8000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.7619    0.9412    0.8421        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     0.8000    1.0000    0.8889         4
                      roberta     0.4719    0.8077    0.5957        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    0.5000    0.6667         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5        nan    0.0000       nan         2
                         swin     0.8571    1.0000    0.9231         6
                           t5     0.8750    1.0000    0.9333        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8182    0.6429    0.7200        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     0.7500    0.7500    0.7500         4
                  xlm-roberta     0.5357    0.5000    0.5172        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     1.0000    1.0000    1.0000         3

                     accuracy                         0.8399       681
                    macro avg     0.8989    0.8231    0.8770       681
                 weighted avg     0.8525    0.8399    0.8408       681

2024-08-16 12:01:47.379 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8399
2024-08-16 12:01:47.382 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:01:47.382 | INFO     | __main__:eval:454 - Validation loss: 4.873680569908836
2024-08-16 12:01:47.389 | INFO     | __main__:train:256 - epochs: 6
2024-08-16 12:01:47.390 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635]
2024-08-16 12:01:47.390 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836]
2024-08-16 12:01:47.390 | INFO     | __main__:train:159 - ====epoch #7====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:59,  3.57s/it]
Training:   2%|▏         | 2/85 [00:07<04:49,  3.49s/it]
Training:   4%|▎         | 3/85 [00:10<04:42,  3.45s/it]
Training:   5%|▍         | 4/85 [00:13<04:37,  3.43s/it]
Training:   6%|▌         | 5/85 [00:17<04:33,  3.42s/it]
Training:   7%|▋         | 6/85 [00:20<04:29,  3.41s/it]
Training:   8%|▊         | 7/85 [00:23<04:25,  3.40s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:17,  3.39s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.39s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.39s/it]
Training:  14%|█▍        | 12/85 [00:40<04:07,  3.39s/it]
Training:  15%|█▌        | 13/85 [00:44<04:03,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:51<03:56,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:54,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:44,  3.40s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.41s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.41s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.40s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.39s/it]
Training:  29%|██▉       | 25/85 [01:25<03:23,  3.39s/it]
Training:  31%|███       | 26/85 [01:28<03:20,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:10,  3.40s/it]
Training:  35%|███▌      | 30/85 [01:42<03:07,  3.41s/it]
Training:  36%|███▋      | 31/85 [01:45<03:03,  3.41s/it]
Training:  38%|███▊      | 32/85 [01:48<03:01,  3.42s/it]
Training:  39%|███▉      | 33/85 [01:52<02:57,  3.42s/it]
Training:  40%|████      | 34/85 [01:55<02:54,  3.41s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.41s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.39s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:16<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:28,  3.38s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.38s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.38s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:44,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:35,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.39s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.39s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.39s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.39s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.39s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:08,  3.41s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.41s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:01,  3.40s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.41s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.42s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:51,  3.41s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.42s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:44,  3.42s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:41,  3.42s/it]
Training:  87%|████████▋ | 74/85 [04:11<00:37,  3.42s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:34,  3.41s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.41s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.41s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.42s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.42s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:17,  3.42s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.42s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.42s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.41s/it]
Training:  99%|█████████▉| 84/85 [04:45<00:03,  3.41s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.40s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.40s/it]
2024-08-16 12:06:36.480 | INFO     | __main__:train:207 - Epoch 7 Average Loss: 4.29859
2024-08-16 12:06:37.188 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL7*****
2024-08-16 12:06:37.188 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:06:37.188 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.06it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.17it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.21it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.27it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.27it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.65it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 12:06:54.185 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9697    0.9275    0.9481        69
                     big_bird     0.8800    1.0000    0.9362        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert        nan    0.0000       nan        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7500    0.5806    0.6545        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     1.0000    1.0000    1.0000         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.5000    0.6667         6
                     layoutlm        nan    0.0000       nan         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     0.7143    1.0000    0.8333         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    0.9130    0.9545        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    0.8750    0.9333         8
                   maskformer     0.7500    0.6000    0.6667         5
                        mbart     0.6667    1.0000    0.8000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8333    0.8824    0.8571        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     0.6667    1.0000    0.8000         4
                      roberta     0.3852    0.9038    0.5402        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    0.5000    0.6667         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5        nan    0.0000       nan         2
                         swin     0.8571    1.0000    0.9231         6
                           t5     0.9333    1.0000    0.9655        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.2000    0.5000    0.2857         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8261    0.6786    0.7451        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     0.8000    1.0000    0.8889         4
                  xlm-roberta        nan    0.0000       nan        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8253       681
                    macro avg     0.9140    0.8332    0.9037       681
                 weighted avg     0.8870    0.8253    0.8839       681

2024-08-16 12:06:54.185 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8253
2024-08-16 12:06:54.193 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:06:54.193 | INFO     | __main__:eval:454 - Validation loss: 4.882195342670787
2024-08-16 12:06:54.201 | INFO     | __main__:train:256 - epochs: 7
2024-08-16 12:06:54.202 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186]
2024-08-16 12:06:54.202 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787]
2024-08-16 12:06:54.202 | INFO     | __main__:train:159 - ====epoch #8====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:57,  3.54s/it]
Training:   2%|▏         | 2/85 [00:06<04:46,  3.46s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.43s/it]
Training:   5%|▍         | 4/85 [00:13<04:36,  3.42s/it]
Training:   6%|▌         | 5/85 [00:17<04:37,  3.47s/it]
Training:   7%|▋         | 6/85 [00:20<04:31,  3.44s/it]
Training:   8%|▊         | 7/85 [00:24<04:26,  3.42s/it]
Training:   9%|▉         | 8/85 [00:27<04:22,  3.41s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.40s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.40s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.40s/it]
Training:  14%|█▍        | 12/85 [00:40<04:07,  3.39s/it]
Training:  15%|█▌        | 13/85 [00:44<04:03,  3.38s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:51<03:56,  3.38s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.38s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.38s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.38s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.38s/it]
Training:  24%|██▎       | 20/85 [01:08<03:40,  3.38s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:29,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.39s/it]
Training:  29%|██▉       | 25/85 [01:24<03:23,  3.39s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:41<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:03,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.39s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:45,  3.38s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.39s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:28,  3.38s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.38s/it]
Training:  51%|█████     | 43/85 [02:25<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.38s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.38s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:11,  3.38s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.38s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.38s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.38s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.38s/it]
Training:  60%|██████    | 51/85 [02:52<01:54,  3.37s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.38s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.38s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:44,  3.38s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.38s/it]
Training:  66%|██████▌   | 56/85 [03:09<01:38,  3.38s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.38s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:36<01:10,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.38s/it]
Training:  81%|████████  | 69/85 [03:53<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.38s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:03<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.38s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.38s/it]
Training:  91%|█████████ | 77/85 [04:20<00:27,  3.38s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.38s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.38s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:37<00:10,  3.39s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.39s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:47<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 12:11:42.205 | INFO     | __main__:train:207 - Epoch 8 Average Loss: 4.28337
2024-08-16 12:11:42.907 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL8*****
2024-08-16 12:11:42.907 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:11:42.907 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.03it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.16it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.27it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.27it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 12:11:59.924 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9552    0.9275    0.9412        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.4000    0.0800    0.1333        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    0.7500    0.8571         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.6667    0.7097    0.6875        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn        nan    0.0000       nan         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.6000    1.0000    0.7500         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     0.7143    1.0000    0.8333         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    0.9130    0.9545        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     0.7143    1.0000    0.8333         5
                  mask2former     0.8889    1.0000    0.9412         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     1.0000    0.8571    0.9231         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.4943    0.8269    0.6187        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     0.7500    1.0000    0.8571         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5        nan    0.0000       nan         2
                         swin     1.0000    0.8333    0.9091         6
                           t5     0.9333    1.0000    0.9655        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1111    0.5000    0.1818         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8500    0.6071    0.7083        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.8235    0.4667    0.5957        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8532       681
                    macro avg     0.9109    0.8529    0.8985       681
                 weighted avg     0.8757    0.8532    0.8551       681

2024-08-16 12:11:59.925 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8532
2024-08-16 12:11:59.928 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:11:59.928 | INFO     | __main__:eval:454 - Validation loss: 4.810776862231168
2024-08-16 12:11:59.937 | INFO     | __main__:train:256 - epochs: 8
2024-08-16 12:11:59.937 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568]
2024-08-16 12:11:59.937 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168]
2024-08-16 12:11:59.937 | INFO     | __main__:train:159 - ====epoch #9====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:58,  3.55s/it]
Training:   2%|▏         | 2/85 [00:06<04:49,  3.48s/it]
Training:   4%|▎         | 3/85 [00:10<04:43,  3.46s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.43s/it]
Training:   6%|▌         | 5/85 [00:17<04:33,  3.42s/it]
Training:   7%|▋         | 6/85 [00:20<04:29,  3.41s/it]
Training:   8%|▊         | 7/85 [00:23<04:25,  3.40s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.40s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.39s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.40s/it]
Training:  14%|█▍        | 12/85 [00:40<04:07,  3.39s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:54,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.38s/it]
Training:  24%|██▎       | 20/85 [01:08<03:39,  3.38s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.38s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.38s/it]
Training:  29%|██▉       | 25/85 [01:24<03:22,  3.38s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:41<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.39s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.38s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.38s/it]
Training:  45%|████▍     | 38/85 [02:08<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:25<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.39s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.38s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.38s/it]
Training:  60%|██████    | 51/85 [02:52<01:54,  3.38s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.37s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.38s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:44,  3.38s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.38s/it]
Training:  66%|██████▌   | 56/85 [03:09<01:38,  3.38s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.38s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.39s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.39s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.39s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:53<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.38s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.38s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.38s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.38s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:37<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 12:16:48.045 | INFO     | __main__:train:207 - Epoch 9 Average Loss: 4.34028
2024-08-16 12:16:48.756 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL9*****
2024-08-16 12:16:48.756 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:16:48.756 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.05it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.16it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.24it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.24it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.25it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.25it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.26it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 12:17:05.829 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9552    0.9275    0.9412        69
                     big_bird     0.9565    1.0000    0.9778        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     1.0000    0.0400    0.0769        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     0.8000    1.0000    0.8889         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7586    0.7097    0.7333        31
                          esm     0.8750    1.0000    0.9333         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm        nan    0.0000       nan         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     0.8333    1.0000    0.9091         5
                  mask2former     0.6667    1.0000    0.8000         8
                   maskformer     0.8333    1.0000    0.9091         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8421    0.9412    0.8889        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     1.0000    0.8571    0.9231         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.4681    0.8462    0.6027        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.0000    0.0000       nan         2
                         swin     1.0000    0.3333    0.5000         6
                           t5     0.9333    1.0000    0.9655        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1429    0.5000    0.2222         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8636    0.6786    0.7600        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.7368    0.4667    0.5714        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     1.0000    1.0000    1.0000         3

                     accuracy                         0.8546       681
                    macro avg     0.9138    0.8505    0.9004       681
                 weighted avg     0.8939    0.8546    0.8533       681

2024-08-16 12:17:05.829 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8546
2024-08-16 12:17:05.833 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:17:05.833 | INFO     | __main__:eval:454 - Validation loss: 4.797635511918501
2024-08-16 12:17:05.840 | INFO     | __main__:train:256 - epochs: 9
2024-08-16 12:17:05.840 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129]
2024-08-16 12:17:05.841 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501]
2024-08-16 12:17:05.841 | INFO     | __main__:train:159 - ====epoch #10====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:58,  3.55s/it]
Training:   2%|▏         | 2/85 [00:06<04:45,  3.45s/it]
Training:   4%|▎         | 3/85 [00:10<04:40,  3.42s/it]
Training:   5%|▍         | 4/85 [00:13<04:35,  3.40s/it]
Training:   6%|▌         | 5/85 [00:17<04:31,  3.40s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.39s/it]
Training:   8%|▊         | 7/85 [00:23<04:24,  3.39s/it]
Training:   9%|▉         | 8/85 [00:27<04:20,  3.39s/it]
Training:  11%|█         | 9/85 [00:30<04:17,  3.39s/it]
Training:  12%|█▏        | 10/85 [00:33<04:13,  3.38s/it]
Training:  13%|█▎        | 11/85 [00:37<04:10,  3.38s/it]
Training:  14%|█▍        | 12/85 [00:40<04:07,  3.38s/it]
Training:  15%|█▌        | 13/85 [00:44<04:03,  3.38s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.38s/it]
Training:  18%|█▊        | 15/85 [00:50<03:56,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.40s/it]
Training:  22%|██▏       | 19/85 [01:04<03:45,  3.41s/it]
Training:  24%|██▎       | 20/85 [01:07<03:41,  3.41s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.42s/it]
Training:  26%|██▌       | 22/85 [01:14<03:35,  3.42s/it]
Training:  27%|██▋       | 23/85 [01:18<03:31,  3.42s/it]
Training:  28%|██▊       | 24/85 [01:21<03:28,  3.42s/it]
Training:  29%|██▉       | 25/85 [01:25<03:25,  3.42s/it]
Training:  31%|███       | 26/85 [01:28<03:21,  3.42s/it]
Training:  32%|███▏      | 27/85 [01:31<03:18,  3.42s/it]
Training:  33%|███▎      | 28/85 [01:35<03:15,  3.43s/it]
Training:  34%|███▍      | 29/85 [01:38<03:11,  3.43s/it]
Training:  35%|███▌      | 30/85 [01:42<03:08,  3.42s/it]
Training:  36%|███▋      | 31/85 [01:45<03:04,  3.42s/it]
Training:  38%|███▊      | 32/85 [01:49<03:01,  3.42s/it]
Training:  39%|███▉      | 33/85 [01:52<02:58,  3.42s/it]
Training:  40%|████      | 34/85 [01:55<02:55,  3.44s/it]
Training:  41%|████      | 35/85 [01:59<02:52,  3.44s/it]
Training:  42%|████▏     | 36/85 [02:02<02:48,  3.44s/it]
Training:  44%|████▎     | 37/85 [02:06<02:44,  3.42s/it]
Training:  45%|████▍     | 38/85 [02:09<02:40,  3.41s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.41s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.40s/it]
Training:  49%|████▉     | 42/85 [02:23<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.38s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:14,  3.37s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:11,  3.38s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:08,  3.38s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.38s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.38s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:24<01:24,  3.39s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.39s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.39s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:07,  3.39s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.39s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.39s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.38s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.38s/it]
Training:  87%|████████▋ | 74/85 [04:11<00:37,  3.38s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.38s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.38s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:45<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.40s/it]
2024-08-16 12:21:54.557 | INFO     | __main__:train:207 - Epoch 10 Average Loss: 4.10500
2024-08-16 12:21:55.255 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL10*****
2024-08-16 12:21:55.255 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:21:55.255 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.04it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.17it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.21it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.26it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 12:22:12.314 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9552    0.9275    0.9412        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     1.0000    0.0400    0.0769        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.4286    0.9677    0.5941        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     0.7143    1.0000    0.8333         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    0.9130    0.9545        23
                       longt5     0.7500    1.0000    0.8571         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     0.8333    1.0000    0.9091         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    0.8000    0.8889         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8500    1.0000    0.9189        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     0.8000    1.0000    0.8889         4
                      roberta     0.6071    0.6538    0.6296        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5        nan    0.0000       nan         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9333    1.0000    0.9655        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder        nan    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8636    0.6786    0.7600        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.8750    0.4667    0.6087        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8561       681
                    macro avg     0.9222    0.8714    0.9030       681
                 weighted avg     0.9001    0.8561    0.8545       681

2024-08-16 12:22:12.315 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8561
2024-08-16 12:22:12.318 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:22:12.318 | INFO     | __main__:eval:454 - Validation loss: 4.8002578670328315
2024-08-16 12:22:12.325 | INFO     | __main__:train:256 - epochs: 10
2024-08-16 12:22:12.325 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975]
2024-08-16 12:22:12.325 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315]
2024-08-16 12:22:12.325 | INFO     | __main__:train:159 - ====epoch #11====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:57,  3.54s/it]
Training:   2%|▏         | 2/85 [00:06<04:47,  3.46s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.43s/it]
Training:   5%|▍         | 4/85 [00:13<04:36,  3.42s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.41s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.40s/it]
Training:   8%|▊         | 7/85 [00:23<04:24,  3.40s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.40s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.39s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.39s/it]
Training:  14%|█▍        | 12/85 [00:40<04:07,  3.39s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:49,  3.38s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.38s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:07<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:42,  3.48s/it]
Training:  26%|██▌       | 22/85 [01:15<03:37,  3.45s/it]
Training:  27%|██▋       | 23/85 [01:18<03:32,  3.43s/it]
Training:  28%|██▊       | 24/85 [01:21<03:28,  3.42s/it]
Training:  29%|██▉       | 25/85 [01:25<03:24,  3.40s/it]
Training:  31%|███       | 26/85 [01:28<03:20,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.38s/it]
Training:  35%|███▌      | 30/85 [01:42<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.39s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:59<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:45,  3.38s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.38s/it]
Training:  45%|████▍     | 38/85 [02:09<02:38,  3.38s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.39s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:11,  3.38s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.38s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.38s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.38s/it]
Training:  60%|██████    | 51/85 [02:53<01:54,  3.38s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.38s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.38s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:44,  3.38s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.38s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.38s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.39s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.39s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:10,  3.37s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.37s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.37s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.38s/it]
Training:  81%|████████  | 69/85 [03:53<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.37s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.38s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.39s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 12:27:00.537 | INFO     | __main__:train:207 - Epoch 11 Average Loss: 4.11071
2024-08-16 12:27:01.269 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL11*****
2024-08-16 12:27:01.269 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:27:01.269 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.00it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.14it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.19it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.24it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.25it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 12:27:18.339 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9143    0.9275    0.9209        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5000    0.3200    0.3902        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8077    0.6774    0.7368        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     0.8333    1.0000    0.9091         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     0.8333    1.0000    0.9091         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     1.0000    0.8571    0.9231         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.5000    0.7885    0.6119        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.9333    0.4667    0.6222        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.7500    1.0000    0.8571         3

                     accuracy                         0.8634       681
                    macro avg     0.9137    0.8750    0.9158       681
                 weighted avg     0.8879    0.8634    0.8767       681

2024-08-16 12:27:18.339 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8634
2024-08-16 12:27:18.342 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:27:18.343 | INFO     | __main__:eval:454 - Validation loss: 4.7950898083773525
2024-08-16 12:27:18.350 | INFO     | __main__:train:256 - epochs: 11
2024-08-16 12:27:18.351 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566]
2024-08-16 12:27:18.351 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525]
2024-08-16 12:27:18.351 | INFO     | __main__:train:159 - ====epoch #12====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:56,  3.53s/it]
Training:   2%|▏         | 2/85 [00:06<04:46,  3.45s/it]
Training:   4%|▎         | 3/85 [00:10<04:40,  3.42s/it]
Training:   5%|▍         | 4/85 [00:13<04:36,  3.41s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.40s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.40s/it]
Training:   8%|▊         | 7/85 [00:23<04:24,  3.40s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.39s/it]
Training:  11%|█         | 9/85 [00:30<04:17,  3.38s/it]
Training:  12%|█▏        | 10/85 [00:34<04:13,  3.38s/it]
Training:  13%|█▎        | 11/85 [00:37<04:09,  3.38s/it]
Training:  14%|█▍        | 12/85 [00:40<04:06,  3.38s/it]
Training:  15%|█▌        | 13/85 [00:44<04:02,  3.37s/it]
Training:  16%|█▋        | 14/85 [00:47<03:59,  3.38s/it]
Training:  18%|█▊        | 15/85 [00:50<03:56,  3.38s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.38s/it]
Training:  20%|██        | 17/85 [00:57<03:49,  3.38s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.38s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.38s/it]
Training:  24%|██▎       | 20/85 [01:07<03:39,  3.38s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.38s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.38s/it]
Training:  27%|██▋       | 23/85 [01:17<03:29,  3.38s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.38s/it]
Training:  29%|██▉       | 25/85 [01:24<03:22,  3.38s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.38s/it]
Training:  32%|███▏      | 27/85 [01:31<03:15,  3.38s/it]
Training:  33%|███▎      | 28/85 [01:34<03:12,  3.38s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.38s/it]
Training:  35%|███▌      | 30/85 [01:41<03:06,  3.38s/it]
Training:  36%|███▋      | 31/85 [01:44<03:02,  3.38s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.38s/it]
Training:  39%|███▉      | 33/85 [01:51<02:55,  3.38s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:01<02:45,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.38s/it]
Training:  45%|████▍     | 38/85 [02:08<02:38,  3.38s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.38s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:18<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:25<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:28<02:18,  3.39s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:35<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:45<02:02,  3.40s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:52<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:02<01:44,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:09<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.38s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:19<01:28,  3.39s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.39s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:29<01:17,  3.39s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:36<01:11,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:46<01:00,  3.39s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:53<00:54,  3.39s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.38s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:03<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.38s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.38s/it]
Training:  88%|████████▊ | 75/85 [04:13<00:33,  3.38s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.38s/it]
Training:  91%|█████████ | 77/85 [04:20<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:30<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:37<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.39s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:47<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:47<00:00,  3.39s/it]
2024-08-16 12:32:06.152 | INFO     | __main__:train:207 - Epoch 12 Average Loss: 4.21021
2024-08-16 12:32:06.878 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL12*****
2024-08-16 12:32:06.878 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:32:06.878 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.10it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:16,  1.19it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.22it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.27it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.27it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:11<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 12:32:23.873 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9552    0.9275    0.9412        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5556    0.4000    0.4651        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.6591    0.9355    0.7733        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     0.8333    1.0000    0.9091         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.5692    0.7115    0.6325        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    0.5000    0.6667         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     0.6000    0.7500    0.6667         4
                unispeech-sat     0.0000    0.0000       nan         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6667    0.9286    0.7761        28
                        wavlm     1.0000    0.0833    0.1538        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.9333    0.4667    0.6222        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8737       681
                    macro avg     0.9055    0.8728    0.9146       681
                 weighted avg     0.8916    0.8737    0.8744       681

2024-08-16 12:32:23.873 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8737
2024-08-16 12:32:23.877 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:32:23.877 | INFO     | __main__:eval:454 - Validation loss: 4.774518999186429
2024-08-16 12:32:23.884 | INFO     | __main__:train:256 - epochs: 12
2024-08-16 12:32:23.885 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595]
2024-08-16 12:32:23.885 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429]
2024-08-16 12:32:23.885 | INFO     | __main__:train:159 - ====epoch #13====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<05:01,  3.58s/it]
Training:   2%|▏         | 2/85 [00:07<04:50,  3.49s/it]
Training:   4%|▎         | 3/85 [00:10<04:43,  3.46s/it]
Training:   5%|▍         | 4/85 [00:13<04:39,  3.45s/it]
Training:   6%|▌         | 5/85 [00:17<04:34,  3.43s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.43s/it]
Training:   8%|▊         | 7/85 [00:24<04:26,  3.42s/it]
Training:   9%|▉         | 8/85 [00:27<04:23,  3.42s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.41s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.41s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:41<04:09,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:44<04:05,  3.41s/it]
Training:  16%|█▋        | 14/85 [00:47<04:02,  3.41s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.41s/it]
Training:  19%|█▉        | 16/85 [00:54<03:55,  3.41s/it]
Training:  20%|██        | 17/85 [00:58<03:51,  3.41s/it]
Training:  21%|██        | 18/85 [01:01<03:48,  3.41s/it]
Training:  22%|██▏       | 19/85 [01:04<03:44,  3.40s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.40s/it]
Training:  25%|██▍       | 21/85 [01:11<03:37,  3.40s/it]
Training:  26%|██▌       | 22/85 [01:15<03:34,  3.40s/it]
Training:  27%|██▋       | 23/85 [01:18<03:31,  3.41s/it]
Training:  28%|██▊       | 24/85 [01:22<03:27,  3.41s/it]
Training:  29%|██▉       | 25/85 [01:25<03:24,  3.41s/it]
Training:  31%|███       | 26/85 [01:28<03:20,  3.41s/it]
Training:  32%|███▏      | 27/85 [01:32<03:17,  3.41s/it]
Training:  33%|███▎      | 28/85 [01:35<03:14,  3.41s/it]
Training:  34%|███▍      | 29/85 [01:39<03:11,  3.42s/it]
Training:  35%|███▌      | 30/85 [01:42<03:08,  3.42s/it]
Training:  36%|███▋      | 31/85 [01:45<03:04,  3.42s/it]
Training:  38%|███▊      | 32/85 [01:49<03:01,  3.42s/it]
Training:  39%|███▉      | 33/85 [01:52<02:58,  3.43s/it]
Training:  40%|████      | 34/85 [01:56<02:54,  3.43s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.42s/it]
Training:  42%|████▏     | 36/85 [02:03<02:47,  3.42s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.41s/it]
Training:  45%|████▍     | 38/85 [02:09<02:40,  3.40s/it]
Training:  46%|████▌     | 39/85 [02:13<02:36,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.41s/it]
Training:  48%|████▊     | 41/85 [02:20<02:29,  3.41s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.41s/it]
Training:  51%|█████     | 43/85 [02:26<02:23,  3.41s/it]
Training:  52%|█████▏    | 44/85 [02:30<02:19,  3.41s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.41s/it]
Training:  54%|█████▍    | 46/85 [02:37<02:12,  3.40s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.41s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.40s/it]
Training:  58%|█████▊    | 49/85 [02:47<02:02,  3.40s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:54<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:57<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.40s/it]
Training:  64%|██████▎   | 54/85 [03:04<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:41,  3.40s/it]
Training:  66%|██████▌   | 56/85 [03:11<01:38,  3.40s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.40s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.40s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.40s/it]
Training:  71%|███████   | 60/85 [03:24<01:25,  3.40s/it]
Training:  72%|███████▏  | 61/85 [03:28<01:21,  3.40s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.41s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.41s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:11,  3.41s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:08,  3.41s/it]
Training:  78%|███████▊  | 66/85 [03:45<01:04,  3.41s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:01,  3.41s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.41s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.41s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:51,  3.41s/it]
Training:  84%|████████▎ | 71/85 [04:02<00:47,  3.40s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.40s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.40s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:19<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:29<00:20,  3.38s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:16,  3.38s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.37s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.37s/it]
Training:  99%|█████████▉| 84/85 [04:46<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.41s/it]
2024-08-16 12:37:13.386 | INFO     | __main__:train:207 - Epoch 13 Average Loss: 4.16130
2024-08-16 12:37:14.102 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL13*****
2024-08-16 12:37:14.102 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:37:14.102 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:01<00:24,  1.19s/it]
Evaluating:   9%|▉         | 2/22 [00:01<00:19,  1.05it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:16,  1.14it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:15,  1.18it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:14,  1.21it/s]
Evaluating:  27%|██▋       | 6/22 [00:05<00:13,  1.23it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.24it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:09<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:13<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.28it/s]
2024-08-16 12:37:31.298 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9836    0.8696    0.9231        69
                     big_bird     0.9565    1.0000    0.9778        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5556    0.4000    0.4651        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    0.9615    0.9804        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     0.9714    0.9714    0.9714        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7667    0.7419    0.7541        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     0.6667    1.0000    0.8000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     1.0000    0.6667    0.8000         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     0.6667    1.0000    0.8000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.4675    0.6923    0.5581        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.6667    1.0000    0.8000         2
                         swin     1.0000    0.3333    0.5000         6
                           t5     0.9231    0.8571    0.8889        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.2000    0.5000    0.2857         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.6522    0.5000    0.5660        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8488       681
                    macro avg     0.9067    0.8668    0.9051       681
                 weighted avg     0.8740    0.8488    0.8641       681

2024-08-16 12:37:31.299 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8488
2024-08-16 12:37:31.303 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:37:31.303 | INFO     | __main__:eval:454 - Validation loss: 4.921102285385132
2024-08-16 12:37:31.309 | INFO     | __main__:train:256 - epochs: 13
2024-08-16 12:37:31.309 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305]
2024-08-16 12:37:31.309 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132]
2024-08-16 12:37:31.310 | INFO     | __main__:train:159 - ====epoch #14====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:57,  3.54s/it]
Training:   2%|▏         | 2/85 [00:06<04:46,  3.45s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.43s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.44s/it]
Training:   6%|▌         | 5/85 [00:17<04:34,  3.43s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.42s/it]
Training:   8%|▊         | 7/85 [00:23<04:26,  3.41s/it]
Training:   9%|▉         | 8/85 [00:27<04:22,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.41s/it]
Training:  12%|█▏        | 10/85 [00:34<04:16,  3.42s/it]
Training:  13%|█▎        | 11/85 [00:37<04:13,  3.42s/it]
Training:  14%|█▍        | 12/85 [00:41<04:09,  3.42s/it]
Training:  15%|█▌        | 13/85 [00:44<04:05,  3.42s/it]
Training:  16%|█▋        | 14/85 [00:47<04:02,  3.42s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.41s/it]
Training:  19%|█▉        | 16/85 [00:54<03:55,  3.41s/it]
Training:  20%|██        | 17/85 [00:58<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.40s/it]
Training:  22%|██▏       | 19/85 [01:04<03:44,  3.40s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.40s/it]
Training:  25%|██▍       | 21/85 [01:11<03:37,  3.40s/it]
Training:  26%|██▌       | 22/85 [01:15<03:34,  3.40s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.40s/it]
Training:  28%|██▊       | 24/85 [01:21<03:27,  3.40s/it]
Training:  29%|██▉       | 25/85 [01:25<03:24,  3.41s/it]
Training:  31%|███       | 26/85 [01:28<03:21,  3.41s/it]
Training:  32%|███▏      | 27/85 [01:32<03:17,  3.41s/it]
Training:  33%|███▎      | 28/85 [01:35<03:14,  3.41s/it]
Training:  34%|███▍      | 29/85 [01:38<03:10,  3.41s/it]
Training:  35%|███▌      | 30/85 [01:42<03:07,  3.41s/it]
Training:  36%|███▋      | 31/85 [01:45<03:03,  3.40s/it]
Training:  38%|███▊      | 32/85 [01:49<03:00,  3.40s/it]
Training:  39%|███▉      | 33/85 [01:52<02:57,  3.41s/it]
Training:  40%|████      | 34/85 [01:55<02:53,  3.41s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.41s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.40s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.40s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.40s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.40s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.40s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.40s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.40s/it]
Training:  51%|█████     | 43/85 [02:26<02:23,  3.41s/it]
Training:  52%|█████▏    | 44/85 [02:30<02:19,  3.41s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.40s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.40s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.40s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.40s/it]
Training:  58%|█████▊    | 49/85 [02:47<02:02,  3.40s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:59,  3.41s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.40s/it]
Training:  61%|██████    | 52/85 [02:57<01:52,  3.40s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:49,  3.41s/it]
Training:  64%|██████▎   | 54/85 [03:04<01:45,  3.41s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:42,  3.41s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.41s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.40s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.40s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.41s/it]
Training:  71%|███████   | 60/85 [03:24<01:25,  3.41s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.40s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.40s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.40s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:11,  3.40s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:08,  3.40s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.40s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:01,  3.40s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.40s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.40s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:50,  3.40s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.40s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.40s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.40s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.38s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:45<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.40s/it]
2024-08-16 12:42:20.605 | INFO     | __main__:train:207 - Epoch 14 Average Loss: 4.06833
2024-08-16 12:42:21.321 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL14*****
2024-08-16 12:42:21.321 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:42:21.321 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.09it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:16,  1.19it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.22it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.24it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.25it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.26it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.26it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:11<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.27it/s]
2024-08-16 12:42:38.703 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9697    0.9275    0.9481        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.4167    0.2000    0.2703        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.6765    0.7419    0.7077        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     0.6667    1.0000    0.8000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.4625    0.7115    0.5606        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     1.0000    0.5000    0.6667         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9231    0.8571    0.8889        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8261    0.6786    0.7451        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.8235    0.4667    0.5957        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8590       681
                    macro avg     0.9096    0.8803    0.9081       681
                 weighted avg     0.8788    0.8590    0.8633       681

2024-08-16 12:42:38.704 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.859
2024-08-16 12:42:38.713 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:42:38.713 | INFO     | __main__:eval:454 - Validation loss: 4.804804574359547
2024-08-16 12:42:38.721 | INFO     | __main__:train:256 - epochs: 14
2024-08-16 12:42:38.721 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548]
2024-08-16 12:42:38.721 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547]
2024-08-16 12:42:38.722 | INFO     | __main__:train:159 - ====epoch #15====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:59,  3.56s/it]
Training:   2%|▏         | 2/85 [00:07<04:50,  3.50s/it]
Training:   4%|▎         | 3/85 [00:10<04:44,  3.47s/it]
Training:   5%|▍         | 4/85 [00:13<04:39,  3.45s/it]
Training:   6%|▌         | 5/85 [00:17<04:35,  3.44s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.42s/it]
Training:   8%|▊         | 7/85 [00:24<04:26,  3.42s/it]
Training:   9%|▉         | 8/85 [00:27<04:22,  3.41s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.41s/it]
Training:  12%|█▏        | 10/85 [00:34<04:16,  3.42s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.42s/it]
Training:  14%|█▍        | 12/85 [00:41<04:09,  3.42s/it]
Training:  15%|█▌        | 13/85 [00:44<04:06,  3.42s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.41s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.40s/it]
Training:  19%|█▉        | 16/85 [00:54<03:54,  3.40s/it]
Training:  20%|██        | 17/85 [00:58<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:08<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:15<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.39s/it]
Training:  29%|██▉       | 25/85 [01:25<03:23,  3.39s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:32<03:16,  3.38s/it]
Training:  33%|███▎      | 28/85 [01:35<03:12,  3.38s/it]
Training:  34%|███▍      | 29/85 [01:38<03:08,  3.37s/it]
Training:  35%|███▌      | 30/85 [01:42<03:05,  3.38s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.38s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.38s/it]
Training:  39%|███▉      | 33/85 [01:52<02:55,  3.38s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.38s/it]
Training:  41%|████      | 35/85 [01:59<02:49,  3.38s/it]
Training:  42%|████▏     | 36/85 [02:02<02:45,  3.38s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.38s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.39s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:11,  3.38s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.38s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.38s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.38s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:44,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.38s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.38s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.39s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.40s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.39s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.39s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:18,  3.40s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.40s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.40s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.40s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.40s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:01,  3.40s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.40s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.40s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.40s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.40s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:44,  3.40s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.40s/it]
Training:  87%|████████▋ | 74/85 [04:11<00:37,  3.40s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.40s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.40s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.39s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.39s/it]
Training:  99%|█████████▉| 84/85 [04:45<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.40s/it]
2024-08-16 12:47:27.396 | INFO     | __main__:train:207 - Epoch 15 Average Loss: 4.02722
2024-08-16 12:47:28.103 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL15*****
2024-08-16 12:47:28.103 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:47:28.103 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.05it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.16it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.27it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 12:47:45.099 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9412    0.9275    0.9343        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.4118    0.5600    0.4746        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7419    0.7419    0.7419        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     1.0000    1.0000    1.0000         3
                     gpt_neox     0.5000    0.5000    0.5000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    0.8000    0.8889         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8500    1.0000    0.9189        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     0.8000    1.0000    0.8889         4
                      roberta     0.6066    0.7115    0.6549        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.8571    0.8571    0.8571        14
                    unispeech     0.5000    0.5000    0.5000         4
                unispeech-sat     0.0000    0.0000       nan         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8261    0.6786    0.7451        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.7778    0.4667    0.5833        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.7500    1.0000    0.8571         3

                     accuracy                         0.8693       681
                    macro avg     0.8996    0.8721    0.9201       681
                 weighted avg     0.8836    0.8693    0.8790       681

2024-08-16 12:47:45.100 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8693
2024-08-16 12:47:45.108 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:47:45.108 | INFO     | __main__:eval:454 - Validation loss: 4.804324041713368
2024-08-16 12:47:45.114 | INFO     | __main__:train:256 - epochs: 15
2024-08-16 12:47:45.114 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797]
2024-08-16 12:47:45.114 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368]
2024-08-16 12:47:45.115 | INFO     | __main__:train:159 - ====epoch #16====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:59,  3.57s/it]
Training:   2%|▏         | 2/85 [00:06<04:48,  3.48s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.44s/it]
Training:   5%|▍         | 4/85 [00:13<04:37,  3.42s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.41s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.40s/it]
Training:   8%|▊         | 7/85 [00:23<04:25,  3.40s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.40s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.40s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.40s/it]
Training:  14%|█▍        | 12/85 [00:40<04:08,  3.40s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.40s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.40s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.40s/it]
Training:  19%|█▉        | 16/85 [00:54<03:54,  3.40s/it]
Training:  20%|██        | 17/85 [00:57<03:51,  3.40s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:08<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:37,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:29,  3.38s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.38s/it]
Training:  29%|██▉       | 25/85 [01:24<03:23,  3.38s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:41<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.40s/it]
Training:  40%|████      | 34/85 [01:55<02:53,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.39s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:28,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:25<02:22,  3.38s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.38s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:44,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.38s/it]
Training:  66%|██████▌   | 56/85 [03:09<01:37,  3.38s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.38s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.37s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.37s/it]
Training:  81%|████████  | 69/85 [03:53<00:53,  3.37s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.38s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.38s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.37s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.38s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.38s/it]
Training:  91%|█████████ | 77/85 [04:20<00:27,  3.38s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.37s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.37s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:37<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:47<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 12:52:33.143 | INFO     | __main__:train:207 - Epoch 16 Average Loss: 4.17514
2024-08-16 12:52:33.842 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL16*****
2024-08-16 12:52:33.842 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:52:33.842 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.07it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:16,  1.18it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.22it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.25it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.26it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.27it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.27it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:11<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 12:52:50.799 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9412    0.9275    0.9343        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5000    0.4000    0.4444        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8333    0.6452    0.7273        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    0.8750    0.9333         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.5068    0.7115    0.5920        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     0.8571    1.0000    0.9231         6
                           t5     0.9231    0.8571    0.8889        14
                    unispeech     0.6000    0.7500    0.6667         4
                unispeech-sat     0.0000    0.0000       nan         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8261    0.6786    0.7451        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.6250    0.5000    0.5556        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8634       681
                    macro avg     0.8979    0.8804    0.9226       681
                 weighted avg     0.8762    0.8634    0.8719       681

2024-08-16 12:52:50.799 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8634
2024-08-16 12:52:50.808 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:52:50.808 | INFO     | __main__:eval:454 - Validation loss: 4.759243715893138
2024-08-16 12:52:50.813 | INFO     | __main__:train:256 - epochs: 16
2024-08-16 12:52:50.813 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732]
2024-08-16 12:52:50.813 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138]
2024-08-16 12:52:50.813 | INFO     | __main__:train:159 - ====epoch #17====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:58,  3.55s/it]
Training:   2%|▏         | 2/85 [00:06<04:46,  3.45s/it]
Training:   4%|▎         | 3/85 [00:10<04:40,  3.42s/it]
Training:   5%|▍         | 4/85 [00:13<04:36,  3.41s/it]
Training:   6%|▌         | 5/85 [00:17<04:31,  3.39s/it]
Training:   7%|▋         | 6/85 [00:20<04:27,  3.39s/it]
Training:   8%|▊         | 7/85 [00:23<04:23,  3.38s/it]
Training:   9%|▉         | 8/85 [00:27<04:20,  3.38s/it]
Training:  11%|█         | 9/85 [00:30<04:16,  3.38s/it]
Training:  12%|█▏        | 10/85 [00:33<04:13,  3.38s/it]
Training:  13%|█▎        | 11/85 [00:37<04:10,  3.38s/it]
Training:  14%|█▍        | 12/85 [00:40<04:06,  3.38s/it]
Training:  15%|█▌        | 13/85 [00:44<04:03,  3.38s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.38s/it]
Training:  18%|█▊        | 15/85 [00:50<03:56,  3.38s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.38s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.38s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:07<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:17<03:29,  3.38s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.38s/it]
Training:  29%|██▉       | 25/85 [01:24<03:23,  3.38s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.38s/it]
Training:  33%|███▎      | 28/85 [01:34<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:41<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.38s/it]
Training:  39%|███▉      | 33/85 [01:51<02:55,  3.38s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.38s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.38s/it]
Training:  42%|████▏     | 36/85 [02:01<02:45,  3.38s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.38s/it]
Training:  45%|████▍     | 38/85 [02:08<02:38,  3.38s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.37s/it]
Training:  47%|████▋     | 40/85 [02:15<02:31,  3.38s/it]
Training:  48%|████▊     | 41/85 [02:18<02:28,  3.38s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.38s/it]
Training:  51%|█████     | 43/85 [02:25<02:21,  3.38s/it]
Training:  52%|█████▏    | 44/85 [02:28<02:18,  3.38s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.38s/it]
Training:  54%|█████▍    | 46/85 [02:35<02:11,  3.38s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.37s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:04,  3.38s/it]
Training:  58%|█████▊    | 49/85 [02:45<02:01,  3.38s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.37s/it]
Training:  60%|██████    | 51/85 [02:52<01:54,  3.38s/it]
Training:  61%|██████    | 52/85 [02:55<01:51,  3.38s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.38s/it]
Training:  64%|██████▎   | 54/85 [03:02<01:44,  3.38s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.38s/it]
Training:  66%|██████▌   | 56/85 [03:09<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:12<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.39s/it]
Training:  69%|██████▉   | 59/85 [03:19<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.37s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:29<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:36<01:10,  3.37s/it]
Training:  76%|███████▋  | 65/85 [03:39<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:46<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.38s/it]
Training:  81%|████████  | 69/85 [03:53<00:54,  3.39s/it]
Training:  82%|████████▏ | 70/85 [03:56<00:50,  3.39s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.39s/it]
Training:  85%|████████▍ | 72/85 [04:03<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.38s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:13<00:34,  3.43s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.42s/it]
Training:  91%|█████████ | 77/85 [04:20<00:27,  3.41s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.40s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.40s/it]
Training:  94%|█████████▍| 80/85 [04:30<00:16,  3.40s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:37<00:10,  3.39s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.39s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:47<00:00,  3.39s/it]
Training: 100%|██████████| 85/85 [04:47<00:00,  3.39s/it]
2024-08-16 12:57:38.687 | INFO     | __main__:train:207 - Epoch 17 Average Loss: 4.08543
2024-08-16 12:57:39.382 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL17*****
2024-08-16 12:57:39.383 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 12:57:39.383 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.05it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.17it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.21it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.29it/s]
2024-08-16 12:57:56.395 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9697    0.9275    0.9481        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5556    0.4000    0.4651        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     0.8000    1.0000    0.8889         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.5636    1.0000    0.7209        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.6667    0.6667    0.6667         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    0.8750    0.9333         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6415    0.6538    0.6476        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     0.8571    1.0000    0.9231         6
                           t5     0.9231    0.8571    0.8889        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm     1.0000    0.0833    0.1538        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     1.0000    0.5667    0.7234        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8722       681
                    macro avg     0.9104    0.8739    0.9011       681
                 weighted avg     0.8977    0.8722    0.8723       681

2024-08-16 12:57:56.395 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8722
2024-08-16 12:57:56.399 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 12:57:56.399 | INFO     | __main__:eval:454 - Validation loss: 4.764866026965055
2024-08-16 12:57:56.408 | INFO     | __main__:train:256 - epochs: 17
2024-08-16 12:57:56.408 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029]
2024-08-16 12:57:56.408 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055]
2024-08-16 12:57:56.408 | INFO     | __main__:train:159 - ====epoch #18====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:58,  3.55s/it]
Training:   2%|▏         | 2/85 [00:06<04:48,  3.47s/it]
Training:   4%|▎         | 3/85 [00:10<04:42,  3.44s/it]
Training:   5%|▍         | 4/85 [00:13<04:37,  3.42s/it]
Training:   6%|▌         | 5/85 [00:17<04:33,  3.42s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.42s/it]
Training:   8%|▊         | 7/85 [00:24<04:27,  3.43s/it]
Training:   9%|▉         | 8/85 [00:27<04:23,  3.42s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.42s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.41s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:41<04:09,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.40s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.40s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.40s/it]
Training:  19%|█▉        | 16/85 [00:54<03:54,  3.39s/it]
Training:  20%|██        | 17/85 [00:58<03:51,  3.41s/it]
Training:  21%|██        | 18/85 [01:01<03:49,  3.42s/it]
Training:  22%|██▏       | 19/85 [01:04<03:45,  3.42s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.41s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.42s/it]
Training:  26%|██▌       | 22/85 [01:15<03:34,  3.41s/it]
Training:  27%|██▋       | 23/85 [01:18<03:31,  3.41s/it]
Training:  28%|██▊       | 24/85 [01:22<03:28,  3.42s/it]
Training:  29%|██▉       | 25/85 [01:25<03:24,  3.42s/it]
Training:  31%|███       | 26/85 [01:28<03:21,  3.41s/it]
Training:  32%|███▏      | 27/85 [01:32<03:18,  3.41s/it]
Training:  33%|███▎      | 28/85 [01:35<03:14,  3.42s/it]
Training:  34%|███▍      | 29/85 [01:39<03:11,  3.41s/it]
Training:  35%|███▌      | 30/85 [01:42<03:07,  3.41s/it]
Training:  36%|███▋      | 31/85 [01:45<03:04,  3.41s/it]
Training:  38%|███▊      | 32/85 [01:49<03:00,  3.41s/it]
Training:  39%|███▉      | 33/85 [01:52<02:57,  3.41s/it]
Training:  40%|████      | 34/85 [01:56<02:54,  3.41s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.41s/it]
Training:  42%|████▏     | 36/85 [02:02<02:47,  3.42s/it]
Training:  44%|████▎     | 37/85 [02:06<02:44,  3.42s/it]
Training:  45%|████▍     | 38/85 [02:09<02:40,  3.41s/it]
Training:  46%|████▌     | 39/85 [02:13<02:37,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.42s/it]
Training:  48%|████▊     | 41/85 [02:20<02:30,  3.42s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.41s/it]
Training:  51%|█████     | 43/85 [02:26<02:23,  3.42s/it]
Training:  52%|█████▏    | 44/85 [02:30<02:20,  3.42s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.42s/it]
Training:  54%|█████▍    | 46/85 [02:37<02:13,  3.42s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.41s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:05,  3.41s/it]
Training:  58%|█████▊    | 49/85 [02:47<02:02,  3.40s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:59,  3.41s/it]
Training:  60%|██████    | 51/85 [02:54<01:55,  3.41s/it]
Training:  61%|██████    | 52/85 [02:57<01:52,  3.41s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.40s/it]
Training:  64%|██████▎   | 54/85 [03:04<01:45,  3.40s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:41,  3.40s/it]
Training:  66%|██████▌   | 56/85 [03:11<01:38,  3.40s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.41s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.40s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.40s/it]
Training:  71%|███████   | 60/85 [03:24<01:25,  3.40s/it]
Training:  72%|███████▏  | 61/85 [03:28<01:21,  3.41s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.41s/it]
Training:  74%|███████▍  | 63/85 [03:35<01:15,  3.41s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:11,  3.41s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:08,  3.41s/it]
Training:  78%|███████▊  | 66/85 [03:45<01:04,  3.41s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:01,  3.41s/it]
Training:  80%|████████  | 68/85 [03:52<00:58,  3.42s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.42s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:51,  3.42s/it]
Training:  84%|████████▎ | 71/85 [04:02<00:47,  3.42s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.41s/it]
Training:  86%|████████▌ | 73/85 [04:09<00:40,  3.41s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.40s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:33,  3.40s/it]
Training:  89%|████████▉ | 76/85 [04:19<00:30,  3.40s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.41s/it]
Training:  92%|█████████▏| 78/85 [04:26<00:23,  3.41s/it]
Training:  93%|█████████▎| 79/85 [04:29<00:20,  3.41s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:17,  3.41s/it]
Training:  95%|█████████▌| 81/85 [04:36<00:13,  3.42s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.42s/it]
Training:  98%|█████████▊| 83/85 [04:43<00:06,  3.42s/it]
Training:  99%|█████████▉| 84/85 [04:46<00:03,  3.42s/it]
Training: 100%|██████████| 85/85 [04:50<00:00,  3.42s/it]
Training: 100%|██████████| 85/85 [04:50<00:00,  3.41s/it]
2024-08-16 13:02:46.595 | INFO     | __main__:train:207 - Epoch 18 Average Loss: 4.13689
2024-08-16 13:02:47.300 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL18*****
2024-08-16 13:02:47.300 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:02:47.300 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.06it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.16it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.24it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.25it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.25it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.26it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 13:03:04.370 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9412    0.9275    0.9343        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5217    0.4800    0.5000        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8182    0.8710    0.8438        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.9444    1.0000    0.9714        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.5342    0.7500    0.6240        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9231    0.8571    0.8889        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8261    0.6786    0.7451        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.9333    0.4667    0.6222        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8781       681
                    macro avg     0.9148    0.8865    0.9161       681
                 weighted avg     0.8996    0.8781    0.8848       681

2024-08-16 13:03:04.371 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8781
2024-08-16 13:03:04.379 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:03:04.379 | INFO     | __main__:eval:454 - Validation loss: 4.741184115409851
2024-08-16 13:03:04.388 | INFO     | __main__:train:256 - epochs: 18
2024-08-16 13:03:04.390 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866]
2024-08-16 13:03:04.390 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851]
2024-08-16 13:03:04.390 | INFO     | __main__:train:159 - ====epoch #19====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:59,  3.57s/it]
Training:   2%|▏         | 2/85 [00:06<04:47,  3.47s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.44s/it]
Training:   5%|▍         | 4/85 [00:13<04:37,  3.42s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.41s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.42s/it]
Training:   8%|▊         | 7/85 [00:24<04:26,  3.42s/it]
Training:   9%|▉         | 8/85 [00:27<04:22,  3.41s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.41s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.41s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.39s/it]
Training:  14%|█▍        | 12/85 [00:40<04:07,  3.39s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:08<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.38s/it]
Training:  29%|██▉       | 25/85 [01:24<03:22,  3.38s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.38s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.38s/it]
Training:  33%|███▎      | 28/85 [01:35<03:12,  3.38s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.38s/it]
Training:  35%|███▌      | 30/85 [01:41<03:05,  3.38s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.38s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.38s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.39s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.39s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:28,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:25<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:19,  3.39s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:09,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:53<01:54,  3.38s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.38s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:09<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.39s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.39s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.39s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.39s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:18,  3.39s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.39s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.39s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.39s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.39s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.37s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 13:07:52.631 | INFO     | __main__:train:207 - Epoch 19 Average Loss: 4.01685
2024-08-16 13:07:53.321 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL19*****
2024-08-16 13:07:53.321 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:07:53.321 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.10it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:16,  1.19it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.22it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 13:08:10.320 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9412    0.9275    0.9343        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5000    0.6800    0.5763        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8485    0.9032    0.8750        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     1.0000    1.0000    1.0000         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6349    0.7692    0.6957        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     0.6000    0.7500    0.6667         4
                unispeech-sat     0.0000    0.0000       nan         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8636    0.6786    0.7600        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     1.0000    0.4000    0.5714        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8884       681
                    macro avg     0.9115    0.8900    0.9335       681
                 weighted avg     0.9074    0.8884    0.8959       681

2024-08-16 13:08:10.321 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8884
2024-08-16 13:08:10.324 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:08:10.324 | INFO     | __main__:eval:454 - Validation loss: 4.769154245203191
2024-08-16 13:08:10.333 | INFO     | __main__:train:256 - epochs: 19
2024-08-16 13:08:10.333 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629]
2024-08-16 13:08:10.333 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191]
2024-08-16 13:08:10.333 | INFO     | __main__:train:159 - ====epoch #20====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:59,  3.56s/it]
Training:   2%|▏         | 2/85 [00:06<04:48,  3.48s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.44s/it]
Training:   5%|▍         | 4/85 [00:13<04:37,  3.43s/it]
Training:   6%|▌         | 5/85 [00:17<04:33,  3.42s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.40s/it]
Training:   8%|▊         | 7/85 [00:23<04:24,  3.39s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.40s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.40s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.40s/it]
Training:  14%|█▍        | 12/85 [00:40<04:08,  3.40s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.40s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.40s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:54,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:44,  3.40s/it]
Training:  24%|██▎       | 20/85 [01:08<03:40,  3.40s/it]
Training:  25%|██▍       | 21/85 [01:11<03:37,  3.40s/it]
Training:  26%|██▌       | 22/85 [01:14<03:34,  3.40s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.40s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.39s/it]
Training:  29%|██▉       | 25/85 [01:25<03:23,  3.39s/it]
Training:  31%|███       | 26/85 [01:28<03:20,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:42<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.39s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:45,  3.38s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.38s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.38s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:25<02:21,  3.38s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.38s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.38s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:44,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.38s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.38s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.39s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.39s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.39s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.39s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.39s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.38s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.38s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.38s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.38s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.39s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 13:12:58.558 | INFO     | __main__:train:207 - Epoch 20 Average Loss: 4.15996
2024-08-16 13:12:59.254 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL20*****
2024-08-16 13:12:59.254 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:12:59.254 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.02it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.15it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.19it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 13:13:16.303 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.8421    0.9275    0.8828        69
                     big_bird     0.9565    1.0000    0.9778        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5000    0.4400    0.4681        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8387    0.8387    0.8387        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     1.0000    1.0000    1.0000         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     0.8889    1.0000    0.9412         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8500    1.0000    0.9189        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.5909    0.7500    0.6610        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    0.8333    0.9091         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8636    0.6786    0.7600        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.9333    0.4667    0.6222        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8752       681
                    macro avg     0.9148    0.8841    0.9149       681
                 weighted avg     0.8916    0.8752    0.8795       681

2024-08-16 13:13:16.303 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8752
2024-08-16 13:13:16.308 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:13:16.308 | INFO     | __main__:eval:454 - Validation loss: 4.8135000467300415
2024-08-16 13:13:16.314 | INFO     | __main__:train:256 - epochs: 20
2024-08-16 13:13:16.315 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655]
2024-08-16 13:13:16.315 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415]
2024-08-16 13:13:16.315 | INFO     | __main__:train:159 - ====epoch #21====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:59,  3.57s/it]
Training:   2%|▏         | 2/85 [00:06<04:47,  3.47s/it]
Training:   4%|▎         | 3/85 [00:10<04:41,  3.43s/it]
Training:   5%|▍         | 4/85 [00:13<04:36,  3.42s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.41s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.40s/it]
Training:   8%|▊         | 7/85 [00:23<04:24,  3.40s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.39s/it]
Training:  11%|█         | 9/85 [00:30<04:18,  3.40s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.40s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.39s/it]
Training:  14%|█▍        | 12/85 [00:40<04:07,  3.39s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:07<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:29,  3.38s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.39s/it]
Training:  29%|██▉       | 25/85 [01:24<03:23,  3.38s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:41<03:05,  3.38s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.38s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:52<02:56,  3.39s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:48,  3.38s/it]
Training:  42%|████▏     | 36/85 [02:02<02:45,  3.38s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.38s/it]
Training:  45%|████▍     | 38/85 [02:08<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.38s/it]
Training:  48%|████▊     | 41/85 [02:19<02:28,  3.38s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:25<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.39s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:07,  3.44s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:03,  3.42s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:59,  3.41s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.40s/it]
Training:  61%|██████    | 52/85 [02:56<01:52,  3.40s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.39s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.39s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.39s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.39s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.39s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:44,  3.39s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.39s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 13:18:04.625 | INFO     | __main__:train:207 - Epoch 21 Average Loss: 4.03818
2024-08-16 13:18:05.322 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL21*****
2024-08-16 13:18:05.322 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:18:05.322 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.06it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.17it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.21it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.24it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.25it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.25it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.65it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 13:18:22.343 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9412    0.9275    0.9343        69
                     big_bird     0.9565    1.0000    0.9778        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.4828    0.5600    0.5185        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7647    0.8387    0.8000        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     1.0000    1.0000    1.0000         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8500    1.0000    0.9189        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6094    0.7500    0.6724        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.9333    0.4667    0.6222        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8767       681
                    macro avg     0.9189    0.8800    0.9220       681
                 weighted avg     0.8977    0.8767    0.8914       681

2024-08-16 13:18:22.343 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8767
2024-08-16 13:18:22.347 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:18:22.347 | INFO     | __main__:eval:454 - Validation loss: 4.7602174932306465
2024-08-16 13:18:22.352 | INFO     | __main__:train:256 - epochs: 21
2024-08-16 13:18:22.353 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794]
2024-08-16 13:18:22.353 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465]
2024-08-16 13:18:22.353 | INFO     | __main__:train:159 - ====epoch #22====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:57,  3.54s/it]
Training:   2%|▏         | 2/85 [00:06<04:46,  3.45s/it]
Training:   4%|▎         | 3/85 [00:10<04:40,  3.42s/it]
Training:   5%|▍         | 4/85 [00:13<04:36,  3.41s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.40s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.40s/it]
Training:   8%|▊         | 7/85 [00:23<04:24,  3.39s/it]
Training:   9%|▉         | 8/85 [00:27<04:20,  3.38s/it]
Training:  11%|█         | 9/85 [00:30<04:17,  3.38s/it]
Training:  12%|█▏        | 10/85 [00:33<04:13,  3.38s/it]
Training:  13%|█▎        | 11/85 [00:37<04:10,  3.38s/it]
Training:  14%|█▍        | 12/85 [00:40<04:06,  3.38s/it]
Training:  15%|█▌        | 13/85 [00:44<04:03,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:50<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:07<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:37,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.38s/it]
Training:  29%|██▉       | 25/85 [01:24<03:23,  3.39s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.38s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:34<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:41<03:06,  3.38s/it]
Training:  36%|███▋      | 31/85 [01:45<03:03,  3.39s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.39s/it]
Training:  39%|███▉      | 33/85 [01:51<02:56,  3.39s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:43,  3.40s/it]
Training:  45%|████▍     | 38/85 [02:08<02:39,  3.40s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.40s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:25<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.39s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.39s/it]
Training:  54%|█████▍    | 46/85 [02:35<02:12,  3.39s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.39s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:52<01:54,  3.38s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.38s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:09<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.38s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.39s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:36<01:11,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.39s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.39s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.39s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:53<00:54,  3.39s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.39s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.39s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:44,  3.39s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.38s/it]
Training:  91%|█████████ | 77/85 [04:20<00:27,  3.38s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.38s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.38s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:37<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 13:23:10.418 | INFO     | __main__:train:207 - Epoch 22 Average Loss: 3.99751
2024-08-16 13:23:11.115 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL22*****
2024-08-16 13:23:11.115 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:23:11.115 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.05it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.17it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.21it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.26it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.27it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:11<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 13:23:28.115 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9412    0.9275    0.9343        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.4643    0.5200    0.4906        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    0.9231    0.9600        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7941    0.8710    0.8308        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     0.5000    1.0000    0.6667         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6154    0.7692    0.6838        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     1.0000    0.4667    0.6364        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8752       681
                    macro avg     0.9093    0.8791    0.9147       681
                 weighted avg     0.8996    0.8752    0.8902       681

2024-08-16 13:23:28.116 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8752
2024-08-16 13:23:28.121 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:23:28.121 | INFO     | __main__:eval:454 - Validation loss: 4.762599728324196
2024-08-16 13:23:28.131 | INFO     | __main__:train:256 - epochs: 22
2024-08-16 13:23:28.132 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249]
2024-08-16 13:23:28.132 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196]
2024-08-16 13:23:28.132 | INFO     | __main__:train:159 - ====epoch #23====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<05:00,  3.57s/it]
Training:   2%|▏         | 2/85 [00:07<04:49,  3.49s/it]
Training:   4%|▎         | 3/85 [00:10<04:43,  3.46s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.44s/it]
Training:   6%|▌         | 5/85 [00:17<04:33,  3.42s/it]
Training:   7%|▋         | 6/85 [00:20<04:29,  3.41s/it]
Training:   8%|▊         | 7/85 [00:24<04:26,  3.42s/it]
Training:   9%|▉         | 8/85 [00:27<04:23,  3.42s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.42s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.41s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:41<04:08,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:44<04:06,  3.42s/it]
Training:  16%|█▋        | 14/85 [00:47<04:02,  3.42s/it]
Training:  18%|█▊        | 15/85 [00:51<03:59,  3.42s/it]
Training:  19%|█▉        | 16/85 [00:54<03:56,  3.42s/it]
Training:  20%|██        | 17/85 [00:58<03:52,  3.42s/it]
Training:  21%|██        | 18/85 [01:01<03:49,  3.42s/it]
Training:  22%|██▏       | 19/85 [01:05<03:45,  3.42s/it]
Training:  24%|██▎       | 20/85 [01:08<03:42,  3.42s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.42s/it]
Training:  26%|██▌       | 22/85 [01:15<03:35,  3.43s/it]
Training:  27%|██▋       | 23/85 [01:18<03:32,  3.42s/it]
Training:  28%|██▊       | 24/85 [01:22<03:28,  3.42s/it]
Training:  29%|██▉       | 25/85 [01:25<03:25,  3.42s/it]
Training:  31%|███       | 26/85 [01:29<03:21,  3.42s/it]
Training:  32%|███▏      | 27/85 [01:32<03:18,  3.42s/it]
Training:  33%|███▎      | 28/85 [01:35<03:15,  3.44s/it]
Training:  34%|███▍      | 29/85 [01:39<03:12,  3.44s/it]
Training:  35%|███▌      | 30/85 [01:42<03:09,  3.44s/it]
Training:  36%|███▋      | 31/85 [01:46<03:05,  3.43s/it]
Training:  38%|███▊      | 32/85 [01:49<03:01,  3.42s/it]
Training:  39%|███▉      | 33/85 [01:53<02:57,  3.42s/it]
Training:  40%|████      | 34/85 [01:56<02:54,  3.41s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.42s/it]
Training:  42%|████▏     | 36/85 [02:03<02:47,  3.42s/it]
Training:  44%|████▎     | 37/85 [02:06<02:44,  3.42s/it]
Training:  45%|████▍     | 38/85 [02:10<02:40,  3.41s/it]
Training:  46%|████▌     | 39/85 [02:13<02:36,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.41s/it]
Training:  48%|████▊     | 41/85 [02:20<02:29,  3.41s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.40s/it]
Training:  51%|█████     | 43/85 [02:27<02:23,  3.41s/it]
Training:  52%|█████▏    | 44/85 [02:30<02:19,  3.40s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.41s/it]
Training:  54%|█████▍    | 46/85 [02:37<02:12,  3.40s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.40s/it]
Training:  56%|█████▋    | 48/85 [02:44<02:06,  3.41s/it]
Training:  58%|█████▊    | 49/85 [02:47<02:02,  3.41s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:59,  3.41s/it]
Training:  60%|██████    | 51/85 [02:54<01:56,  3.41s/it]
Training:  61%|██████    | 52/85 [02:57<01:52,  3.41s/it]
Training:  62%|██████▏   | 53/85 [03:01<01:49,  3.41s/it]
Training:  64%|██████▎   | 54/85 [03:04<01:45,  3.41s/it]
Training:  65%|██████▍   | 55/85 [03:08<01:42,  3.41s/it]
Training:  66%|██████▌   | 56/85 [03:11<01:39,  3.42s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.42s/it]
Training:  68%|██████▊   | 58/85 [03:18<01:32,  3.42s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.42s/it]
Training:  71%|███████   | 60/85 [03:25<01:25,  3.42s/it]
Training:  72%|███████▏  | 61/85 [03:28<01:21,  3.42s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.42s/it]
Training:  74%|███████▍  | 63/85 [03:35<01:15,  3.42s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:11,  3.42s/it]
Training:  76%|███████▋  | 65/85 [03:42<01:08,  3.42s/it]
Training:  78%|███████▊  | 66/85 [03:45<01:04,  3.42s/it]
Training:  79%|███████▉  | 67/85 [03:49<01:01,  3.42s/it]
Training:  80%|████████  | 68/85 [03:52<00:57,  3.41s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.40s/it]
Training:  82%|████████▏ | 70/85 [03:59<00:51,  3.41s/it]
Training:  84%|████████▎ | 71/85 [04:02<00:47,  3.41s/it]
Training:  85%|████████▍ | 72/85 [04:06<00:44,  3.41s/it]
Training:  86%|████████▌ | 73/85 [04:09<00:40,  3.41s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.41s/it]
Training:  88%|████████▊ | 75/85 [04:16<00:34,  3.41s/it]
Training:  89%|████████▉ | 76/85 [04:19<00:30,  3.41s/it]
Training:  91%|█████████ | 77/85 [04:23<00:27,  3.41s/it]
Training:  92%|█████████▏| 78/85 [04:26<00:23,  3.41s/it]
Training:  93%|█████████▎| 79/85 [04:29<00:20,  3.41s/it]
Training:  94%|█████████▍| 80/85 [04:33<00:17,  3.41s/it]
Training:  95%|█████████▌| 81/85 [04:36<00:13,  3.41s/it]
Training:  96%|█████████▋| 82/85 [04:40<00:10,  3.41s/it]
Training:  98%|█████████▊| 83/85 [04:43<00:06,  3.40s/it]
Training:  99%|█████████▉| 84/85 [04:46<00:03,  3.41s/it]
Training: 100%|██████████| 85/85 [04:50<00:00,  3.41s/it]
Training: 100%|██████████| 85/85 [04:50<00:00,  3.42s/it]
2024-08-16 13:28:18.562 | INFO     | __main__:train:207 - Epoch 23 Average Loss: 3.99952
2024-08-16 13:28:19.287 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL23*****
2024-08-16 13:28:19.287 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:28:19.287 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.09it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:16,  1.18it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.22it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.65it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 13:28:36.286 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9275    0.9275    0.9275        69
                     big_bird     0.9565    1.0000    0.9778        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.4783    0.4400    0.4583        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    0.9615    0.9804        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7368    0.9032    0.8116        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     1.0000    1.0000    1.0000         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     0.6667    1.0000    0.8000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8500    1.0000    0.9189        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6094    0.7500    0.6724        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.9375    0.5000    0.6522        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8752       681
                    macro avg     0.9135    0.8792    0.9183       681
                 weighted avg     0.8940    0.8752    0.8889       681

2024-08-16 13:28:36.286 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8752
2024-08-16 13:28:36.290 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:28:36.291 | INFO     | __main__:eval:454 - Validation loss: 4.751052715561607
2024-08-16 13:28:36.300 | INFO     | __main__:train:256 - epochs: 23
2024-08-16 13:28:36.301 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724]
2024-08-16 13:28:36.301 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607]
2024-08-16 13:28:36.301 | INFO     | __main__:train:159 - ====epoch #24====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:57,  3.54s/it]
Training:   2%|▏         | 2/85 [00:06<04:49,  3.49s/it]
Training:   4%|▎         | 3/85 [00:10<04:42,  3.45s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.43s/it]
Training:   6%|▌         | 5/85 [00:17<04:34,  3.43s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.43s/it]
Training:   8%|▊         | 7/85 [00:24<04:27,  3.43s/it]
Training:   9%|▉         | 8/85 [00:27<04:23,  3.42s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.42s/it]
Training:  12%|█▏        | 10/85 [00:34<04:16,  3.42s/it]
Training:  13%|█▎        | 11/85 [00:37<04:12,  3.41s/it]
Training:  14%|█▍        | 12/85 [00:41<04:08,  3.41s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.40s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.40s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.40s/it]
Training:  19%|█▉        | 16/85 [00:54<03:55,  3.41s/it]
Training:  20%|██        | 17/85 [00:58<03:52,  3.41s/it]
Training:  21%|██        | 18/85 [01:01<03:48,  3.42s/it]
Training:  22%|██▏       | 19/85 [01:04<03:45,  3.42s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.41s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.41s/it]
Training:  26%|██▌       | 22/85 [01:15<03:35,  3.41s/it]
Training:  27%|██▋       | 23/85 [01:18<03:37,  3.50s/it]
Training:  28%|██▊       | 24/85 [01:22<03:32,  3.48s/it]
Training:  29%|██▉       | 25/85 [01:25<03:27,  3.46s/it]
Training:  31%|███       | 26/85 [01:29<03:23,  3.45s/it]
Training:  32%|███▏      | 27/85 [01:32<03:19,  3.44s/it]
Training:  33%|███▎      | 28/85 [01:36<03:15,  3.43s/it]
Training:  34%|███▍      | 29/85 [01:39<03:11,  3.42s/it]
Training:  35%|███▌      | 30/85 [01:42<03:08,  3.43s/it]
Training:  36%|███▋      | 31/85 [01:46<03:04,  3.42s/it]
Training:  38%|███▊      | 32/85 [01:49<03:01,  3.42s/it]
Training:  39%|███▉      | 33/85 [01:53<02:57,  3.42s/it]
Training:  40%|████      | 34/85 [01:56<02:54,  3.42s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.42s/it]
Training:  42%|████▏     | 36/85 [02:03<02:46,  3.41s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.41s/it]
Training:  45%|████▍     | 38/85 [02:10<02:39,  3.40s/it]
Training:  46%|████▌     | 39/85 [02:13<02:36,  3.40s/it]
Training:  47%|████▋     | 40/85 [02:16<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:20<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.40s/it]
Training:  51%|█████     | 43/85 [02:27<02:22,  3.40s/it]
Training:  52%|█████▏    | 44/85 [02:30<02:19,  3.40s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.40s/it]
Training:  54%|█████▍    | 46/85 [02:37<02:12,  3.40s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.40s/it]
Training:  56%|█████▋    | 48/85 [02:44<02:05,  3.40s/it]
Training:  58%|█████▊    | 49/85 [02:47<02:02,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:54<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:57<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [03:01<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:04<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:41,  3.40s/it]
Training:  66%|██████▌   | 56/85 [03:11<01:38,  3.40s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.40s/it]
Training:  68%|██████▊   | 58/85 [03:18<01:31,  3.39s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.39s/it]
Training:  71%|███████   | 60/85 [03:24<01:24,  3.39s/it]
Training:  72%|███████▏  | 61/85 [03:28<01:21,  3.40s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.40s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:11,  3.39s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:07,  3.40s/it]
Training:  78%|███████▊  | 66/85 [03:45<01:04,  3.40s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:01,  3.40s/it]
Training:  80%|████████  | 68/85 [03:52<00:57,  3.40s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.40s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:50,  3.40s/it]
Training:  84%|████████▎ | 71/85 [04:02<00:47,  3.39s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.40s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:19<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:29<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:36<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.39s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.39s/it]
Training:  99%|█████████▉| 84/85 [04:46<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.39s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.41s/it]
2024-08-16 13:33:25.993 | INFO     | __main__:train:207 - Epoch 24 Average Loss: 4.02102
2024-08-16 13:33:26.708 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL24*****
2024-08-16 13:33:26.708 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:33:26.708 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.02it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.16it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.27it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.27it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.27it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.65it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 13:33:43.666 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9143    0.9275    0.9209        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5263    0.4000    0.4545        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    0.9615    0.9804        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8485    0.9032    0.8750        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     0.6667    1.0000    0.8000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8500    1.0000    0.9189        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.5972    0.8269    0.6935        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8636    0.6786    0.7600        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     1.0000    0.5333    0.6957        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8855       681
                    macro avg     0.9113    0.8883    0.9146       681
                 weighted avg     0.9045    0.8855    0.8905       681

2024-08-16 13:33:43.666 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8855
2024-08-16 13:33:43.669 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:33:43.669 | INFO     | __main__:eval:454 - Validation loss: 4.769751689650795
2024-08-16 13:33:43.678 | INFO     | __main__:train:256 - epochs: 24
2024-08-16 13:33:43.678 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724, 4.021023601644179]
2024-08-16 13:33:43.678 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607, 4.769751689650795]
2024-08-16 13:33:43.678 | INFO     | __main__:train:159 - ====epoch #25====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:56,  3.53s/it]
Training:   2%|▏         | 2/85 [00:06<04:48,  3.48s/it]
Training:   4%|▎         | 3/85 [00:10<04:43,  3.45s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.44s/it]
Training:   6%|▌         | 5/85 [00:17<04:34,  3.43s/it]
Training:   7%|▋         | 6/85 [00:20<04:31,  3.43s/it]
Training:   8%|▊         | 7/85 [00:24<04:27,  3.43s/it]
Training:   9%|▉         | 8/85 [00:27<04:23,  3.43s/it]
Training:  11%|█         | 9/85 [00:30<04:20,  3.42s/it]
Training:  12%|█▏        | 10/85 [00:34<04:16,  3.42s/it]
Training:  13%|█▎        | 11/85 [00:37<04:13,  3.42s/it]
Training:  14%|█▍        | 12/85 [00:41<04:09,  3.42s/it]
Training:  15%|█▌        | 13/85 [00:44<04:06,  3.42s/it]
Training:  16%|█▋        | 14/85 [00:48<04:02,  3.42s/it]
Training:  18%|█▊        | 15/85 [00:51<03:59,  3.41s/it]
Training:  19%|█▉        | 16/85 [00:54<03:55,  3.41s/it]
Training:  20%|██        | 17/85 [00:58<03:51,  3.41s/it]
Training:  21%|██        | 18/85 [01:01<03:48,  3.41s/it]
Training:  22%|██▏       | 19/85 [01:05<03:44,  3.41s/it]
Training:  24%|██▎       | 20/85 [01:08<03:41,  3.41s/it]
Training:  25%|██▍       | 21/85 [01:11<03:37,  3.40s/it]
Training:  26%|██▌       | 22/85 [01:15<03:34,  3.41s/it]
Training:  27%|██▋       | 23/85 [01:18<03:31,  3.41s/it]
Training:  28%|██▊       | 24/85 [01:22<03:28,  3.41s/it]
Training:  29%|██▉       | 25/85 [01:25<03:24,  3.41s/it]
Training:  31%|███       | 26/85 [01:28<03:21,  3.41s/it]
Training:  32%|███▏      | 27/85 [01:32<03:18,  3.41s/it]
Training:  33%|███▎      | 28/85 [01:35<03:14,  3.41s/it]
Training:  34%|███▍      | 29/85 [01:39<03:11,  3.42s/it]
Training:  35%|███▌      | 30/85 [01:42<03:07,  3.42s/it]
Training:  36%|███▋      | 31/85 [01:46<03:04,  3.42s/it]
Training:  38%|███▊      | 32/85 [01:49<03:00,  3.41s/it]
Training:  39%|███▉      | 33/85 [01:52<02:57,  3.41s/it]
Training:  40%|████      | 34/85 [01:56<02:53,  3.41s/it]
Training:  41%|████      | 35/85 [01:59<02:50,  3.41s/it]
Training:  42%|████▏     | 36/85 [02:03<02:47,  3.41s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.41s/it]
Training:  45%|████▍     | 38/85 [02:09<02:40,  3.41s/it]
Training:  46%|████▌     | 39/85 [02:13<02:36,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.40s/it]
Training:  48%|████▊     | 41/85 [02:20<02:30,  3.42s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.41s/it]
Training:  51%|█████     | 43/85 [02:26<02:23,  3.42s/it]
Training:  52%|█████▏    | 44/85 [02:30<02:20,  3.42s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:16,  3.42s/it]
Training:  54%|█████▍    | 46/85 [02:37<02:13,  3.42s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.42s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:06,  3.41s/it]
Training:  58%|█████▊    | 49/85 [02:47<02:02,  3.41s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:59,  3.42s/it]
Training:  60%|██████    | 51/85 [02:54<01:56,  3.42s/it]
Training:  61%|██████    | 52/85 [02:57<01:52,  3.42s/it]
Training:  62%|██████▏   | 53/85 [03:01<01:49,  3.42s/it]
Training:  64%|██████▎   | 54/85 [03:04<01:45,  3.42s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:42,  3.41s/it]
Training:  66%|██████▌   | 56/85 [03:11<01:38,  3.41s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:35,  3.41s/it]
Training:  68%|██████▊   | 58/85 [03:18<01:32,  3.42s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.42s/it]
Training:  71%|███████   | 60/85 [03:24<01:25,  3.40s/it]
Training:  72%|███████▏  | 61/85 [03:28<01:21,  3.40s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:18,  3.39s/it]
Training:  74%|███████▍  | 63/85 [03:35<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:11,  3.39s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:07,  3.39s/it]
Training:  78%|███████▊  | 66/85 [03:45<01:04,  3.39s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:00,  3.39s/it]
Training:  80%|████████  | 68/85 [03:52<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.39s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:50,  3.39s/it]
Training:  84%|████████▎ | 71/85 [04:02<00:47,  3.39s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:44,  3.39s/it]
Training:  86%|████████▌ | 73/85 [04:09<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:19<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:29<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:36<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.39s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:46<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.37s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.41s/it]
2024-08-16 13:38:33.309 | INFO     | __main__:train:207 - Epoch 25 Average Loss: 3.91654
2024-08-16 13:38:34.024 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL25*****
2024-08-16 13:38:34.024 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:38:34.024 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.04it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.15it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.27it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 13:38:51.027 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9412    0.9275    0.9343        69
                     big_bird     0.9565    1.0000    0.9778        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5000    0.4000    0.4444        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    0.9231    0.9600        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7297    0.8710    0.7941        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     1.0000    1.0000    1.0000         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     0.5000    1.0000    0.6667         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8500    1.0000    0.9189        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.5821    0.7500    0.6555        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8636    0.6786    0.7600        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.8889    0.5333    0.6667        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8767       681
                    macro avg     0.9084    0.8862    0.9120       681
                 weighted avg     0.8939    0.8767    0.8823       681

2024-08-16 13:38:51.028 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8767
2024-08-16 13:38:51.042 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:38:51.042 | INFO     | __main__:eval:454 - Validation loss: 4.739060575311834
2024-08-16 13:38:51.049 | INFO     | __main__:train:256 - epochs: 25
2024-08-16 13:38:51.050 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724, 4.021023601644179, 3.916540437586167]
2024-08-16 13:38:51.050 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607, 4.769751689650795, 4.739060575311834]
2024-08-16 13:38:51.050 | INFO     | __main__:train:159 - ====epoch #26====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<05:00,  3.58s/it]
Training:   2%|▏         | 2/85 [00:07<04:50,  3.50s/it]
Training:   4%|▎         | 3/85 [00:10<04:43,  3.46s/it]
Training:   5%|▍         | 4/85 [00:13<04:39,  3.45s/it]
Training:   6%|▌         | 5/85 [00:17<04:34,  3.44s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.43s/it]
Training:   8%|▊         | 7/85 [00:24<04:27,  3.43s/it]
Training:   9%|▉         | 8/85 [00:27<04:23,  3.42s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.42s/it]
Training:  12%|█▏        | 10/85 [00:34<04:16,  3.42s/it]
Training:  13%|█▎        | 11/85 [00:37<04:13,  3.42s/it]
Training:  14%|█▍        | 12/85 [00:41<04:09,  3.42s/it]
Training:  15%|█▌        | 13/85 [00:44<04:05,  3.41s/it]
Training:  16%|█▋        | 14/85 [00:48<04:02,  3.41s/it]
Training:  18%|█▊        | 15/85 [00:51<03:58,  3.41s/it]
Training:  19%|█▉        | 16/85 [00:54<03:55,  3.42s/it]
Training:  20%|██        | 17/85 [00:58<03:52,  3.42s/it]
Training:  21%|██        | 18/85 [01:01<03:49,  3.42s/it]
Training:  22%|██▏       | 19/85 [01:05<03:44,  3.41s/it]
Training:  24%|██▎       | 20/85 [01:08<03:42,  3.42s/it]
Training:  25%|██▍       | 21/85 [01:11<03:38,  3.42s/it]
Training:  26%|██▌       | 22/85 [01:15<03:35,  3.42s/it]
Training:  27%|██▋       | 23/85 [01:18<03:32,  3.43s/it]
Training:  28%|██▊       | 24/85 [01:22<03:28,  3.42s/it]
Training:  29%|██▉       | 25/85 [01:25<03:25,  3.43s/it]
Training:  31%|███       | 26/85 [01:29<03:22,  3.43s/it]
Training:  32%|███▏      | 27/85 [01:32<03:18,  3.42s/it]
Training:  33%|███▎      | 28/85 [01:35<03:15,  3.43s/it]
Training:  34%|███▍      | 29/85 [01:39<03:11,  3.43s/it]
Training:  35%|███▌      | 30/85 [01:42<03:08,  3.43s/it]
Training:  36%|███▋      | 31/85 [01:46<03:05,  3.43s/it]
Training:  38%|███▊      | 32/85 [01:49<03:01,  3.42s/it]
Training:  39%|███▉      | 33/85 [01:53<02:57,  3.42s/it]
Training:  40%|████      | 34/85 [01:56<02:54,  3.42s/it]
Training:  41%|████      | 35/85 [01:59<02:51,  3.42s/it]
Training:  42%|████▏     | 36/85 [02:03<02:47,  3.41s/it]
Training:  44%|████▎     | 37/85 [02:06<02:43,  3.41s/it]
Training:  45%|████▍     | 38/85 [02:10<02:40,  3.42s/it]
Training:  46%|████▌     | 39/85 [02:13<02:37,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:16<02:33,  3.42s/it]
Training:  48%|████▊     | 41/85 [02:20<02:30,  3.42s/it]
Training:  49%|████▉     | 42/85 [02:23<02:26,  3.41s/it]
Training:  51%|█████     | 43/85 [02:27<02:23,  3.41s/it]
Training:  52%|█████▏    | 44/85 [02:30<02:19,  3.41s/it]
Training:  53%|█████▎    | 45/85 [02:33<02:15,  3.40s/it]
Training:  54%|█████▍    | 46/85 [02:37<02:12,  3.40s/it]
Training:  55%|█████▌    | 47/85 [02:40<02:09,  3.40s/it]
Training:  56%|█████▋    | 48/85 [02:44<02:05,  3.40s/it]
Training:  58%|█████▊    | 49/85 [02:47<02:02,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:50<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:54<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:57<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [03:01<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:04<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:07<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:11<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:14<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:18<01:31,  3.39s/it]
Training:  69%|██████▉   | 59/85 [03:21<01:28,  3.39s/it]
Training:  71%|███████   | 60/85 [03:24<01:24,  3.39s/it]
Training:  72%|███████▏  | 61/85 [03:28<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:31<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:38<01:10,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:41<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:45<01:04,  3.39s/it]
Training:  79%|███████▉  | 67/85 [03:48<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.38s/it]
Training:  81%|████████  | 69/85 [03:55<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:58<00:50,  3.39s/it]
Training:  84%|████████▎ | 71/85 [04:02<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:05<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:12<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:15<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:22<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:29<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:32<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:39<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:46<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:49<00:00,  3.41s/it]
2024-08-16 13:43:40.515 | INFO     | __main__:train:207 - Epoch 26 Average Loss: 3.84640
2024-08-16 13:43:41.223 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL26*****
2024-08-16 13:43:41.223 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:43:41.223 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.09it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:16,  1.18it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.21it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.25it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 13:43:58.221 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9275    0.9275    0.9275        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5185    0.5600    0.5385        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8125    0.8387    0.8254        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6061    0.7692    0.6780        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     0.5000    0.5000    0.5000         4
                unispeech-sat     0.0000    0.0000       nan         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8636    0.6786    0.7600        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     1.0000    0.5000    0.6667        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8840       681
                    macro avg     0.9057    0.8854    0.9287       681
                 weighted avg     0.9011    0.8840    0.8928       681

2024-08-16 13:43:58.221 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.884
2024-08-16 13:43:58.226 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:43:58.226 | INFO     | __main__:eval:454 - Validation loss: 4.747467355294661
2024-08-16 13:43:58.232 | INFO     | __main__:train:256 - epochs: 26
2024-08-16 13:43:58.233 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724, 4.021023601644179, 3.916540437586167, 3.8463964476304895]
2024-08-16 13:43:58.233 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607, 4.769751689650795, 4.739060575311834, 4.747467355294661]
2024-08-16 13:43:58.233 | INFO     | __main__:train:159 - ====epoch #27====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:57,  3.54s/it]
Training:   2%|▏         | 2/85 [00:06<04:46,  3.46s/it]
Training:   4%|▎         | 3/85 [00:10<04:40,  3.42s/it]
Training:   5%|▍         | 4/85 [00:13<04:35,  3.41s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.40s/it]
Training:   7%|▋         | 6/85 [00:20<04:28,  3.40s/it]
Training:   8%|▊         | 7/85 [00:23<04:24,  3.39s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.39s/it]
Training:  11%|█         | 9/85 [00:30<04:17,  3.39s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.39s/it]
Training:  13%|█▎        | 11/85 [00:37<04:10,  3.39s/it]
Training:  14%|█▍        | 12/85 [00:40<04:06,  3.38s/it]
Training:  15%|█▌        | 13/85 [00:44<04:03,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:50<03:56,  3.38s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.39s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.38s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.38s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.38s/it]
Training:  24%|██▎       | 20/85 [01:07<03:39,  3.38s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.38s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.38s/it]
Training:  27%|██▋       | 23/85 [01:18<03:29,  3.38s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.39s/it]
Training:  29%|██▉       | 25/85 [01:24<03:23,  3.39s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.38s/it]
Training:  32%|███▏      | 27/85 [01:31<03:15,  3.38s/it]
Training:  33%|███▎      | 28/85 [01:34<03:12,  3.38s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.38s/it]
Training:  35%|███▌      | 30/85 [01:41<03:05,  3.37s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.38s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.38s/it]
Training:  39%|███▉      | 33/85 [01:51<02:56,  3.39s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:01<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.39s/it]
Training:  45%|████▍     | 38/85 [02:08<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.39s/it]
Training:  48%|████▊     | 41/85 [02:18<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:29,  3.47s/it]
Training:  51%|█████     | 43/85 [02:25<02:24,  3.44s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:20,  3.43s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:16,  3.42s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:12,  3.41s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:09,  3.40s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:02,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:53<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.38s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.39s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.39s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.39s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.39s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:01,  3.39s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.39s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.40s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:51,  3.41s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.41s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:44,  3.41s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.40s/it]
Training:  87%|████████▋ | 74/85 [04:11<00:37,  3.40s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.40s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.40s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.40s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.40s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.39s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.39s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 13:48:46.698 | INFO     | __main__:train:207 - Epoch 27 Average Loss: 3.88034
2024-08-16 13:48:47.415 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL27*****
2024-08-16 13:48:47.415 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:48:47.415 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.05it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.15it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.25it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.26it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.26it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.26it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.26it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 13:49:04.463 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9412    0.9275    0.9343        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.5000    0.4000    0.4444        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8182    0.8710    0.8438        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.5694    0.7885    0.6613        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.8636    0.6786    0.7600        28
                        wavlm     0.5556    0.8333    0.6667        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.8750    0.4667    0.6087        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8796       681
                    macro avg     0.9129    0.8869    0.9153       681
                 weighted avg     0.8972    0.8796    0.8845       681

2024-08-16 13:49:04.463 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8796
2024-08-16 13:49:04.475 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:49:04.475 | INFO     | __main__:eval:454 - Validation loss: 4.742271553386342
2024-08-16 13:49:04.484 | INFO     | __main__:train:256 - epochs: 27
2024-08-16 13:49:04.484 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724, 4.021023601644179, 3.916540437586167, 3.8463964476304895, 3.880342351689058]
2024-08-16 13:49:04.484 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607, 4.769751689650795, 4.739060575311834, 4.747467355294661, 4.742271553386342]
2024-08-16 13:49:04.484 | INFO     | __main__:train:159 - ====epoch #28====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:58,  3.55s/it]
Training:   2%|▏         | 2/85 [00:06<04:48,  3.47s/it]
Training:   4%|▎         | 3/85 [00:10<04:42,  3.45s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.44s/it]
Training:   6%|▌         | 5/85 [00:17<04:34,  3.43s/it]
Training:   7%|▋         | 6/85 [00:20<04:29,  3.42s/it]
Training:   8%|▊         | 7/85 [00:24<04:25,  3.41s/it]
Training:   9%|▉         | 8/85 [00:27<04:21,  3.40s/it]
Training:  11%|█         | 9/85 [00:30<04:17,  3.39s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.39s/it]
Training:  13%|█▎        | 11/85 [00:37<04:10,  3.39s/it]
Training:  14%|█▍        | 12/85 [00:40<04:06,  3.38s/it]
Training:  15%|█▌        | 13/85 [00:44<04:03,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.38s/it]
Training:  18%|█▊        | 15/85 [00:51<03:56,  3.38s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.38s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:08<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:29,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.38s/it]
Training:  29%|██▉       | 25/85 [01:24<03:23,  3.39s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.39s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.38s/it]
Training:  33%|███▎      | 28/85 [01:35<03:12,  3.38s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:41<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.38s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.38s/it]
Training:  39%|███▉      | 33/85 [01:52<02:55,  3.38s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.38s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.38s/it]
Training:  42%|████▏     | 36/85 [02:02<02:45,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.39s/it]
Training:  45%|████▍     | 38/85 [02:08<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.39s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.38s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:25<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.39s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.38s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:11,  3.38s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.38s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.38s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:52<01:55,  3.39s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.39s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.39s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.39s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:09<01:38,  3.39s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.37s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:36<01:10,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.38s/it]
Training:  81%|████████  | 69/85 [03:53<00:53,  3.37s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.38s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:03<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.38s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.38s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.38s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.38s/it]
Training:  91%|█████████ | 77/85 [04:20<00:27,  3.38s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.39s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.38s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.38s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.38s/it]
Training:  96%|█████████▋| 82/85 [04:37<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.38s/it]
Training: 100%|██████████| 85/85 [04:47<00:00,  3.38s/it]
Training: 100%|██████████| 85/85 [04:47<00:00,  3.39s/it]
2024-08-16 13:53:52.447 | INFO     | __main__:train:207 - Epoch 28 Average Loss: 4.08204
2024-08-16 13:53:53.166 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL28*****
2024-08-16 13:53:53.167 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:53:53.167 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.05it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.17it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.21it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.23it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.26it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.27it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.27it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.27it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:11<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.27it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.27it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.65it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.30it/s]
2024-08-16 13:54:10.183 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.8767    0.9275    0.9014        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.3462    0.3600    0.3529        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8000    0.9032    0.8485        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6393    0.7500    0.6903        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     1.0000    0.4667    0.6364        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8722       681
                    macro avg     0.9144    0.8781    0.9181       681
                 weighted avg     0.8921    0.8722    0.8855       681

2024-08-16 13:54:10.183 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8722
2024-08-16 13:54:10.207 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:54:10.208 | INFO     | __main__:eval:454 - Validation loss: 4.746249567378651
2024-08-16 13:54:10.214 | INFO     | __main__:train:256 - epochs: 28
2024-08-16 13:54:10.215 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724, 4.021023601644179, 3.916540437586167, 3.8463964476304895, 3.880342351689058, 4.082041246750776]
2024-08-16 13:54:10.215 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607, 4.769751689650795, 4.739060575311834, 4.747467355294661, 4.742271553386342, 4.746249567378651]
2024-08-16 13:54:10.215 | INFO     | __main__:train:159 - ====epoch #29====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:58,  3.55s/it]
Training:   2%|▏         | 2/85 [00:06<04:48,  3.48s/it]
Training:   4%|▎         | 3/85 [00:10<04:43,  3.46s/it]
Training:   5%|▍         | 4/85 [00:13<04:38,  3.44s/it]
Training:   6%|▌         | 5/85 [00:17<04:34,  3.44s/it]
Training:   7%|▋         | 6/85 [00:20<04:30,  3.43s/it]
Training:   8%|▊         | 7/85 [00:24<04:27,  3.43s/it]
Training:   9%|▉         | 8/85 [00:27<04:23,  3.43s/it]
Training:  11%|█         | 9/85 [00:30<04:19,  3.41s/it]
Training:  12%|█▏        | 10/85 [00:34<04:15,  3.41s/it]
Training:  13%|█▎        | 11/85 [00:37<04:11,  3.40s/it]
Training:  14%|█▍        | 12/85 [00:41<04:08,  3.40s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.40s/it]
Training:  16%|█▋        | 14/85 [00:47<04:01,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:54,  3.40s/it]
Training:  20%|██        | 17/85 [00:58<03:50,  3.39s/it]
Training:  21%|██        | 18/85 [01:01<03:47,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:44,  3.40s/it]
Training:  24%|██▎       | 20/85 [01:08<03:40,  3.40s/it]
Training:  25%|██▍       | 21/85 [01:11<03:37,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:15<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.39s/it]
Training:  29%|██▉       | 25/85 [01:25<03:23,  3.39s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.38s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.38s/it]
Training:  33%|███▎      | 28/85 [01:35<03:12,  3.38s/it]
Training:  34%|███▍      | 29/85 [01:38<03:08,  3.37s/it]
Training:  35%|███▌      | 30/85 [01:42<03:05,  3.38s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.38s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.38s/it]
Training:  39%|███▉      | 33/85 [01:52<02:55,  3.38s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.38s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:45,  3.38s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.38s/it]
Training:  45%|████▍     | 38/85 [02:09<02:39,  3.38s/it]
Training:  46%|████▌     | 39/85 [02:12<02:35,  3.38s/it]
Training:  47%|████▋     | 40/85 [02:15<02:32,  3.38s/it]
Training:  48%|████▊     | 41/85 [02:19<02:29,  3.39s/it]
Training:  49%|████▉     | 42/85 [02:22<02:25,  3.39s/it]
Training:  51%|█████     | 43/85 [02:26<02:22,  3.39s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:18,  3.38s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:15,  3.38s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:11,  3.38s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:08,  3.38s/it]
Training:  56%|█████▋    | 48/85 [02:42<02:05,  3.39s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:01,  3.39s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:58,  3.39s/it]
Training:  60%|██████    | 51/85 [02:53<01:54,  3.38s/it]
Training:  61%|██████    | 52/85 [02:56<01:51,  3.38s/it]
Training:  62%|██████▏   | 53/85 [02:59<01:48,  3.38s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:44,  3.38s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.39s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.38s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:34,  3.39s/it]
Training:  68%|██████▊   | 58/85 [03:16<01:31,  3.38s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:27,  3.38s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.38s/it]
Training:  72%|███████▏  | 61/85 [03:26<01:21,  3.38s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:17,  3.38s/it]
Training:  74%|███████▍  | 63/85 [03:33<01:14,  3.38s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:10,  3.38s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:07,  3.38s/it]
Training:  78%|███████▊  | 66/85 [03:43<01:04,  3.38s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:00,  3.38s/it]
Training:  80%|████████  | 68/85 [03:50<00:57,  3.38s/it]
Training:  81%|████████  | 69/85 [03:53<00:54,  3.38s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.38s/it]
Training:  84%|████████▎ | 71/85 [04:00<00:47,  3.38s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:43,  3.38s/it]
Training:  86%|████████▌ | 73/85 [04:07<00:40,  3.38s/it]
Training:  87%|████████▋ | 74/85 [04:10<00:37,  3.38s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:17<00:30,  3.39s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.39s/it]
Training:  92%|█████████▏| 78/85 [04:24<00:23,  3.38s/it]
Training:  93%|█████████▎| 79/85 [04:27<00:20,  3.38s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.38s/it]
Training:  95%|█████████▌| 81/85 [04:34<00:13,  3.37s/it]
Training:  96%|█████████▋| 82/85 [04:37<00:10,  3.38s/it]
Training:  98%|█████████▊| 83/85 [04:41<00:06,  3.38s/it]
Training:  99%|█████████▉| 84/85 [04:44<00:03,  3.37s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.37s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
2024-08-16 13:58:58.324 | INFO     | __main__:train:207 - Epoch 29 Average Loss: 3.96588
2024-08-16 13:58:59.040 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL29*****
2024-08-16 13:58:59.040 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 13:58:59.040 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:20,  1.03it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:17,  1.15it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.20it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.25it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:11,  1.25it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.26it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.26it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.26it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.26it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.26it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.27it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.27it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.27it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.27it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.27it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.27it/s]
Evaluating:  91%|█████████ | 20/22 [00:15<00:01,  1.26it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.26it/s]
Evaluating: 100%|██████████| 22/22 [00:16<00:00,  1.64it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 13:59:16.062 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9143    0.9275    0.9209        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.4483    0.5200    0.4815        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.8667    0.8387    0.8525        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6094    0.7500    0.6724        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.8750    0.4667    0.6087        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8752       681
                    macro avg     0.9151    0.8795    0.9197       681
                 weighted avg     0.8950    0.8752    0.8899       681

2024-08-16 13:59:16.062 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8752
2024-08-16 13:59:16.080 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 13:59:16.080 | INFO     | __main__:eval:454 - Validation loss: 4.77142439105294
2024-08-16 13:59:16.087 | INFO     | __main__:train:256 - epochs: 29
2024-08-16 13:59:16.087 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724, 4.021023601644179, 3.916540437586167, 3.8463964476304895, 3.880342351689058, 4.082041246750776, 3.965880245320937]
2024-08-16 13:59:16.087 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607, 4.769751689650795, 4.739060575311834, 4.747467355294661, 4.742271553386342, 4.746249567378651, 4.77142439105294]
2024-08-16 13:59:16.087 | INFO     | __main__:train:159 - ====epoch #30====

Training:   0%|          | 0/85 [00:00<?, ?it/s]
Training:   1%|          | 1/85 [00:03<04:59,  3.57s/it]
Training:   2%|▏         | 2/85 [00:06<04:48,  3.48s/it]
Training:   4%|▎         | 3/85 [00:10<04:42,  3.44s/it]
Training:   5%|▍         | 4/85 [00:13<04:37,  3.43s/it]
Training:   6%|▌         | 5/85 [00:17<04:32,  3.41s/it]
Training:   7%|▋         | 6/85 [00:20<04:29,  3.41s/it]
Training:   8%|▊         | 7/85 [00:23<04:24,  3.40s/it]
Training:   9%|▉         | 8/85 [00:27<04:20,  3.39s/it]
Training:  11%|█         | 9/85 [00:30<04:17,  3.39s/it]
Training:  12%|█▏        | 10/85 [00:34<04:14,  3.39s/it]
Training:  13%|█▎        | 11/85 [00:37<04:10,  3.39s/it]
Training:  14%|█▍        | 12/85 [00:40<04:07,  3.39s/it]
Training:  15%|█▌        | 13/85 [00:44<04:04,  3.39s/it]
Training:  16%|█▋        | 14/85 [00:47<04:00,  3.39s/it]
Training:  18%|█▊        | 15/85 [00:51<03:57,  3.39s/it]
Training:  19%|█▉        | 16/85 [00:54<03:53,  3.38s/it]
Training:  20%|██        | 17/85 [00:57<03:50,  3.38s/it]
Training:  21%|██        | 18/85 [01:01<03:46,  3.39s/it]
Training:  22%|██▏       | 19/85 [01:04<03:43,  3.39s/it]
Training:  24%|██▎       | 20/85 [01:07<03:40,  3.39s/it]
Training:  25%|██▍       | 21/85 [01:11<03:36,  3.39s/it]
Training:  26%|██▌       | 22/85 [01:14<03:33,  3.39s/it]
Training:  27%|██▋       | 23/85 [01:18<03:30,  3.39s/it]
Training:  28%|██▊       | 24/85 [01:21<03:26,  3.39s/it]
Training:  29%|██▉       | 25/85 [01:24<03:22,  3.38s/it]
Training:  31%|███       | 26/85 [01:28<03:19,  3.38s/it]
Training:  32%|███▏      | 27/85 [01:31<03:16,  3.39s/it]
Training:  33%|███▎      | 28/85 [01:35<03:13,  3.39s/it]
Training:  34%|███▍      | 29/85 [01:38<03:09,  3.39s/it]
Training:  35%|███▌      | 30/85 [01:41<03:06,  3.39s/it]
Training:  36%|███▋      | 31/85 [01:45<03:02,  3.38s/it]
Training:  38%|███▊      | 32/85 [01:48<02:59,  3.38s/it]
Training:  39%|███▉      | 33/85 [01:51<02:55,  3.38s/it]
Training:  40%|████      | 34/85 [01:55<02:52,  3.39s/it]
Training:  41%|████      | 35/85 [01:58<02:49,  3.39s/it]
Training:  42%|████▏     | 36/85 [02:02<02:46,  3.39s/it]
Training:  44%|████▎     | 37/85 [02:05<02:42,  3.39s/it]
Training:  45%|████▍     | 38/85 [02:08<02:39,  3.39s/it]
Training:  46%|████▌     | 39/85 [02:12<02:36,  3.41s/it]
Training:  47%|████▋     | 40/85 [02:15<02:33,  3.41s/it]
Training:  48%|████▊     | 41/85 [02:19<02:30,  3.42s/it]
Training:  49%|████▉     | 42/85 [02:22<02:27,  3.42s/it]
Training:  51%|█████     | 43/85 [02:26<02:23,  3.42s/it]
Training:  52%|█████▏    | 44/85 [02:29<02:20,  3.42s/it]
Training:  53%|█████▎    | 45/85 [02:32<02:16,  3.42s/it]
Training:  54%|█████▍    | 46/85 [02:36<02:13,  3.42s/it]
Training:  55%|█████▌    | 47/85 [02:39<02:09,  3.41s/it]
Training:  56%|█████▋    | 48/85 [02:43<02:06,  3.41s/it]
Training:  58%|█████▊    | 49/85 [02:46<02:02,  3.42s/it]
Training:  59%|█████▉    | 50/85 [02:49<01:59,  3.42s/it]
Training:  60%|██████    | 51/85 [02:53<01:56,  3.42s/it]
Training:  61%|██████    | 52/85 [02:56<01:52,  3.41s/it]
Training:  62%|██████▏   | 53/85 [03:00<01:48,  3.40s/it]
Training:  64%|██████▎   | 54/85 [03:03<01:45,  3.40s/it]
Training:  65%|██████▍   | 55/85 [03:06<01:41,  3.40s/it]
Training:  66%|██████▌   | 56/85 [03:10<01:38,  3.40s/it]
Training:  67%|██████▋   | 57/85 [03:13<01:35,  3.40s/it]
Training:  68%|██████▊   | 58/85 [03:17<01:31,  3.40s/it]
Training:  69%|██████▉   | 59/85 [03:20<01:28,  3.40s/it]
Training:  71%|███████   | 60/85 [03:23<01:24,  3.40s/it]
Training:  72%|███████▏  | 61/85 [03:27<01:21,  3.40s/it]
Training:  73%|███████▎  | 62/85 [03:30<01:18,  3.40s/it]
Training:  74%|███████▍  | 63/85 [03:34<01:14,  3.40s/it]
Training:  75%|███████▌  | 64/85 [03:37<01:11,  3.40s/it]
Training:  76%|███████▋  | 65/85 [03:40<01:08,  3.40s/it]
Training:  78%|███████▊  | 66/85 [03:44<01:04,  3.40s/it]
Training:  79%|███████▉  | 67/85 [03:47<01:01,  3.40s/it]
Training:  80%|████████  | 68/85 [03:51<00:57,  3.40s/it]
Training:  81%|████████  | 69/85 [03:54<00:54,  3.39s/it]
Training:  82%|████████▏ | 70/85 [03:57<00:50,  3.40s/it]
Training:  84%|████████▎ | 71/85 [04:01<00:47,  3.40s/it]
Training:  85%|████████▍ | 72/85 [04:04<00:44,  3.39s/it]
Training:  86%|████████▌ | 73/85 [04:08<00:40,  3.39s/it]
Training:  87%|████████▋ | 74/85 [04:11<00:37,  3.39s/it]
Training:  88%|████████▊ | 75/85 [04:14<00:33,  3.39s/it]
Training:  89%|████████▉ | 76/85 [04:18<00:30,  3.40s/it]
Training:  91%|█████████ | 77/85 [04:21<00:27,  3.40s/it]
Training:  92%|█████████▏| 78/85 [04:25<00:23,  3.40s/it]
Training:  93%|█████████▎| 79/85 [04:28<00:20,  3.40s/it]
Training:  94%|█████████▍| 80/85 [04:31<00:16,  3.39s/it]
Training:  95%|█████████▌| 81/85 [04:35<00:13,  3.39s/it]
Training:  96%|█████████▋| 82/85 [04:38<00:10,  3.39s/it]
Training:  98%|█████████▊| 83/85 [04:42<00:06,  3.39s/it]
Training:  99%|█████████▉| 84/85 [04:45<00:03,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.39s/it]
Training: 100%|██████████| 85/85 [04:48<00:00,  3.40s/it]
2024-08-16 14:04:04.979 | INFO     | __main__:train:207 - Epoch 30 Average Loss: 3.93385
2024-08-16 14:04:05.703 | INFO     | __main__:eval:312 - ***** Running evaluation longformer_CL30*****
2024-08-16 14:04:05.704 | INFO     | __main__:eval:313 -   Num examples = 681
2024-08-16 14:04:05.704 | INFO     | __main__:eval:314 -   Batch size = 32

Evaluating:   0%|          | 0/22 [00:00<?, ?it/s]
Evaluating:   5%|▍         | 1/22 [00:00<00:19,  1.10it/s]
Evaluating:   9%|▉         | 2/22 [00:01<00:16,  1.18it/s]
Evaluating:  14%|█▎        | 3/22 [00:02<00:15,  1.21it/s]
Evaluating:  18%|█▊        | 4/22 [00:03<00:14,  1.22it/s]
Evaluating:  23%|██▎       | 5/22 [00:04<00:13,  1.24it/s]
Evaluating:  27%|██▋       | 6/22 [00:04<00:12,  1.24it/s]
Evaluating:  32%|███▏      | 7/22 [00:05<00:12,  1.24it/s]
Evaluating:  36%|███▋      | 8/22 [00:06<00:11,  1.24it/s]
Evaluating:  41%|████      | 9/22 [00:07<00:10,  1.25it/s]
Evaluating:  45%|████▌     | 10/22 [00:08<00:09,  1.25it/s]
Evaluating:  50%|█████     | 11/22 [00:08<00:08,  1.26it/s]
Evaluating:  55%|█████▍    | 12/22 [00:09<00:07,  1.25it/s]
Evaluating:  59%|█████▉    | 13/22 [00:10<00:07,  1.25it/s]
Evaluating:  64%|██████▎   | 14/22 [00:11<00:06,  1.25it/s]
Evaluating:  68%|██████▊   | 15/22 [00:12<00:05,  1.26it/s]
Evaluating:  73%|███████▎  | 16/22 [00:12<00:04,  1.26it/s]
Evaluating:  77%|███████▋  | 17/22 [00:13<00:03,  1.25it/s]
Evaluating:  82%|████████▏ | 18/22 [00:14<00:03,  1.25it/s]
Evaluating:  86%|████████▋ | 19/22 [00:15<00:02,  1.25it/s]
Evaluating:  91%|█████████ | 20/22 [00:16<00:01,  1.25it/s]
Evaluating:  95%|█████████▌| 21/22 [00:16<00:00,  1.25it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.63it/s]
Evaluating: 100%|██████████| 22/22 [00:17<00:00,  1.29it/s]
2024-08-16 14:04:22.819 | INFO     | __main__:eval:422 - Classification Report for model_type
                               precision    recall  f1-score   support

                       albert     1.0000    1.0000    1.0000        33
audio-spectrogram-transformer     1.0000    1.0000    1.0000         5
                         bart     1.0000    1.0000    1.0000        22
                         beit     1.0000    0.6667    0.8000         6
                         bert     0.9552    0.9275    0.9412        69
                     big_bird     1.0000    1.0000    1.0000        22
              bigbird_pegasus     1.0000    1.0000    1.0000         8
                   blenderbot     1.0000    1.0000    1.0000         5
                    camembert     0.3929    0.4400    0.4151        25
                       canine     1.0000    1.0000    1.0000         2
                         clip     1.0000    1.0000    1.0000         4
                      codegen     1.0000    1.0000    1.0000         4
                     convnext     1.0000    1.0000    1.0000         7
                   convnextv2     1.0000    1.0000    1.0000         2
                         ctrl     1.0000    1.0000    1.0000         1
                      deberta     1.0000    1.0000    1.0000        15
                   deberta-v2     1.0000    1.0000    1.0000        26
                         detr     1.0000    1.0000    1.0000         3
                   distilbert     1.0000    0.9714    0.9855        35
                          dpr     1.0000    1.0000    1.0000         9
                      electra     0.7368    0.9032    0.8116        31
                          esm     1.0000    1.0000    1.0000         7
                         fnet     1.0000    1.0000    1.0000         2
                         glpn     1.0000    1.0000    1.0000         1
                         gpt2     0.5000    1.0000    0.6667         1
                  gpt_bigcode        nan    0.0000       nan         1
                      gpt_neo     0.7500    1.0000    0.8571         3
                     gpt_neox     0.6667    1.0000    0.8000         2
                         gptj     1.0000    0.6667    0.8000         6
                     layoutlm     1.0000    1.0000    1.0000         1
                   layoutlmv3     1.0000    1.0000    1.0000         2
                          led     1.0000    1.0000    1.0000         5
                         lilt        nan    0.0000       nan         4
                        llama     1.0000    1.0000    1.0000         3
                   longformer     1.0000    1.0000    1.0000        23
                       longt5     1.0000    1.0000    1.0000         3
                      m2m_100     1.0000    0.7500    0.8571         4
                       marian     1.0000    1.0000    1.0000         5
                  mask2former     1.0000    1.0000    1.0000         8
                   maskformer     1.0000    1.0000    1.0000         5
                        mbart     1.0000    1.0000    1.0000         2
                   mobilebert     1.0000    0.8000    0.8889         5
                 mobilenet_v2     1.0000    1.0000    1.0000         4
                    mobilevit     1.0000    1.0000    1.0000         1
                        mpnet     0.8095    1.0000    0.8947        17
                          mpt     1.0000    1.0000    1.0000         6
                          mt5     1.0000    1.0000    1.0000         6
                          opt     1.0000    1.0000    1.0000         5
                      pegasus     0.8571    0.8571    0.8571         7
                    pegasus_x     1.0000    1.0000    1.0000         1
                       plbart     1.0000    1.0000    1.0000         6
                       regnet     1.0000    1.0000    1.0000         3
                       resnet     1.0000    1.0000    1.0000         4
                      roberta     0.6071    0.6538    0.6296        52
                         rwkv     1.0000    1.0000    1.0000         5
                          sam     1.0000    1.0000    1.0000         2
                    segformer     1.0000    1.0000    1.0000         3
               speech_to_text     1.0000    1.0000    1.0000         4
                     speecht5     0.5000    0.5000    0.5000         2
                         swin     1.0000    1.0000    1.0000         6
                           t5     0.9286    0.9286    0.9286        14
                    unispeech     1.0000    0.2500    0.4000         4
                unispeech-sat     0.1667    0.5000    0.2500         2
     vision-text-dual-encoder     0.0000    0.0000       nan         1
                          vit     1.0000    1.0000    1.0000         3
                     wav2vec2     0.6500    0.9286    0.7647        28
                        wavlm        nan    0.0000       nan        12
                      whisper     1.0000    1.0000    1.0000         8
                         xglm     1.0000    1.0000    1.0000         4
                  xlm-roberta     0.7000    0.4667    0.5600        30
                        xlnet     1.0000    1.0000    1.0000        11
                        yolos     0.6000    1.0000    0.7500         3

                     accuracy                         0.8678       681
                    macro avg     0.9104    0.8779    0.9170       681
                 weighted avg     0.8830    0.8678    0.8820       681

2024-08-16 14:04:22.820 | INFO     | __main__:eval:423 - Validation Accuracy for model_type: 0.8678
2024-08-16 14:04:22.853 | INFO     | __main__:eval:426 - Classification report saved to ./eval/longformer_model_type_CLCE_32_5e-05_report_6
2024-08-16 14:04:22.853 | INFO     | __main__:eval:454 - Validation loss: 4.750899000601335
2024-08-16 14:04:22.862 | INFO     | __main__:train:256 - epochs: 30
2024-08-16 14:04:22.862 | INFO     | __main__:train:257 - train_loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724, 4.021023601644179, 3.916540437586167, 3.8463964476304895, 3.880342351689058, 4.082041246750776, 3.965880245320937, 3.933846109053668]
2024-08-16 14:04:22.862 | INFO     | __main__:train:258 - test_loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607, 4.769751689650795, 4.739060575311834, 4.747467355294661, 4.742271553386342, 4.746249567378651, 4.77142439105294, 4.750899000601335]
2024-08-16 14:04:22.862 | INFO     | __main__:train:296 - Train loss: [6.657064679089714, 5.361157504250022, 4.627543182934032, 4.484479216968312, 4.4608970810385316, 4.2983185487635, 4.298588730307186, 4.283366204710568, 4.340283309712129, 4.105003974016975, 4.110709639156566, 4.2102077568278595, 4.1613008246702305, 4.068326790192548, 4.027219162267797, 4.175136580186732, 4.085426344591029, 4.13689044082866, 4.016849318672629, 4.159963512420655, 4.038179275568794, 3.997505746168249, 3.999518802586724, 4.021023601644179, 3.916540437586167, 3.8463964476304895, 3.880342351689058, 4.082041246750776, 3.965880245320937, 3.933846109053668], Test loss: [7.4331487959081475, 5.342955383387479, 5.095791112292897, 4.98743457143957, 4.927706794305281, 4.873680569908836, 4.882195342670787, 4.810776862231168, 4.797635511918501, 4.8002578670328315, 4.7950898083773525, 4.774518999186429, 4.921102285385132, 4.804804574359547, 4.804324041713368, 4.759243715893138, 4.764866026965055, 4.741184115409851, 4.769154245203191, 4.8135000467300415, 4.7602174932306465, 4.762599728324196, 4.751052715561607, 4.769751689650795, 4.739060575311834, 4.747467355294661, 4.742271553386342, 4.746249567378651, 4.77142439105294, 4.750899000601335]
