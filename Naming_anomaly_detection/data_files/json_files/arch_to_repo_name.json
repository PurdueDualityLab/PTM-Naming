{
    "XLMRobertaForSequenceClassification": [
        "203427as321/hnai_model",
        "Andrazp/multilingual-hate-speech-robacofi",
        "Binaryy/xlm-roberta-large-finetuned-cola",
        "Davlan/naija-twitter-sentiment-afriberta-large",
        "DeepPavlov/xlm-roberta-large-en-ru-mnli",
        "EIStakovskii/xlm_roberta_base_multilingual_toxicity_classifier_plus",
        "ERCDiDip/langdetect",
        "Factiverse/factiverse_stance_detection_ort_quantized",
        "FrGes/xlm-roberta-large-finetuned-EUJAV-datasetAB",
        "Jiva/xlm-roberta-large-it-mnli",
        "MMG/xlm-roberta-base-sa-spanish",
        "Maxbnza/country-recognition",
        "MilaNLProc/hate-ita-xlm-r-large",
        "MilaNLProc/xlm-emo-t",
        "MoritzLaurer/multilingual-MiniLMv2-L12-mnli-xnli",
        "MoritzLaurer/multilingual-MiniLMv2-L6-mnli-xnli",
        "MoritzLaurer/xlm-v-base-mnli-xnli",
        "Newtral/xlm-r-finetuned-toxic-political-tweets-es",
        "PrimeQA/tydi-boolean_answer_classifier-xlmr_large-20221117",
        "PrimeQA/tydi-boolean_question_classifier-xlmr_large-20221117",
        "RubenAMtz/mmarco-mMiniLMv2-L12-H384-v1",
        "TransQuest/monotransquest-da-any_en",
        "TransQuest/monotransquest-da-en_any",
        "TransQuest/monotransquest-da-en_de-wiki",
        "TransQuest/monotransquest-da-multilingual",
        "YaraKyrychenko/ukraine-war-pov",
        "akhooli/xlm-r-large-arabic-sent",
        "akhooli/xlm-r-large-arabic-toxic",
        "amphora/KorFinASC-XLM-RoBERTa",
        "bstrai/multilingual-toxic-xlm-roberta",
        "cardiffnlp/twitter-xlm-roberta-base-sentiment",
        "cardiffnlp/twitter-xlm-roberta-base-sentiment-multilingual",
        "cardiffnlp/xlm-roberta-base-sentiment-multilingual",
        "cardiffnlp/xlm-roberta-base-tweet-sentiment-pt",
        "cardiffnlp/xlm-twitter-politics-sentiment",
        "cartesinus/xlm-r-base-amazon-massive-intent",
        "citizenlab/twitter-xlm-roberta-base-sentiment-finetunned",
        "clampert/multilingual-sentiment-covid19",
        "classla/xlm-roberta-base-multilingual-text-genre-classifier",
        "cross-encoder/mmarco-mMiniLMv2-L12-H384-v1",
        "crystina-z/monoXLMR.pft-mmarco",
        "daveni/twitter-xlm-roberta-emotion-es",
        "dcferreira/detoxify-optimized",
        "dinalzein/xlm-roberta-base-finetuned-language-identification",
        "eleldar/language-detection",
        "gg-ai/bert-pt-cardi",
        "hyperonym/barba",
        "ivanlau/language-detection-fine-tuned-on-xlm-roberta-base",
        "joeddav/xlm-roberta-large-xnli",
        "juliensimon/xlm-v-base-language-id",
        "kauffinger/xlm-roberta-base-finetuned-enron",
        "lewtun/xlm-roberta-base-finetuned-marc",
        "lighteternal/fact-or-opinion-xlmr-el",
        "mjwong/multilingual-e5-base-xnli",
        "mjwong/multilingual-e5-large-xnli",
        "mjwong/multilingual-e5-large-xnli-anli",
        "morit/chinese_xlm_xnli",
        "morit/xlm-t-roberta-base-mnli-xnli",
        "mrm8488/xlm-roberta-base-finetuned-HC3-mix",
        "papluca/xlm-roberta-base-language-detection",
        "poltextlab/xlm-roberta-large-english-legal-cap",
        "rmihaylov/roberta-base-sentiment-bg",
        "s-nlp/xlmr_formality_classifier",
        "scroobiustrip/topic-model-v3",
        "simoneteglia/xlm-roberta-europarl-language-detection",
        "sismetanin/xlm_roberta_large-ru-sentiment-rusentiment",
        "symanto/xlm-roberta-base-snli-mnli-anli-xnli",
        "timpal0l/xlm-roberta-base-faq-extractor",
        "unicamp-dl/mMiniLM-L6-v2-en-pt-msmarco-v2",
        "unicamp-dl/mMiniLM-L6-v2-mmarco-v2",
        "unitary/multilingual-toxic-xlm-roberta",
        "vicgalle/xlm-roberta-large-xnli-anli"
    ],
    "ElectraForSequenceClassification": [
        "24bean/multi_classification",
        "Aktsvigun/electra-large-cola",
        "JasperLS/gelectra-base-injection",
        "JasperLS/gelectra-base-injection-pt_v1",
        "JminJ/kcElectra_base_Bad_Sentence_Classifier",
        "OpenAssistant/reward-model-electra-large-discriminator",
        "Recognai/zeroshot_selectra_medium",
        "Recognai/zeroshot_selectra_small",
        "alexandrainst/da-hatespeech-detection-small",
        "anirudh21/electra-base-discriminator-finetuned-rte",
        "beomi/korean-hatespeech-multilabel",
        "bhadresh-savani/electra-base-emotion",
        "circulus/koelectra-polite-v1",
        "circulus/koelectra-sentiment-v1",
        "cross-encoder/ms-marco-electra-base",
        "cross-encoder/qnli-electra-base",
        "crystina-z/monoELECTRA_LCE_nneg31",
        "gooohjy/suicidal-electra",
        "hf-internal-testing/tiny-random-ElectraForSequenceClassification",
        "hf-tiny-model-private/tiny-random-ElectraForSequenceClassification",
        "howey/electra-base-stsb",
        "howey/electra-small-mnli",
        "intfloat/simlm-msmarco-reranker",
        "jaehyeong/koelectra-base-v3-generalized-sentiment-analysis",
        "jcblaise/electra-tagalog-small-uncased-discriminator-newsphnli",
        "jsonccolu/sentiments",
        "kfkas/legal-question-filter-koelectra",
        "kit-nlp/transformers-ud-japanese-electra-base-discriminator-irony",
        "matthewburke/korean_sentiment",
        "monologg/koelectra-base-gender-bias",
        "monologg/koelectra-base-v3-gender-bias",
        "monologg/koelectra-base-v3-hate-speech",
        "mrm8488/electricidad-base-finetuned-muchocine",
        "mrm8488/electricidad-small-finetuned-restaurant-sentiment-analysis",
        "mrm8488/electricidad-small-finetuned-xnli-es",
        "nlp04/korean_sentiment_analysis_kcelectra",
        "ptaszynski/yacis-electra-small-japanese-cyberbullying",
        "searle-j/kote_for_easygoing_people",
        "svalabs/cross-electra-ms-marco-german-uncased"
    ],
    "XLMRobertaForTokenClassification": [
        "2rtl3/mn-xlm-roberta-base-named-entity",
        "51la5/roberta-large-NER",
        "AryPratap/XLM-roberta-HIEN-POS",
        "Davlan/xlm-roberta-base-ner-hrl",
        "Davlan/xlm-roberta-base-wikiann-ner",
        "Davlan/xlm-roberta-large-ner-hrl",
        "Joblift/xlm-roberta-finetuned-ner-recleaned_cased_0.4",
        "MMG/xlm-roberta-large-ner-spanish",
        "MU-NLPC/ahisto-ner-model-s",
        "Venkatesh4342/xlm-roberta-base-NER-ind",
        "Yaxin/xlm-roberta-base-conll2003-ner",
        "asahi417/tner-xlm-roberta-base-ontonotes5",
        "asahi417/tner-xlm-roberta-base-uncased-ontonotes5",
        "asahi417/tner-xlm-roberta-large-all-english",
        "cahya/xlm-roberta-base-indonesian-NER",
        "cahya/xlm-roberta-large-indonesian-NER",
        "edwardjross/xlm-roberta-base-finetuned-recipe-all",
        "grace-pro/afro-xlmr-base-hausa-5e-5",
        "gunghio/xlm-roberta-base-finetuned-panx-ner",
        "jplu/tf-xlm-r-ner-40-lang",
        "julian-schelb/roberta-ner-multilingual",
        "kredor/punctuate-all",
        "lwachowiak/Metaphor-Detection-XLMR",
        "marefa-nlp/marefa-ner",
        "masakhane/afroxlmr-large-ner-masakhaner-1.0_2.0",
        "mbeukman/xlm-roberta-base-finetuned-swahili-finetuned-ner-swahili",
        "msislam/code-mixed-language-detection-XLMRoberta",
        "oliverguhr/fullstop-punctuation-multilang-large",
        "oliverguhr/fullstop-punctuation-multilingual-base",
        "oliverguhr/fullstop-punctuation-multilingual-sonar-base",
        "opensource/extract_names",
        "tner/xlm-roberta-base-uncased-all-english",
        "ukr-models/uk-ner",
        "wietsedv/xlm-roberta-base-ft-udpos28-en",
        "wietsedv/xlm-roberta-base-ft-udpos28-pt",
        "wpnbos/xlm-roberta-base-conll2002-dutch",
        "xlm-roberta-large-finetuned-conll03-english",
        "xlm-roberta-large-finetuned-conll03-german",
        "yeshpanovrustem/xlm-roberta-large-ner-kazakh",
        "yqelz/xml-roberta-large-ner-russian"
    ],
    "RWForCausalLM": [
        "4bit/falcon-7b-instruct-GPTQ",
        "Amod/falcon7b-fine-tuned-therapy-merged",
        "BlackSamorez/falcon-40b-tiny-testing",
        "BramVanroy/falcon-40b-ft-alpaca-dolly-dutch",
        "CleverShovel/falcon-7b-instruct-sharded-bf16",
        "Ichsan2895/Garuda-7B-v02",
        "Linly-AI/Chinese-Falcon-7B",
        "Locala/test_2",
        "OpenAssistant/falcon-40b-sft-mix-1226",
        "OpenAssistant/falcon-40b-sft-top1-560",
        "OpenAssistant/falcon-7b-sft-mix-2000",
        "OpenAssistant/falcon-7b-sft-top1-696",
        "OpenBuddy/openbuddy-falcon-7b-v5-fp16",
        "OpenBuddy/openbuddy-falcon-7b-v6-bf16",
        "Sandiago21/falcon-7b-prompt-answering",
        "TheBloke/WizardLM-Uncensored-Falcon-40B-3bit-GPTQ",
        "TheBloke/WizardLM-Uncensored-Falcon-40B-GPTQ",
        "TheBloke/WizardLM-Uncensored-Falcon-7B-GPTQ",
        "TheBloke/falcon-40b-instruct-3bit-GPTQ",
        "TheBloke/falcon-40b-instruct-GPTQ",
        "TheBloke/falcon-7b-instruct-GPTQ",
        "TheBloke/h2ogpt-gm-oasst1-en-2048-falcon-40b-v2-GPTQ",
        "TheBloke/h2ogpt-gm-oasst1-en-2048-falcon-7b-v3-GPTQ",
        "Weni/WeniGPT",
        "amazon/FalconLite",
        "bofenghuang/vigogne-falcon-7b-chat",
        "bofenghuang/vigogne-falcon-7b-instruct",
        "cambioml/falcon-7b-8bit",
        "clibrain/lince-zero",
        "conceptofmind/Hermes-Falcon-7b-8k",
        "dmunteanu-rws/falcon-40b",
        "ehartford/WizardLM-Uncensored-Falcon-40b",
        "ehartford/WizardLM-Uncensored-Falcon-7b",
        "explosion-testing/falcon-no-parallel-attn-test",
        "explosion-testing/refined-web-model-test",
        "flozi00/falcon-7b-german-assistant",
        "flozi00/falcon-7b-german-assistant-v2",
        "gorilla-llm/gorilla-falcon-7b-hf-v0",
        "h2o-llmstudio/falcon-40b-fix",
        "h2o-llmstudio/falcon-7b-fix",
        "h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v1",
        "h2oai/h2ogpt-gm-oasst1-en-2048-falcon-40b-v2",
        "h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b",
        "h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v2",
        "h2oai/h2ogpt-gm-oasst1-en-2048-falcon-7b-v3",
        "h2oai/h2ogpt-gm-oasst1-multilang-2048-falcon-7b",
        "h2oai/h2ogpt-oasst1-falcon-40b",
        "h2oai/h2ogpt-oig-oasst1-falcon-40b",
        "harshpoddar21/checkpoint-4000",
        "hlarcher/falcon-7b-v100s",
        "huggingface/falcon-40b-gptq",
        "ichitaka/falcon-40b-instruct-8bit",
        "inarikami/falcon-7b-instruct-8bit",
        "jangtu052/longfalcon-40b",
        "justinpinkney/falcon-7b",
        "lightonai/alfred-40b-0723",
        "monuirctc/falcon-7b-instruct-indo",
        "mrm8488/falcoder-7b",
        "nferroukhi/WizardLM-Uncensored-Falcon-7b-sharded-bf16",
        "nomic-ai/gpt4all-falcon",
        "openaccess-ai-collective/falcon-7b-4k-alibi",
        "oscardong/Mental_Health_X_API",
        "projecte-aina/aguila-7b",
        "sachith-surge/falcon-40b-instruct-sharded-bf16",
        "tiiuae/falcon-40b",
        "tiiuae/falcon-40b-instruct",
        "tiiuae/falcon-7b",
        "tiiuae/falcon-7b-instruct",
        "transmogrifier/pr-falcon-7b-instruct-8bit-Jul20",
        "vignesh-trustt/falcon-7B-Instruct",
        "vivekraina/Falcon-instruct-8bit-test",
        "vrsen/falcon-7b-instruct-ft",
        "winglian/falcon-7b-alibi",
        "ybelkada/falcon-7b-sharded-bf16"
    ],
    "MPTForCausalLM": [
        "4bit/mpt-7b-storywriter-4bit-128g",
        "Abzu/mpt-30b-instruct-q8",
        "Abzu/mpt-7b-chat-q8",
        "AnimusOG/mpt-7b-storywriter-4bit-128g-65kTokens-CPU",
        "Arc53/DocsGPT-7B",
        "Birchlabs/mosaicml-mpt-7b-chat-qlora",
        "Gladiaio/mpt-7b-qlora",
        "Intel/neural-chat-7b-v1-1",
        "Jumtra/mpt-7b-base",
        "Jumtra/mpt-7b-inst",
        "Katonic/MPT-7b-instruct-extraction",
        "OccamRazor/mpt-7b-storywriter-4bit-128g",
        "TehVenom/MPT-7b-Chat-Instruct-LongCTX-Merge",
        "Trelis/mpt-7b-8k-chat-sharded-bf16",
        "abacaj/Replit-v2-CodeInstruct-3B-ggml",
        "abhinavkulkarni/mosaicml-mpt-30b-chat-w4-g128-awq",
        "anas-awadalla/mpt-7b",
        "bofenghuang/vigogne-mpt-7b-instruct",
        "cekal/mpt-7b-peft-compatible",
        "dfurman/mpt-7b-dolphin",
        "eluzhnica/mpt-30b-instruct-peft-compatible",
        "eluzhnica/mpt-30b-peft-compatible",
        "eluzhnica/mpt-7b-8k-instruct-peft-compatible",
        "eluzhnica/mpt-7b-8k-peft-compatible",
        "eluzhnica/mpt-7b-instruct-peft-compatible",
        "emozilla/mpt-7b-storysummarizer",
        "flashvenom/mpt-7b-base-lora-fix",
        "float-trip/mpt-30b-drama",
        "fxmarty/tiny-mpt-random-remote-code",
        "gorilla-llm/gorilla-mpt-7b-hf-v0",
        "gretelai/mpt-7b",
        "hyungtae/mpt-30b",
        "ibm/mpt-7b-instruct2",
        "jondurbin/airoboros-mpt-30b-gpt4-1p4-five-epochs",
        "jondurbin/mpt-30b-qlora-compatible",
        "jprafael/mpt-7b-instruct-sharded",
        "julep-ai/mpt-30b-orca-mini",
        "justus27/mpt-7b-lora-compatible",
        "lentan/mpt-125m",
        "lightblue/japanese-mpt-7b",
        "manojpreveen/mpt-30b-v2",
        "matorus/replit-openorca",
        "michaelfeil/ct2fast-mpt-30b-instruct",
        "mosaicml/mpt-30b",
        "mosaicml/mpt-30b-chat",
        "mosaicml/mpt-30b-instruct",
        "mosaicml/mpt-7b",
        "mosaicml/mpt-7b-8k",
        "mosaicml/mpt-7b-8k-chat",
        "mosaicml/mpt-7b-8k-instruct",
        "mosaicml/mpt-7b-chat",
        "mosaicml/mpt-7b-instruct",
        "mosaicml/mpt-7b-storywriter",
        "nomic-ai/gpt4all-mpt",
        "oleksandrfluxon/mpt-7b-chat-4bit",
        "oleksandrfluxon/mpt-7b-instruct-2",
        "oleksandrfluxon/mpt-7b-instruct-evaluate",
        "replit/replit-code-v1-3b",
        "sahil2801/replit-code-instruct-glaive",
        "teknium/Replit-v1-CodeInstruct-3B",
        "teknium/Replit-v2-CodeInstruct-3B"
    ],
    "GPTJForCausalLM": [
        "4bit/pygmalion-6b-4bit-128g",
        "AlekseyKorshuk/chatml-pyg-v1",
        "AlekseyKorshuk/gpt4all-j-groovy",
        "AlekseyKorshuk/pygmalion-6b-vicuna-chatml",
        "Amo/GPT-J-6B-PNY",
        "CarperAI/openai_summarize_tldr_ppo",
        "CarperAI/openai_summarize_tldr_sft",
        "Cedille/fr-boris",
        "Corianas/gpt-j-6B-Dolly",
        "EleutherAI/gpt-j-6b",
        "FunkEngine/FunkEngine-6B",
        "Imablank/D0IIy-Shydgemalion-6B",
        "KoboldAI/GPT-J-6B-Adventure",
        "KoboldAI/GPT-J-6B-Janeway",
        "KoboldAI/GPT-J-6B-Shinen",
        "KoboldAI/GPT-J-6B-Skein",
        "KoboldAI/PPO_Pygway-6b-Mix",
        "Lazycuber/pyg-instruct-wizardlm",
        "Milos/slovak-gpt-j-1.4B",
        "MrBananaHuman/kogpt_6b_fp16",
        "NbAiLab/nb-gpt-j-6B",
        "NbAiLab/nb-gpt-j-6B-alpaca",
        "NbAiLab/nb-gpt-j-6B-norpaca",
        "NovelAI/genji-jp",
        "OccamRazor/pygmalion-6b-gptq-4bit",
        "PsychoC/PP0_PYgway-v8p4_dev-6B",
        "PygmalionAI/pygmalion-6b",
        "TabbyML/J-350M",
        "TehVenom/ChanMalion",
        "TehVenom/Dolly_GPT-J-6b",
        "TehVenom/Dolly_Malion-6b",
        "TehVenom/Dolly_Shygmalion-6b",
        "TehVenom/Dolly_Shygmalion-6b-Dev_V8P2",
        "TehVenom/GPT-J-Pyg_PPO-6B",
        "TehVenom/GPT-J-Pyg_PPO-6B-Dev-V8p4",
        "TehVenom/PPO_Pygway-V8p4_Dev-6b",
        "TehVenom/PPO_Shygmalion-6b",
        "TehVenom/PPO_Shygmalion-V8p4_Dev-6b",
        "ThisIsMyUsername69/gpt-j-6B-16bit",
        "Tverous/sft-trl",
        "VietAI/gpt-j-6B-vietnamese-news",
        "addy88/gpt-j-8bit",
        "amazon/LightGPT",
        "anton-l/gpt-j-tiny-random",
        "architext/gptj-162M",
        "bertin-project/bertin-gpt-j-6B",
        "bertin-project/bertin-gpt-j-6B-alpaca",
        "databricks/dolly-v1-6b",
        "digitous/Adventien-GPTJ",
        "digitous/GPT-R",
        "digitous/Javalion-R",
        "digitous/Javelin-GPTJ",
        "dmayhem93/toolformer_v0_epoch2",
        "dmayhem93/toolformer_v0_epoch3",
        "hakurei/lit-6B",
        "heegyu/kogpt-j-350m",
        "heegyu/kogpt-j-base",
        "hf-internal-testing/tiny-random-GPTJForCausalLM",
        "hf-tiny-model-private/tiny-random-GPTJForCausalLM",
        "hivemind/gpt-j-6B-8bit",
        "mayaeary/pygmalion-6b-4bit-128g",
        "mayaeary/pygmalion-6b_dev-4bit-128g",
        "mrm8488/bertin-gpt-j-6B-ES-8bit",
        "nlpcloud/instruct-gpt-j-fp16",
        "nlpulse/gpt-j-6b-english_quotes",
        "nomic-ai/gpt4all-j",
        "patent/LexGPT-6B",
        "philschmid/gpt-j-6B-fp16-sharded",
        "reshinthadith/codegen_350M_list_manip_5_len",
        "rexwang8/qilin-lit-6b",
        "robertmyers/bpt-sft",
        "rycont/kakaobrain__kogpt-6b-8bit",
        "togethercomputer/GPT-JT-6B-v0",
        "togethercomputer/GPT-JT-6B-v1",
        "togethercomputer/GPT-JT-Moderation-6B",
        "trl-internal-testing/tiny-random-GPTJForCausalLM",
        "usamakenway/gpt4all-lora-unfiltered-quantized",
        "vicgalle/gpt-j-6B-alpaca-gpt4",
        "vlrfrwaprnyysf1/vKUFUzrUTxZmKaL",
        "waifu-workshop/pygmalion-6b",
        "ybelkada/gpt-j-6b-sharded-bf16"
    ],
    "MPNetModel": [
        "AI-Growth-Lab/PatentSBERTa",
        "BernierS/Testing_Setfit",
        "FremyCompany/BioLORD-STAMB2-v1",
        "HamzaFarhan/PDFSegs",
        "JoBeer/multi-qa-mpnet-base-dot-v1-eclass",
        "Kick28/finetunned_sbert",
        "LLukas22/all-mpnet-base-v2-embedding-all",
        "PeppoCola/FewShotIssueClassifier-NLBSE23",
        "UWECProgrammer/setfit-model-one",
        "basel/ATTACK-BERT",
        "consciousAI/cai-stellaris-text-embeddings",
        "deepset/all-mpnet-base-v2-table",
        "guidecare/all-mpnet-base-v2-feature-extraction",
        "gyuri2020/kw-classification-setfit-model",
        "gyuri2020/kw-classification-setfithead-model",
        "hf-internal-testing/tiny-random-MPNetModel",
        "ishan/initial-model-v3",
        "kpourdeilami/transformer",
        "leavoigt/vulnerable_groups",
        "lewtun/my-awesome-setfit-model",
        "lewtun/setfit-ethos-multilabel-example",
        "rodekruis/sml-ukr-message-classifier",
        "sentence-transformers/nli-mpnet-base-v2",
        "sentence-transformers/paraphrase-mpnet-base-v2",
        "sentence-transformers/stsb-mpnet-base-v2",
        "shahrukhx01/paraphrase-mpnet-base-v2-fuzzy-matcher",
        "uclanlp/keyphrase-mpnet-v1"
    ],
    "RobertaModel": [
        "AI-MeisterBin/ko-sentence-bert-MeisterBin",
        "AnnaWegmann/Style-Embedding",
        "BM-K/KoDiffCSE-RoBERTa",
        "BM-K/KoSimCSE-roberta",
        "BM-K/KoSimCSE-roberta-multitask",
        "DeepSoftwareAnalytics/CoCoSoDa",
        "Forturne/cell_retriever",
        "Huffon/sentence-klue-roberta-base",
        "Lazyhope/RepoSim",
        "Lazyhope/unixcoder-clone-detection",
        "Lazyhope/unixcoder-nine-advtest",
        "Maite89/Roberta_finetuning_semantic_similarity_stsb_multi_mt",
        "TomatenMarc/WRAPresentations",
        "bespin-global/klue-sentence-roberta-base-kornlu",
        "cambridgeltl/tweet-roberta-base-embeddings-v1",
        "danjohnvelasco/filipino-sentence-roberta-v1",
        "dariolopez/roberta-base-bne-finetuned-msmarco-qa-es",
        "demdecuong/vihealthbert-base-syllable",
        "demdecuong/vihealthbert-base-word",
        "digio/Twitter4SSE",
        "djsull/aha-sent-similiar",
        "embedding-data/distilroberta-base-sentence-transformer",
        "flax-sentence-embeddings/st-codesearch-distilroberta-base",
        "hackathon-pln-es/bertin-roberta-base-finetuning-esnli",
        "hackathon-pln-es/paraphrase-spanish-distilroberta",
        "hf-internal-testing/tiny-random-RobertaModel",
        "hf-tiny-model-private/tiny-random-RobertaModel",
        "hunkim/sentence-transformer-klue",
        "jegormeister/robbert-v2-dutch-base-mqa-finetuned",
        "jhgan/ko-sroberta-multitask",
        "jhgan/ko-sroberta-nli",
        "keepitreal/vietnamese-sbert",
        "kundank/dspt-roberta-base-agnews",
        "mchochlov/codebert-base-cd-ft",
        "microsoft/codebert-base",
        "microsoft/codeexecutor",
        "microsoft/reacc-py-retriever",
        "microsoft/unixcoder-base",
        "microsoft/unixcoder-base-nine",
        "microsoft/unixcoder-base-unimodal",
        "msullivan/b0230790",
        "princeton-nlp/sup-simcse-roberta-base",
        "princeton-nlp/sup-simcse-roberta-large",
        "princeton-nlp/unsup-simcse-roberta-base",
        "princeton-nlp/unsup-simcse-roberta-large",
        "relbert/relbert-roberta-large-nce-semeval2012-0-400",
        "rovargasc/setfit-model_clasificadorEstudiantesV2",
        "sdadas/st-polish-paraphrase-from-distilroberta",
        "sentence-transformers/distilroberta-base-msmarco-v1",
        "sentence-transformers/distilroberta-base-msmarco-v2",
        "sentence-transformers/distilroberta-base-paraphrase-v1",
        "sentence-transformers/msmarco-distilroberta-base-v2",
        "sentence-transformers/msmarco-roberta-base-ance-firstp",
        "sentence-transformers/msmarco-roberta-base-v2",
        "sentence-transformers/msmarco-roberta-base-v3",
        "sentence-transformers/nli-distilroberta-base-v2",
        "sentence-transformers/nli-roberta-base-v2",
        "sentence-transformers/nli-roberta-large",
        "sentence-transformers/paraphrase-distilroberta-base-v1",
        "sentence-transformers/paraphrase-distilroberta-base-v2",
        "sentence-transformers/roberta-base-nli-mean-tokens",
        "sentence-transformers/roberta-base-nli-stsb-mean-tokens",
        "sentence-transformers/roberta-large-nli-mean-tokens",
        "sentence-transformers/roberta-large-nli-stsb-mean-tokens",
        "sentence-transformers/stsb-distilroberta-base-v2",
        "sentence-transformers/stsb-roberta-base",
        "sentence-transformers/stsb-roberta-base-v2",
        "sentence-transformers/stsb-roberta-large",
        "voidism/diffcse-roberta-base-sts",
        "yongsun-yoon/minilmv2-bertscore-distilled",
        "yseop/roberta-base-finance-hypernym-identification"
    ],
    "XLMRobertaModel": [
        "AIDA-UPM/MSTSb_paraphrase-xlm-r-multilingual-v1",
        "AIDA-UPM/mstsb-paraphrase-multilingual-mpnet-base-v2",
        "DeeeTeeee01/twitter-xlm-roberta-base-sentiment_dee",
        "DeepPavlov/xlm-roberta-large-en-ru",
        "Ghani-25/LF_enrich_sim",
        "KennethEnevoldsen/dfm-sentence-encoder-medium",
        "NtDNlp/sentence-embedding-vietnamese",
        "PM-AI/sts_paraphrase_xlm-roberta-base_de-en",
        "Ramos-Ramos/xlm-roberta-base-en-tl-4-end",
        "T-Systems-onsite/cross-en-de-roberta-sentence-transformer",
        "T-Systems-onsite/cross-en-fr-roberta-sentence-transformer",
        "T-Systems-onsite/german-roberta-sentence-transformer-v2",
        "TingChenChang/make-multilingual-en-zh-tw-20220825062338",
        "Unbabel/xlm-roberta-comet-small",
        "afschowdhury/s-xlmr-bn",
        "cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR",
        "cambridgeltl/SapBERT-UMLS-2020AB-all-lang-from-XLMR-large",
        "clips/mfaq",
        "embaas/sentence-transformers-multilingual-e5-base",
        "intfloat/multilingual-e5-base",
        "intfloat/multilingual-e5-large",
        "lighteternal/stsb-xlm-r-greek-transfer",
        "meedan/indian-sbert",
        "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",
        "sentence-transformers/paraphrase-xlm-r-multilingual-v1",
        "sentence-transformers/stsb-xlm-r-multilingual",
        "sentence-transformers/xlm-r-100langs-bert-base-nli-mean-tokens",
        "sentence-transformers/xlm-r-100langs-bert-base-nli-stsb-mean-tokens",
        "sentence-transformers/xlm-r-bert-base-nli-mean-tokens",
        "sentence-transformers/xlm-r-bert-base-nli-stsb-mean-tokens",
        "sentence-transformers/xlm-r-distilroberta-base-paraphrase-v1",
        "sentence-transformers/xlm-r-large-en-ko-nli-ststb",
        "symanto/sn-xlm-roberta-base-snli-mnli-anli-xnli",
        "tgsc/sentence-transformers_paraphrase-multilingual-mpnet-base-v2",
        "tyzp-INC/few-shot-multilingual-e5-large-xnli",
        "uaritm/multilingual_en_ru_uk"
    ],
    "AlbertForMaskedLM": [
        "ALINEAR/albert-japanese-v2",
        "HooshvareLab/albert-fa-zwnj-base-v2",
        "IDEA-CCNL/Erlangshen-UniMC-Albert-235M-English",
        "abhilash1910/albert-german-ner",
        "albert-base-v1",
        "albert-base-v2",
        "albert-large-v1",
        "albert-large-v2",
        "albert-xlarge-v1",
        "albert-xlarge-v2",
        "albert-xxlarge-v1",
        "albert-xxlarge-v2",
        "asafaya/albert-base-arabic",
        "asafaya/albert-large-arabic",
        "asafaya/albert-xlarge-arabic",
        "ckiplab/albert-base-chinese",
        "ckiplab/albert-tiny-chinese",
        "explosion-testing/albert-test",
        "hf-internal-testing/tiny-albert",
        "hf-internal-testing/tiny-random-AlbertForMaskedLM",
        "ken11/albert-base-japanese-v1",
        "kykim/albert-kor-base",
        "m3hrdadfi/albert-fa-base-v2",
        "qwant/fralbert-base",
        "textattack/albert-base-v2-rotten_tomatoes",
        "uer/albert-base-chinese-cluecorpussmall",
        "voidful/albert_chinese_base",
        "voidful/albert_chinese_large",
        "voidful/albert_chinese_small",
        "voidful/albert_chinese_tiny",
        "voidful/albert_chinese_xlarge"
    ],
    "BeitForImageClassification": [
        "ALM-AHME/beit-large-patch16-224-finetuned-BreastCancer-Classification-BreakHis-AH-60-20-20",
        "ALM-AHME/beit-large-patch16-224-finetuned-Lesion-Classification-HAM10000-AH-60-20-20",
        "ALM-AHME/beit-large-patch16-224-finetuned-Lesion-Classification-HAM10000-AH-60-20-20-Shuffled",
        "AkshatSurolia/BEiT-FaceMask-Finetuned",
        "DunnBC22/dit-base-Business_Documents_Classified_v2",
        "NTQAI/pedestrian_age_recognition",
        "NTQAI/pedestrian_gender_recognition",
        "am-infoweb/dit-base-finetuned-classification-anu-26-07-250",
        "cafeai/cafe_aesthetic",
        "cafeai/cafe_style",
        "cafeai/cafe_waifu",
        "hf-internal-testing/tiny-random-BeitForImageClassification",
        "jadohu/BEiT-finetuned",
        "jordyvl/dit-base_tobacco",
        "kmewhort/beit-sketch-classifier",
        "lixiqi/beit-base-patch16-224-pt22k-ft22k-finetuned-FER2013-6e-05",
        "lixiqi/beit-base-patch16-224-pt22k-ft22k-finetuned-FER2013-7e-05",
        "microsoft/beit-base-patch16-224",
        "microsoft/beit-base-patch16-224-pt22k-ft22k",
        "microsoft/beit-base-patch16-384",
        "microsoft/beit-large-patch16-224",
        "microsoft/beit-large-patch16-224-pt22k-ft22k",
        "microsoft/beit-large-patch16-384",
        "microsoft/beit-large-patch16-512",
        "microsoft/dit-base-finetuned-rvlcdip",
        "microsoft/dit-large-finetuned-rvlcdip",
        "saltacc/anime-ai-detect",
        "shivarama23/DiT_image_quality"
    ],
    "SimpleRobustDT": [
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v1-2607_0733",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v1-2607_1257",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v1-2607_1827",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v10-2707_1125",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v10-2707_1249",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v10-2707_1413",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v2-2607_0942",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v2-2607_1446",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v2-2607_1943",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v3-2607_0351",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v3-2607_0836",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v3-2607_1322",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v4-2607_0351",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v4-2607_0912",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v4-2607_1516",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v5-2607_0623",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v5-2607_1156",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v5-2607_1731",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v6-2607_0623",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v6-2607_1113",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v6-2607_1602",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v7-2607_0623",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v7-2607_1211",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v7-2607_1801",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v8-2607_0624",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v8-2607_1033",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v8-2607_1444",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v9-2607_0625",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v9-2607_1108",
        "ARDT-Internal/ardt-simplest-dataset_combo_train_halfcheetah_v9-2607_1617",
        "Experiment-2/ardt-simplest-dataset_combo_train_halfcheetah_special-2907_1234",
        "afonsosamarques/ardt-simplest-d4rl_expert_halfcheetah-1907_1725",
        "afonsosamarques/ardt-simplest-d4rl_expert_halfcheetah-1907_2219",
        "afonsosamarques/ardt-simplest-d4rl_expert_halfcheetah-2007_0307",
        "afonsosamarques/ardt-simplest-dataset_combo_train_halfcheetah_v1-1907_1733",
        "afonsosamarques/ardt-simplest-dataset_combo_train_halfcheetah_v1-1907_2302",
        "afonsosamarques/ardt-simplest-dataset_combo_train_halfcheetah_v1-2007_0418",
        "afonsosamarques/ardt-simplest-nrmdp_train_halfcheetah_v4-1907_1752",
        "afonsosamarques/ardt-simplest-nrmdp_train_halfcheetah_v4-1907_2346",
        "afonsosamarques/ardt-simplest-nrmdp_train_halfcheetah_v4-2007_0517"
    ],
    "MBartForConditionalGeneration": [
        "ARTeLab/mbart-summarization-fanpage",
        "ARTeLab/mbart-summarization-mlsum",
        "Babelscape/mrebel-large",
        "Babelscape/mrebel-large-32",
        "DeepPavlov/mbart-large-50-ru-persona-chat",
        "DunnBC22/mbart-large-50-English_Spanish_Translation",
        "ELiRF/mbart-large-cc25-dacsa-es",
        "IlyaGusev/mbart_ru_sum_gazeta",
        "Jezia/AraBART-finetuned-wiki-ar",
        "Kirili4ik/mbart_ruDialogSum",
        "MRNH/mbart-english-grammar-corrector",
        "Narrativa/mbart-large-50-finetuned-opus-pt-en-translation",
        "Ransaka/mbart-large-cc25-8bit",
        "Sunbird/mbart-mul-en",
        "Sunbird/sunbird-mul-en-mbart-merged",
        "abdalrahmanshahrour/AraBART-summ",
        "abdalrahmanshahrour/arabartsummarization",
        "abdalrahmanshahrour/auto-arabic-summarization",
        "ai4bharat/IndicBART",
        "ai4bharat/IndicBART-XLSum",
        "ai4bharat/IndicBART-XXEN",
        "ai4bharat/IndicBARTSS",
        "ai4bharat/MultiIndicParaphraseGeneration",
        "ai4bharat/MultiIndicParaphraseGenerationSS",
        "akhooli/mbart-large-cc25-en-ar",
        "bmd1905/vietnamese-correction",
        "cerindam30/tugas_akhir_final",
        "context-mt/scat-mbart50-1toM-target-ctx4-cwd0-en-fr",
        "ctu-aic/mbart25-multilingual-summarization-multilarge-cs",
        "d0rj/ru-mbart-large-summ",
        "eslamxm/mbart-finetune-ar-xlsum",
        "facebook/mbart-large-50",
        "facebook/mbart-large-50-many-to-many-mmt",
        "facebook/mbart-large-50-many-to-one-mmt",
        "facebook/mbart-large-50-one-to-many-mmt",
        "facebook/mbart-large-cc25",
        "facebook/mgenre-wiki",
        "hazemOmrann14/auto-arabic-summarization-finetuned-xsum",
        "hf-internal-testing/tiny-random-MBartForConditionalGeneration",
        "hyunwoongko/asian-bart-ecjk",
        "indobenchmark/indobart-v2",
        "joefox/mbart-large-ru-zh-ru-many-to-many-mmt",
        "ken11/mbart-ja-en",
        "ku-nlp/bart-base-japanese",
        "ku-nlp/bart-large-japanese",
        "lgrobol/mbart-minuscule",
        "lincoln/barthez-squadFR-fquad-piaf-question-generation",
        "lmqg/mbart-large-cc25-dequad-qag",
        "lmqg/mbart-large-cc25-koquad-qag",
        "ml6team/mbart-large-cc25-cnn-dailymail-nl",
        "ml6team/mbart-large-cc25-cnn-dailymail-nl-finetune",
        "moussaKam/barthez",
        "moussaKam/barthez-orangesum-abstract",
        "moussaKam/barthez-orangesum-title",
        "moussaKam/mbarthez",
        "moussaKam/mbarthez-dialogue-summarization",
        "mrm8488/mbart-large-finetuned-opus-en-es-translation",
        "trl-internal-testing/tiny-random-MBartForConditionalGeneration",
        "vasudevgupta/mbart-bhasha-hin-eng",
        "vinai/vinai-translate-en2vi",
        "vinai/vinai-translate-vi2en"
    ],
    "OPTForCausalLM": [
        "Aalaa/opt-125m-wikitext2",
        "AdamG012/chat-opt-1.3b-rlhf-actor-deepspeed",
        "AdamG012/chat-opt-1.3b-rlhf-actor-ema-deepspeed",
        "AdamG012/chat-opt-1.3b-sft-deepspeed",
        "AdamG012/chat-opt-350m-reward-deepspeed",
        "FabbriSimo01/Facebook_opt_1.3b_Quantized",
        "GeorgiaTechResearchInstitute/galactica-30b-evol-instruct-70k",
        "GeorgiaTechResearchInstitute/galactica-6.7b-evol-instruct-70k",
        "GeorgiaTechResearchInstitute/galpaca-30b",
        "InterruptAI/Interrupt-350M",
        "KimSHine/opt-1.3b-strategy-0728",
        "KoboldAI/OPT-13B-Erebus",
        "KoboldAI/OPT-13B-Nerybus-Mix",
        "KoboldAI/OPT-13B-Nerys-v2",
        "KoboldAI/OPT-2.7B-Erebus",
        "KoboldAI/OPT-2.7B-Nerybus-Mix",
        "KoboldAI/OPT-2.7B-Nerys-v2",
        "KoboldAI/OPT-30B-Erebus",
        "KoboldAI/OPT-350M-Erebus",
        "KoboldAI/OPT-350M-Nerys-v2",
        "KoboldAI/OPT-6.7B-Erebus",
        "KoboldAI/OPT-6.7B-Nerybus-Mix",
        "KoboldAI/OPT-6B-nerys-v2",
        "MayaPH/FinOPT-Franklin",
        "MayaPH/FinOPT-Lincoln",
        "MayaPH/FinOPT-Washington",
        "OpenAssistant/galactica-6.7b-finetuned",
        "PygmalionAI/pygmalion-350m",
        "TheBloke/galpaca-30B-GPTQ-4bit-128g",
        "Zicara/OPT-30B-Erebus-4bit-128g",
        "aburnazy/opt-125m-alpaca-am-wiki",
        "aburnazy/opt-350m-hy",
        "aburnazy/opt125m_alpaca",
        "aisquared/chopt-1_3b",
        "aisquared/chopt-2_7b",
        "akoksal/LongForm-OPT-125M",
        "concedo/OPT-19M-ChatSalad",
        "concedo/koboldcpp",
        "facebook/galactica-1.3b",
        "facebook/galactica-120b",
        "facebook/galactica-125m",
        "facebook/galactica-30b",
        "facebook/galactica-6.7b",
        "facebook/opt-1.3b",
        "facebook/opt-125m",
        "facebook/opt-13b",
        "facebook/opt-2.7b",
        "facebook/opt-30b",
        "facebook/opt-350m",
        "facebook/opt-6.7b",
        "facebook/opt-66b",
        "facebook/opt-iml-1.3b",
        "facebook/opt-iml-30b",
        "facebook/opt-iml-max-1.3b",
        "facebook/opt-iml-max-30b",
        "hf-internal-testing/tiny-random-OPTForCausalLM",
        "linkanjarad/OPT-Alpaca-125M",
        "lnair/opt-1.3b-wikitext2",
        "lnair/opt-350m-wikitext2",
        "notstoic/OPT-13B-Erebus-4bit-128g",
        "notstoic/OPT-13B-Nerybus-Mix-4bit-128g",
        "prasanna2003/opt-350m-instruct",
        "pszemraj/opt-350m-email-generation",
        "seonglae/opt-125m-4bit-gptq",
        "sr5434/gptQuotes",
        "trl-internal-testing/tiny-random-OPTForCausalLM"
    ],
    "VisionEncoderDecoderModel": [
        "Abdou/vit-swin-base-224-gpt2-image-captioning",
        "Apocalypse-19/trocr-MICR",
        "Chaymaa/donut-RotAug1",
        "Chaymaa/donut-demo-grdf",
        "Chaymaa/donut-demo-grdf2",
        "Chaymaa/donut-demo-grdf3",
        "Chaymaa/donut-demo-grdf3-v2",
        "DunnBC22/trocr-base-handwritten-OCR-handwriting_recognition_v2",
        "DunnBC22/trocr-base-printed-synthetic_dataset_ocr",
        "DunnBC22/trocr-base-printed_captcha_ocr",
        "DunnBC22/trocr-base-printed_license_plates_ocr",
        "DunnBC22/trocr-large-printed-cmc7_tesseract_MICR_ocr",
        "Flova/omr_transformer",
        "ITNovaML/invoices-donut-model-v1",
        "Maciel/Muge-Image-Caption",
        "Neleac/timesformer-gpt2-video-captioning",
        "ShekDass/donut-base-cord-smart-86",
        "TeamFnord/manga-ocr",
        "UBC-NLP/Qalam",
        "Zayn/AICVTG_What_if_a_machine_could_create_captions_automatically",
        "agomberto/trocr-base-printed-fr",
        "ahmed-masry/unichart-base-960",
        "ahmed-masry/unichart-chartqa-960",
        "atasoglu/vit-gpt2-flickr8k",
        "binery/donut_receipt_v1.20",
        "binery/donut_receipt_v2.29",
        "bipin/image-caption-generator",
        "circulus/kovit-caption-v1",
        "daekeun-ml/ko-trocr-base-nsmc-news-chatbot",
        "ddobokki/ko-trocr",
        "dodogeny/marshmallow-finetuned-cord-v2",
        "dragonstar/image-text-captcha-v2",
        "fruk19/donut_nfact_v3",
        "fxmarty/tiny-doc-qa-vision-encoder-decoder",
        "hf-internal-testing/tiny-random-VisionEncoderDecoderModel-vit-gpt2",
        "hf-internal-testing/tiny-random-vit-gpt2",
        "ivelin/donut-refexp-combined-v1",
        "jinhybr/OCR-DocVQA-Donut",
        "jinhybr/OCR-Donut-CORD",
        "joeljohansson/sampled-tickets-model",
        "katanaml-org/invoices-donut-model-v1",
        "katanaml/donut-demo",
        "kha-white/manga-ocr-base",
        "microsoft/trocr-base-handwritten",
        "microsoft/trocr-base-printed",
        "microsoft/trocr-base-stage1",
        "microsoft/trocr-base-str",
        "microsoft/trocr-large-handwritten",
        "microsoft/trocr-large-printed",
        "microsoft/trocr-large-stage1",
        "microsoft/trocr-large-str",
        "microsoft/trocr-small-handwritten",
        "microsoft/trocr-small-printed",
        "microsoft/trocr-small-stage1",
        "naver-clova-ix/donut-base",
        "naver-clova-ix/donut-base-finetuned-cord-v1",
        "naver-clova-ix/donut-base-finetuned-cord-v1-2560",
        "naver-clova-ix/donut-base-finetuned-cord-v2",
        "naver-clova-ix/donut-base-finetuned-docvqa",
        "naver-clova-ix/donut-base-finetuned-rvlcdip",
        "naver-clova-ix/donut-base-finetuned-zhtrainticket",
        "naver-clova-ix/donut-proto",
        "nielsr/donut-base",
        "nielsr/donut-base-finetuned-cord-v2",
        "nielsr/donut-base-finetuned-docvqa",
        "nielsr/donut-demo",
        "nielsr/donut-docvqa-demo",
        "nlpconnect/vit-gpt2-image-captioning",
        "nttdataspain/vit-gpt2-stablediffusion2-lora",
        "paturi1710/donut-docvqa-v1.0",
        "philschmid/donut-base-sroie",
        "philschmid/trocr-base-printed",
        "rhovhannisyan/dmr-invoice-extractor",
        "sachin/vit2distilgpt2",
        "sakib131/donut-bn-LP",
        "shivi/donut-cheque-parser",
        "svjack/vit-gpt-diffusion-zh",
        "team-lucid/trocr-small-korean",
        "thivy/num-trocr-large-handwritten-v1",
        "to-be/donut-base-finetuned-invoices",
        "tuman/vit-rugpt2-image-captioning",
        "unstructuredio/donut-base-sroie",
        "unstructuredio/ved-fine-tuning",
        "ydshieh/vit-gpt2-coco-en",
        "ydshieh/vit-gpt2-coco-en-ckpts",
        "yhshin/latex-ocr",
        "yuanzhoulvpi/vit-gpt2-image-chinese-captioning",
        "zenoda/trocr-captcha-killer"
    ],
    "SwinForImageClassification": [
        "Ahmed9275/ALL-3",
        "Ahmed9275/ALL-test",
        "Annabelleabbott/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "GRANTHE2761/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "KL/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "Kaludi/food-category-classification-v2.0",
        "Matthijs/snacks-classifier",
        "MazenAmria/swin-tiny-finetuned-cifar100",
        "Neruoy/swin-finetuned-food101-e3",
        "aricibo/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "fufufukakaka/pokemon_image_classifier",
        "guhuawuli/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "hf-internal-testing/tiny-random-SwinForImageClassification",
        "ibombonato/swin-age-classifier",
        "jemole/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "mbyanfei/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "mehnaazasad/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "microsoft/swin-base-patch4-window12-384",
        "microsoft/swin-base-patch4-window12-384-in22k",
        "microsoft/swin-base-patch4-window7-224",
        "microsoft/swin-base-patch4-window7-224-in22k",
        "microsoft/swin-large-patch4-window12-384",
        "microsoft/swin-large-patch4-window12-384-in22k",
        "microsoft/swin-large-patch4-window7-224",
        "microsoft/swin-large-patch4-window7-224-in22k",
        "microsoft/swin-small-patch4-window7-224",
        "microsoft/swin-tiny-patch4-window7-224",
        "nickmuchi/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "nielsr/swin-tiny-patch4-window7-224-finetuned-cifar10",
        "nielsr/swin-tiny-patch4-window7-224-finetuned-eurosat",
        "skylord/swin-finetuned-food101"
    ],
    "GPTNeoForCausalLM": [
        "AhmedTaha012/gptneo-TxtToJson-v0.2.0",
        "Amrrs/sd-prompt-generator-gpt-neo",
        "Daoguang/PyCodeGPT",
        "Deepthoughtworks/gpt-neo-2.7B__low-cpu",
        "DrishtiSharma/StableDiffusion-Prompt-Generator-GPT-Neo-125M",
        "EleutherAI/gpt-neo-1.3B",
        "EleutherAI/gpt-neo-125m",
        "EleutherAI/gpt-neo-2.7B",
        "FrostAura/gpt-neo-1.3B-fiction-novel-generation",
        "Harshvir/LaMini-Neo-1.3B-Mental-Health_lora",
        "HeyLucasLeao/gpt-neo-small-portuguese",
        "IlyaGusev/rulm_gpt_neo_small",
        "KadeLoertscher/Lyric-Lyft-Model",
        "KaiyuanDu/demo",
        "KoboldAI/GPT-Neo-1.3B-Adventure",
        "KoboldAI/GPT-Neo-125M-AID",
        "KoboldAI/GPT-Neo-2.7B-AID",
        "KoboldAI/GPT-Neo-2.7B-Horni",
        "KoboldAI/GPT-Neo-2.7B-Horni-LN",
        "KoboldAI/GPT-Neo-2.7B-Janeway",
        "KoboldAI/GPT-Neo-2.7B-Picard",
        "KoboldAI/GPT-Neo-2.7B-Shinen",
        "MBZUAI/LaMini-Neo-1.3B",
        "MBZUAI/LaMini-Neo-125M",
        "Merry/AID-Neo-125M",
        "NlpHUST/gpt-neo-vi-small",
        "Norod78/hebrew-gpt_neo-small",
        "Norod78/hebrew-gpt_neo-tiny",
        "Norod78/hebrew-gpt_neo-xl",
        "OptimalScale/gpt-neo2.7B-inst-tuning",
        "PygmalionAI/pygmalion-2.7b",
        "Shanav12/swift_lyrics_final",
        "Tincando/fiction_story_generator",
        "VietAI/gpt-neo-1.3B-vietnamese-news",
        "achrekarom/text_generation",
        "arun-shankar/ChatGPT-Neo",
        "b3ck1/gpt-neo-125M-finetuned-beer-recipes",
        "cactusfriend/nightmare-invokeai-prompts",
        "cactusfriend/nightmare-promptgen-XL",
        "callMeRover/yum",
        "chelvan/Gpt-Neo_1.3B_Stock_Prediction",
        "dumitrescustefan/gpt-neo-romanian-780m",
        "edbeeching/gpt-neo-125M-imdb",
        "flax-community/gpt-neo-125M-apps-all",
        "flax-community/gpt-neo-125M-code-clippy",
        "flax-community/gpt-neo-125M-code-clippy-dedup-2048",
        "gmongaras/gpt-anime-sub-1.3B",
        "hakurei/lit-125M",
        "hf-internal-testing/tiny-random-GPTNeoForCausalLM",
        "iliemihai/gpt-neo-romanian-125m",
        "josu/gpt-neo-pt-br",
        "lewiswatson/gptj-neo-1.3B_finetuned-enusec-talks-22",
        "minhtoan/gpt3-small-finetune-cnndaily-news",
        "ncfrey/ChemGPT-1.2B",
        "ncfrey/ChemGPT-4.7M",
        "ogimgio/gpt-neo-125m-neurallinguisticpioneers",
        "rautsrijana/Joyous_Jackals_Lyriclyft",
        "roneneldan/TinyStories-1Layer-21M",
        "roneneldan/TinyStories-1M",
        "roneneldan/TinyStories-28M",
        "roneneldan/TinyStories-2Layers-33M",
        "roneneldan/TinyStories-33M",
        "roneneldan/TinyStories-3M",
        "roneneldan/TinyStories-8M",
        "roneneldan/TinyStories-Instruct-1M",
        "roneneldan/TinyStories-Instruct-28M",
        "roneneldan/TinyStories-Instruct-2Layers-33M",
        "roneneldan/TinyStories-Instruct-33M",
        "roneneldan/TinyStories-Instruct-3M",
        "roneneldan/TinyStories-Instruct-8M",
        "roneneldan/TinyStories-Instuct-1Layer-21M",
        "sullyd/PhilosophicalQuotes",
        "sumo43/agi-125m",
        "trl-internal-testing/tiny-random-GPTNeoForCausalLM",
        "tsdocode/text-to-sql",
        "usamakenway/Stable-diffusion-prompt-generator-1m-examples",
        "xhyi/PT_GPTNEO350_ATG",
        "ybelkada/gpt-neo-125m-detox"
    ],
    "DistilBertForTokenClassification": [
        "AkimfromParis/NER-Luxury",
        "CouchCat/ma_ner_v7_distil",
        "Davlan/distilbert-base-multilingual-cased-masakhaner",
        "Davlan/distilbert-base-multilingual-cased-ner-hrl",
        "HooshvareLab/distilbert-fa-zwnj-base-ner",
        "Iceland/quote-model-delta",
        "Lunerwalker2/claims-data-model",
        "Qishuai/distilbert_punctuator_en",
        "Trapita/NER-tushi",
        "algiraldohe/lm-ner-linkedin-skills-recognition",
        "autoevaluate/entity-extraction",
        "brettlin/distilbert-base-uncased-finetuned-ner",
        "chambliss/distilbert-for-food-extraction",
        "chilliadgl/RG_fake_signatures",
        "d4data/biomedical-ner-all",
        "dmargutierrez/distilbert-base-multilingual-cased-mapa_coarse-ner",
        "elastic/distilbert-base-cased-finetuned-conll03-english",
        "elastic/distilbert-base-uncased-finetuned-conll03-english",
        "gunghio/distilbert-base-multilingual-cased-finetuned-conll2003-ner",
        "helenai/elastic-distilbert-base-cased-finetuned-conll03-english-ov",
        "hf-internal-testing/tiny-random-DistilBertForTokenClassification",
        "hf-tiny-model-private/tiny-random-DistilBertForTokenClassification",
        "ismail-lucifer011/autotrain-company_all-903429548",
        "ismail-lucifer011/autotrain-job_all-903929564",
        "ismail-lucifer011/autotrain-name_all-904029577",
        "issifuamajeed/distilbert-base-uncased-finetuned-ner",
        "kolj4/few_nerd",
        "m3hrdadfi/typo-detector-distilbert-en",
        "malduwais/distilbert-base-uncased-finetuned-ner",
        "manishiitg/resume-ner",
        "ml6team/keyphrase-extraction-distilbert-inspec",
        "ml6team/keyphrase-extraction-distilbert-kptimes",
        "ml6team/keyphrase-extraction-distilbert-openkp",
        "mrm8488/distilbert-base-multi-cased-finetuned-typo-detection",
        "nickprock/distilbert-finetuned-ner-ontonotes",
        "osiria/distilbert-italian-cased-ner",
        "pierrerappolt-okta/app",
        "rcds/distilbert-SBD-de-judgements-laws",
        "silpakanneganti/bert-medical-ner",
        "stevhliu/my_awesome_wnut_model",
        "ui-chope/distilbert-base-uncased-finetuned-ner",
        "vishnun/knowledge-graph-nlp",
        "whispAI/DirectQuote-SentLevel-DistilBERT"
    ],
    "ConvNextForImageClassification": [
        "AkshatSurolia/ConvNeXt-FaceMask-Finetuned",
        "BIDEQUITY/autotrain-software_picture_preselection_classifier-2804582686",
        "Calin/convnext-tiny-finteuned-eurosat",
        "Soulaimen/convnext-large-224-22k-1k-LongSleeveCleanedData",
        "Soulaimen/convnext-large-224-22k-1k-bottomCleanedData",
        "Soulaimen/convnext-large-224-22k-1k-convnext_short_sleeve_data_cleaned",
        "SyedMujtabaHassanRizvi/convnext-tiny-finetuned-eurosat",
        "ahsanjavid/convnext-tiny-finetuned-cifar10",
        "davanstrien/convnext_manuscript_iiif",
        "facebook/convnext-base-224",
        "facebook/convnext-base-224-22k",
        "facebook/convnext-base-224-22k-1k",
        "facebook/convnext-base-384",
        "facebook/convnext-base-384-22k-1k",
        "facebook/convnext-large-224",
        "facebook/convnext-large-224-22k",
        "facebook/convnext-large-224-22k-1k",
        "facebook/convnext-large-384",
        "facebook/convnext-large-384-22k-1k",
        "facebook/convnext-small-224",
        "facebook/convnext-tiny-224",
        "facebook/convnext-xlarge-224-22k",
        "facebook/convnext-xlarge-224-22k-1k",
        "facebook/convnext-xlarge-384-22k-1k",
        "flyswot/convnext-tiny-224_flyswot",
        "flyswot/flyswot",
        "hf-internal-testing/tiny-random-ConvNextForImageClassification",
        "hf-internal-testing/tiny-random-convnext",
        "mrm8488/convnext-tiny-finetuned-beans",
        "mrm8488/convnext-tiny-finetuned-eurosat",
        "nielsr/convnext-tiny-224-finetuned-eurosat-albumentations",
        "nielsr/convnext-tiny-finetuned-eurosat",
        "nielsr/convnext-tiny-finetuned-eurostat",
        "nielsr/convnext-xlarge-224-22k",
        "nielsr/convnext-xlarge-224-22k-1k"
    ],
    "XLMRobertaForQuestionAnswering": [
        "AlexKay/xlm-roberta-large-qa-multilingual-finedtuned-ru",
        "AswiN037/xlm-roberta-squad-tamil",
        "CodeNinja1126/xlm-roberta-large-kor-mrc",
        "SajjadAyoubi/xlm-roberta-large-fa-qa",
        "ZTamas/xlm-roberta-large-squad2_impossible_long_answer",
        "alon-albalak/xlm-roberta-base-xquad",
        "alon-albalak/xlm-roberta-large-xquad",
        "ancs21/xlm-roberta-large-vi-qa",
        "bhavikardeshna/xlm-roberta-base-arabic",
        "deepset/xlm-roberta-base-squad2",
        "deepset/xlm-roberta-base-squad2-distilled",
        "deepset/xlm-roberta-large-squad2",
        "gaussalgo/xlm-roberta-large_extractive-QA_en-cs",
        "helenai/deepset-xlm-roberta-base-squad2-ov",
        "helenai/deepset-xlm-roberta-large-squad2-ov",
        "m3hrdadfi/xlmr-large-qa-fa",
        "nguyenvulebinh/vi-mrc-base",
        "nguyenvulebinh/vi-mrc-large",
        "pedramyazdipoor/persian_xlm_roberta_large",
        "robinhad/ukrainian-qa",
        "svalabs/infoxlm-german-question-answering"
    ],
    "AlbertForSequenceClassification": [
        "Alireza1044/albert-base-v2-cola",
        "Alireza1044/albert-base-v2-mnli",
        "Alireza1044/albert-base-v2-mrpc",
        "Alireza1044/albert-base-v2-qnli",
        "Alireza1044/albert-base-v2-sst2",
        "Alireza1044/albert-base-v2-stsb",
        "Alireza1044/albert-base-v2-wnli",
        "AnReu/albert-for-math-ar-base-ft",
        "DAMO-NLP-SG/zero-shot-classify-SSTuning-ALBERT",
        "Intel/albert-base-v2-sst2-int8-dynamic",
        "Intel/albert-base-v2-sst2-int8-static",
        "JanSt/albert-base-v2_mbti-classification",
        "XSY/albert-base-v2-fakenews-discriminator",
        "albertvillanova/autonlp-indic_glue-multi_class_classification-1e67664-1311135",
        "antonioalvarado/text_analyzer_albert-base-v2",
        "bhadresh-savani/albert-base-v2-emotion",
        "bongsoo/albert-small-kor-cross-encoder-v1",
        "clhuang/albert-news-classification",
        "dccuchile/albert-base-10-spanish-finetuned-mldoc",
        "hf-internal-testing/tiny-random-AlbertForSequenceClassification",
        "l3cube-pune/MarathiSentiment",
        "m3hrdadfi/albert-fa-base-v2-clf-persiannews",
        "pykeio/lite-toxic-comment-classification",
        "tals/albert-xlarge-vitaminc",
        "tals/albert-xlarge-vitaminc-mnli",
        "textattack/albert-base-v2-CoLA",
        "textattack/albert-base-v2-SST-2",
        "textattack/albert-base-v2-ag-news",
        "textattack/albert-base-v2-imdb",
        "textattack/albert-base-v2-snli",
        "vineet1409/fine-tuned-AlBERT",
        "vlsb/autotrain-security-text-classification-albert-688320769",
        "voidful/albert_chinese_small_sentiment",
        "vumichien/albert-base-v2-imdb",
        "ynie/albert-xxlarge-v2-snli_mnli_fever_anli_R1_R2_R3-nli"
    ],
    "SegformerForSemanticSegmentation": [
        "AlmogM/segformer-b0-finetuned-fish-almogm",
        "ChristianMDahl/segFormer-b3-horizontal-vertical",
        "DiTo97/binarization-segformer-b3",
        "Efferbach/segformer-finetuned-lane-10k-steps",
        "Efferbach/segformer-finetuned-lane-1k-steps",
        "FranciscoGaribaldi/segformer_B5_corn",
        "Jalilov/doc-segment",
        "Lexic0n/segformer-b0-finetuned-human-parsing",
        "MariaK/scene_segmentation",
        "Onegafer/segformer-v-mesh-0",
        "alanoix/segformer_b0_flair_one",
        "andrewljohnson/segformer-b0-finetuned-magic-cards-230117",
        "andrewljohnson/segformer-b5-finetuned-magic-cards-230117-2",
        "andrewljohnson/segformer-b5-finetuned-magic-cards-230117-3",
        "aurioldegbelo/slm-segformer",
        "bilal01/segformer-b0-finetuned-segments-sidewalk-2",
        "bilal01/segformer-b0-finetuned-segments-stamp-verification",
        "bilal01/segformer-b0-finetuned-segments-test",
        "blzncz/segformer-finetuned-4ss1st3r_s3gs3m-10k-steps",
        "chainyo/segformer-b1-sidewalk",
        "chainyo/segformer-sidewalk",
        "deep-learning-analytics/segformer_semantic_segmentation",
        "deprem-ml/deprem_satellite_semantic_whu",
        "enes361/segformer_b2_clothes",
        "hf-internal-testing/tiny-random-SegformerForSemanticSegmentation",
        "hufanyoung/segformer-b0-finetuned-segments-sidewalk-2",
        "imadd/segformer-b0-finetuned-segments-water-2",
        "irfan-noordin/segformer-b0-finetuned-segments-sidewalk-oct-22",
        "jonathandinu/face-parsing",
        "koushikn/segformer-finetuned-Maize-10k-steps-sem",
        "lapix/segformer-b3-finetuned-ccagt-400-300",
        "malra/segformer-b0-finetuned-segments-sidewalk-4",
        "malra/segformer-b5-segments-warehouse1",
        "matei-dorian/segformer-b0-finetuned-human-parsing",
        "matei-dorian/segformer-b5-finetuned-human-parsing",
        "matnun/segformer-b0-finetuned-segments-sidewalk-2",
        "mattmdjaga/segformer_b0_clothes",
        "mattmdjaga/segformer_b2_clothes",
        "millionhz/segformer-b0-finetuned-flame",
        "mraottth/trashbot_v1",
        "nickmuchi/segformer-b4-finetuned-segments-sidewalk",
        "nielsr/segformer-b0-finetuned-segments-sidewalk",
        "nielsr/segformer-finetuned-sidewalk",
        "nielsr/segformer-finetuned-sidewalk-10k-steps",
        "nielsr/segformer-test-sidewalk-v2",
        "nielsr/segformer-test-v5",
        "nielsr/segformer-test-v6",
        "nielsr/segformer-test-v7",
        "nielsr/segformer-trainer-test-bis",
        "nielsr/sidewalk-semantic-demo",
        "nvidia/segformer-b0-finetuned-ade-512-512",
        "nvidia/segformer-b0-finetuned-cityscapes-1024-1024",
        "nvidia/segformer-b0-finetuned-cityscapes-512-1024",
        "nvidia/segformer-b0-finetuned-cityscapes-640-1280",
        "nvidia/segformer-b0-finetuned-cityscapes-768-768",
        "nvidia/segformer-b1-finetuned-ade-512-512",
        "nvidia/segformer-b1-finetuned-cityscapes-1024-1024",
        "nvidia/segformer-b2-finetuned-ade-512-512",
        "nvidia/segformer-b2-finetuned-cityscapes-1024-1024",
        "nvidia/segformer-b3-finetuned-ade-512-512",
        "nvidia/segformer-b3-finetuned-cityscapes-1024-1024",
        "nvidia/segformer-b4-finetuned-ade-512-512",
        "nvidia/segformer-b4-finetuned-cityscapes-1024-1024",
        "nvidia/segformer-b5-finetuned-ade-640-640",
        "nvidia/segformer-b5-finetuned-cityscapes-1024-1024",
        "optimum/segformer-b0-finetuned-ade-512-512",
        "plant/segformer-b5-finetuned-segments-instryde-foot-test",
        "prem-timsina/segformer-b0-finetuned-food",
        "reannayang/segformer-b0-pavement",
        "s3nh/SegFormer-b0-person-segmentation",
        "s3nh/SegFormer-b4-person-segmentation",
        "s3nh/SegFormer-b5-person-segm",
        "sam1120/segformer-b0-finetuned-neurosymbolic-contingency-bag1-v0.1-v0",
        "sayakpaul/mit-b0-finetuned-sidewalk-semantic",
        "segments-tobias/segformer-b0-finetuned-segments-sidewalk",
        "segments-tobias/segformer-b3-finetuned-segments-sidewalk",
        "shaheen1998/segformer-b0-finetuned-segments-sidewalk-2",
        "varcoder/segformer-b4-crack-segmentation-dataset",
        "venture361/clothes_segmentation",
        "yiming19/segformer-b0-finetuned-segments-construction-1",
        "zklee98/segformer-b1-solarModuleAnomaly-v0.1",
        "zoheb/mit-b5-finetuned-sidewalk-semantic"
    ],
    "Wav2Vec2ForPreTraining": [
        "Alvenir/wav2vec2-base-da",
        "LIA-AvignonUniversity/IWSLT2022-tamasheq-only",
        "TencentGameMate/chinese-wav2vec2-base",
        "TencentGameMate/chinese-wav2vec2-large",
        "chcaa/xls-r-300m-danish",
        "facebook/mms-1b",
        "facebook/mms-300m",
        "facebook/wav2vec2-base",
        "facebook/wav2vec2-base-100k-voxpopuli",
        "facebook/wav2vec2-base-ro-voxpopuli-v2",
        "facebook/wav2vec2-large",
        "facebook/wav2vec2-large-100k-voxpopuli",
        "facebook/wav2vec2-large-es-voxpopuli",
        "facebook/wav2vec2-large-it-voxpopuli",
        "facebook/wav2vec2-large-lv60",
        "facebook/wav2vec2-large-robust",
        "facebook/wav2vec2-large-xlsr-53",
        "facebook/wav2vec2-xls-r-1b",
        "facebook/wav2vec2-xls-r-2b",
        "facebook/wav2vec2-xls-r-300m",
        "nguyenvulebinh/wav2vec2-base-vi",
        "nguyenvulebinh/wav2vec2-large-vi",
        "patrickvonplaten/wav2vec2-base",
        "patrickvonplaten/wav2vec2-base-v2",
        "wbbbbb/wav2vec2-large-chinese-zh-cn"
    ],
    "RobertaForQuestionAnswering": [
        "AmazonScience/qanlu",
        "AntoineBlanot/roberta-large-squadv2",
        "Evelyn18/roberta-base-spanish-squades-becasv3",
        "Forturne/Klue_MRC_Model",
        "Forturne/qa_roberta_1",
        "IIC/roberta-base-bne-bioasq",
        "IIC/roberta-base-spanish-sqac",
        "PlanTL-GOB-ES/roberta-base-bne-sqac",
        "PlanTL-GOB-ES/roberta-large-bne-sqac",
        "Rakib/roberta-base-on-cuad",
        "Salesforce/discord_qa",
        "Salesforce/qaconv-roberta-large-squad2",
        "akdeniz27/roberta-base-cuad",
        "akdeniz27/roberta-large-cuad",
        "chau/autotrain-swot-roberta-base-distilled-3268791189",
        "consciousAI/question-answering-roberta-base-s",
        "consciousAI/question-answering-roberta-base-s-v2",
        "csarron/roberta-base-squad-v1",
        "dangkhoa99/roberta-base-finetuned-squad-v2",
        "dccuchile/bertin-roberta-base-spanish-finetuned-qa-tar",
        "deepset/roberta-base-squad2",
        "deepset/roberta-base-squad2-covid",
        "deepset/roberta-base-squad2-distilled",
        "deepset/roberta-large-squad2",
        "deepset/tinyroberta-squad2",
        "egorishti/roberta-based-qa-model-test",
        "etalab-ia/camembert-base-squadFR-fquad-piaf",
        "etweedy/roberta-base-squad-v2",
        "gaotianyu1350/roberta-large-squad",
        "giangduong/finetune-viquad",
        "gustavhartz/roberta-base-cuad-finetuned",
        "helenai/deepset-roberta-base-squad2-ov",
        "hf-internal-testing/tiny-random-RobertaForQuestionAnswering",
        "marshmellow77/roberta-base-cuad",
        "mbartolo/roberta-large-synqa-ext",
        "mbeck/roberta-base-squad2",
        "microsoft/xdoc-base-squad2.0",
        "mrm8488/longformer-base-4096-spanish-finetuned-squad",
        "nlpconnect/roberta-base-squad2-nq",
        "optimum/roberta-base-squad2",
        "radlab/polish-roberta-large-v2-qa",
        "saiful9379/Bangla_Roberta_Question_and_Answer",
        "sguskin/minilmv2-L6-H384-squad1.1",
        "sunitha/CV_Custom_DS",
        "syndi-models/roberta-base-squad2",
        "thatdramebaazguy/roberta-base-squad",
        "tsmatz/roberta_qa_japanese",
        "twmkn9/distilroberta-base-squad2",
        "uomnf97/klue-roberta-finetuned-korquad-v2",
        "vanadhi/roberta-base-fiqa-flm-sq-flit",
        "veronica320/QA-for-Event-Extraction",
        "ydshieh/roberta-base-squad2"
    ],
    "BertForPreTraining": [
        "AnReu/math_pretrained_bert",
        "Charangan/MedBERT",
        "CleverShovel/rubert-tiny2-tnved-v3",
        "CleverShovel/rubert-tiny2-tnved-v4",
        "Intel/bert-base-uncased-sparse-85-unstructured-pruneofa",
        "Intel/bert-base-uncased-sparse-90-unstructured-pruneofa",
        "TurkuNLP/eccobert-base-cased-v1",
        "UWB-AIR/Czert-B-base-cased",
        "adsabs/astroBERT",
        "alexaapo/greek_legal_bert_v2",
        "bigcode/starencoder",
        "bongsoo/bert-base-kor-v1",
        "cl-tohoku/bert-base-japanese-char-v3",
        "cl-tohoku/bert-base-japanese-v3",
        "cl-tohoku/bert-large-japanese-char-v2",
        "cl-tohoku/bert-large-japanese-v2",
        "clincolnoz/LessSexistBERT",
        "clincolnoz/MoreSexistBERT",
        "cointegrated/LaBSE-en-ru",
        "cointegrated/rubert-tiny",
        "cointegrated/rubert-tiny2",
        "dkleczek/bert-base-polish-cased-v1",
        "dkleczek/bert-base-polish-uncased-v1",
        "explosion-testing/bert-test-sharded",
        "giacomomiolo/scibert_reupload",
        "google/multiberts-seed_0",
        "google/multiberts-seed_0-step_0k",
        "google/multiberts-seed_0-step_100k",
        "google/multiberts-seed_0-step_2000k",
        "google/multiberts-seed_0-step_200k",
        "google/multiberts-seed_1",
        "hf-tiny-model-private/tiny-random-BertForPreTraining",
        "izumi-lab/bert-base-japanese-fin-additional",
        "lassl/bert-ko-small",
        "law-ai/InLegalBERT",
        "lysandre/tiny-bert-random",
        "nlpaueb/bert-base-greek-uncased-v1",
        "nlpaueb/legal-bert-base-uncased",
        "nlpaueb/sec-bert-base",
        "nlpaueb/sec-bert-shape",
        "pvl/labse_bert",
        "schen/longformer-chinese-base-4096",
        "seiya/oubiobert-base-uncased",
        "slone/LaBSE-shallow-distilled-bak",
        "taishi-i/nagisa_bert",
        "trueto/medbert-base-chinese",
        "yemen2016/memo_model"
    ],
    "GPTBigCodeForCausalLM": [
        "ArmelR/starcoder-gradio-v0",
        "GeorgiaTechResearchInstitute/starcoder-gpteacher-code-instruct",
        "HuggingFaceH4/starchat-alpha",
        "HuggingFaceH4/starchat-beta",
        "LoupGarou/WizardCoder-Guanaco-15B-V1.0",
        "LoupGarou/WizardCoder-Guanaco-15B-V1.1",
        "Narsil/starcoder-gptq",
        "TabbyML/SantaCoder-1B",
        "TheBloke/Redmond-Hermes-Coder-GPTQ",
        "TheBloke/Starcoderplus-Guanaco-GPT4-15B-V1.0-GPTQ",
        "TheBloke/WizardCoder-15B-1.0-GPTQ",
        "TheBloke/WizardCoder-Guanaco-15B-V1.0-GPTQ",
        "TheBloke/WizardCoder-Guanaco-15B-V1.1-GPTQ",
        "TheBloke/starchat-beta-GPTQ",
        "TheBloke/starcoder-GPTQ",
        "TheBloke/starcoderplus-GPTQ",
        "WizardLM/WizardCoder-15B-V1.0",
        "bigcode/gpt_bigcode-santacoder",
        "bigcode/starcoder",
        "bigcode/starcoderbase",
        "bigcode/starcoderbase-1b",
        "bigcode/starcoderbase-3b",
        "bigcode/starcoderbase-7b",
        "bigcode/starcoderplus",
        "bigcode/tiny_starcoder_py",
        "codecomplete/starcoderbase_fp16",
        "codecomplete/starcoderbase_int8",
        "codeparrot/starcoder-self-instruct",
        "defog/starcoder-finetune",
        "frank098/starcoder-merged",
        "hf-internal-testing/tiny-random-GPTBigCodeForCausalLM",
        "openaccess-ai-collective/dodona-pyg-v8p4-15b-preview",
        "openchat/opencoderplus",
        "rahuldshetty/starchat-beta-8bit",
        "richardr1126/spider-natsql-wizard-coder-8bit",
        "richardr1126/spider-natsql-wizard-coder-merged",
        "richardr1126/spider-skeleton-wizard-coder-8bit",
        "thr10/thr-wlm-15b-3gb"
    ],
    "LEDForConditionalGeneration": [
        "ArtifactAI/led_base_16384_arxiv_summarization",
        "ArtifactAI/led_base_16384_billsum_summarization",
        "ArtifactAI/led_large_16384_arxiv_summarization",
        "ArtifactAI/led_large_16384_billsum_summarization",
        "HHousen/distil-led-large-cnn-16384",
        "MingZhong/DialogLED-base-16384",
        "MingZhong/DialogLED-large-5120",
        "Udit191/autotrain-summarization_bart_longformer-54164127153",
        "Xmm/led-large-16384-cnn_dailymail",
        "allenai/PRIMERA",
        "allenai/PRIMERA-arxiv",
        "allenai/PRIMERA-multinews",
        "allenai/PRIMERA-multixscience",
        "allenai/PRIMERA-wcep",
        "allenai/led-base-16384",
        "allenai/led-large-16384",
        "allenai/led-large-16384-arxiv",
        "hf-internal-testing/tiny-random-LEDForConditionalGeneration",
        "hyesunyun/update-summarization-bart-large-longformer",
        "lefnire/tisuth",
        "nsi319/legal-led-base-16384",
        "patrickvonplaten/led-large-16384-pubmed",
        "pszemraj/led-base-book-summary",
        "pszemraj/led-large-book-summary",
        "trl-internal-testing/tiny-random-LEDForConditionalGeneration"
    ],
    "PegasusForConditionalGeneration": [
        "AryanLala/autonlp-Scientific_Title_Generator-34558227",
        "DunnBC22/pegasus-multi_news-NewsSummarization_BBC",
        "IDEA-CCNL/Randeng-Pegasus-238M-Chinese",
        "IDEA-CCNL/Randeng-Pegasus-238M-Summary-Chinese",
        "IDEA-CCNL/Randeng-Pegasus-523M-Chinese",
        "IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese",
        "IDEA-CCNL/Randeng-Pegasus-523M-Summary-Chinese-V1",
        "Mapcar/pegasus-samsum",
        "SamAct/PromptGeneration-base",
        "Yale-LILY/brio-xsum-cased",
        "alireza7/ARMAN-MSR-persian-base",
        "alireza7/PEGASUS-persian-base",
        "geckos/pegasus-fined-tuned-on-paraphrase",
        "google/pegasus-arxiv",
        "google/pegasus-big_patent",
        "google/pegasus-billsum",
        "google/pegasus-cnn_dailymail",
        "google/pegasus-large",
        "google/pegasus-multi_news",
        "google/pegasus-newsroom",
        "google/pegasus-pubmed",
        "google/pegasus-reddit_tifu",
        "google/pegasus-wikihow",
        "google/pegasus-xsum",
        "hf-internal-testing/tiny-random-PegasusForConditionalGeneration",
        "human-centered-summarization/financial-summarization-pegasus",
        "knlpscience/pegasus-ft",
        "lvwerra/pegasus-samsum",
        "mikeadimech/pegasus-qmsum-meeting-summarization",
        "nsi319/legal-pegasus",
        "pszemraj/pegasus-large-summary-explain",
        "sshleifer/distill-pegasus-cnn-16-4",
        "sshleifer/distill-pegasus-xsum-16-4",
        "sshleifer/pegasus-cnn-ft-v2",
        "stas/pegasus-cnn_dailymail-tiny-random",
        "stevied67/pegasus-subreddit-comments-summarizer",
        "transformersbook/pegasus-samsum",
        "trl-internal-testing/tiny-random-PegasusForConditionalGeneration",
        "tuner007/pegasus_paraphrase",
        "tuner007/pegasus_qa",
        "tuner007/pegasus_summarizer",
        "usakha/Pegasus_MedPaper_model",
        "valurank/Pegasus_cnn_news_headline_generator",
        "valurank/final_headline_generator",
        "zedfum/arman-longformer-8k-finetuned-ensani"
    ],
    "DetrForObjectDetection": [
        "AterMors/detr-resnet-50_finetuned_animals",
        "Benito/DeTr-TableDetection-5000-images",
        "Darna/detr-5000-400-finetuned-table-detector",
        "Jonathancasjar/Retail_Shelves",
        "SalML/DETR-table-detection",
        "SalML/DETR-table-structure-recognition",
        "TahaDouaji/detr-doc-table-detection",
        "aditmohan96/detr-finetuned-face",
        "biglam/detr-resnet-50_fine_tuned_nls_chapbooks",
        "chiHang/detr-resnet50-finetuned_clothes007",
        "deepnight-research/object-detection-small",
        "devonho/detr-resnet-50_finetuned_cppe5",
        "elipark11/detr-finetune-v1",
        "facebook/detr-resnet-101",
        "facebook/detr-resnet-101-dc5",
        "facebook/detr-resnet-50",
        "facebook/detr-resnet-50-dc5",
        "hf-internal-testing/tiny-detr-mobilenetsv3",
        "hf-internal-testing/tiny-random-DetrForObjectDetection",
        "ismadoukkali/detr-resnet-50_finetuned_OCR",
        "nickmuchi/detr-resnet50-license-plate-detection",
        "nielsr/detr-finetuned-balloon",
        "nielsr/detr-table-detection",
        "nielsr/detr-table-structure-recognition",
        "taroii/finetuned-detr-50"
    ],
    "BartForSequenceClassification": [
        "AyoubChLin/Bart-MNLI-CNN_news",
        "CogComp/bart-faithful-summary-detector",
        "ModelTC/bart-base-mnli",
        "Softechlb/articles_classification",
        "ainize/bart-base-cnn",
        "deepnight-nexus/zsc-text",
        "deepnight-research/zsc-text",
        "dnzblgn/BART_Sentiment_Classification",
        "eleldar/theme-classification",
        "facebook/bart-large-mnli",
        "geckos/bart-fined-tuned-on-entailment-classification",
        "hf-internal-testing/tiny-random-BartForSequenceClassification",
        "joeddav/bart-large-mnli-yahoo-answers",
        "microsoft/tapex-large-finetuned-tabfact",
        "navteca/bart-large-mnli",
        "oigele/Fb_improved_zeroshot",
        "valhalla/bart-large-sst2",
        "valhalla/distilbart-mnli-12-1",
        "valhalla/distilbart-mnli-12-3",
        "valhalla/distilbart-mnli-12-6",
        "valhalla/distilbart-mnli-12-9",
        "ynie/bart-large-snli_mnli_fever_anli_R1_R2_R3-nli"
    ],
    "DebertaV2ForSequenceClassification": [
        "Babelscape/mdeberta-v3-base-triplet-critic-xnli",
        "ClinicalNLP/SDOHv7",
        "Elron/deberta-v3-large-sentiment",
        "JasperLS/deberta-v3-base-injection",
        "Kaludi/Reviews-Sentiment-Analysis",
        "Mel-Iza0/zero-shot",
        "MoritzLaurer/DeBERTa-v3-base-mnli",
        "MoritzLaurer/DeBERTa-v3-base-mnli-fever-anli",
        "MoritzLaurer/DeBERTa-v3-base-mnli-fever-docnli-ling-2c",
        "MoritzLaurer/DeBERTa-v3-large-mnli-fever-anli-ling-wanli",
        "MoritzLaurer/DeBERTa-v3-small-mnli-fever-docnli-ling-2c",
        "MoritzLaurer/DeBERTa-v3-xsmall-mnli-fever-anli-ling-binary",
        "MoritzLaurer/mDeBERTa-v3-base-mnli-xnli",
        "MoritzLaurer/mDeBERTa-v3-base-xnli-multilingual-nli-2mil7",
        "NDugar/ZSD-microsoft-v2xxlmnli",
        "NDugar/deberta-v2-xlarge-mnli",
        "NDugar/debertav3-mnli-snli-anli",
        "OpenAssistant/reward-model-deberta-v3-base",
        "OpenAssistant/reward-model-deberta-v3-large",
        "OpenAssistant/reward-model-deberta-v3-large-v2",
        "RashidNLP/Amazon-Deberta-Base-Sentiment",
        "RashidNLP/Finance-Sentiment-Classification",
        "Sarwar242/autotrain-fake-reviews-labelling-37433101195",
        "Tverous/entailment-classification",
        "Voryoji/Shuichi",
        "amphora/FinABSA-DeBERTa",
        "apsys/deberta-v3-base-finetuned-vc-pitches",
        "apsys/deberta-v3-base-finetuned-vc-pitches-industry",
        "apsys/deberta-v3-base-finetuned-vc-pitches-investor",
        "cross-encoder/nli-deberta-v3-base",
        "cross-encoder/nli-deberta-v3-large",
        "cross-encoder/nli-deberta-v3-small",
        "cross-encoder/nli-deberta-v3-xsmall",
        "deepset/deberta-v3-base-injection",
        "diegopetrola/mDeBERTa-mnli-kaggle-contradictory-my-dear-watson",
        "domenicrosati/deberta-v3-large-finetuned-paws-paraphrase-detector",
        "futuredatascience/strat_call_followup_prod",
        "hf-internal-testing/tiny-random-DebertaV2ForSequenceClassification",
        "khalidalt/DeBERTa-v3-large-mnli",
        "ktgiahieu/base-deberta-v3-large-peft-p-tuning-fbprize",
        "leofn3/autotrain-racismo",
        "martypants/debertads-gloomhaven",
        "mathislucka/deberta-large-hallucination-eval-v2",
        "microsoft/deberta-v2-xlarge-mnli",
        "microsoft/deberta-v2-xxlarge-mnli",
        "mrm8488/deberta-v3-small-finetuned-cola",
        "mrm8488/deberta-v3-small-finetuned-mnli",
        "naver/trecdl22-crossencoder-debertav3",
        "navteca/nli-deberta-v3-xsmall",
        "nickmuchi/deberta-v3-base-finetuned-finance-text-classification",
        "potsawee/deberta-v3-large-mnli",
        "shayonhuggingface/videberta-sentiment-analysis",
        "sileod/deberta-v3-base-tasksource-nli",
        "sileod/deberta-v3-large-tasksource-nli",
        "sileod/deberta-v3-large-tasksource-rlhf-reward-model",
        "sileod/mdeberta-v3-base-tasksource-nli",
        "whispAI/ClaimBuster-DeBERTaV2",
        "yiiino/deberta-v3-large-cola"
    ],
    "M2M100ForConditionalGeneration": [
        "Babelscape/mrebel-base",
        "CadenzaBaron/M2M100-418M-for-GameTranslation-Finetuned-Zh-En",
        "Jayyydyyy/m2m100_418m_tokipona",
        "NHNDQ/nllb-finetuned-en2ko",
        "NHNDQ/nllb-finetuned-ko2en",
        "Pawel-M/src_ctx_aware_nllb_600M",
        "Xenova/nllb-200-distilled-600M",
        "alirezamsh/small100",
        "anzorq/m2m100_418M_ft_ru-kbd_44K",
        "cartesinus/iva_mt_wslot-m2m100_418M-en-de",
        "danhsf/m2m100_418M-finetuned-kde4-en-to-pt_BR",
        "facebook/m2m100-12B-avg-5-ckpt",
        "facebook/m2m100-12B-last-ckpt",
        "facebook/m2m100_1.2B",
        "facebook/m2m100_418M",
        "facebook/nllb-200-1.3B",
        "facebook/nllb-200-3.3B",
        "facebook/nllb-200-distilled-1.3B",
        "facebook/nllb-200-distilled-600M",
        "facebook/wmt21-dense-24-wide-x-en",
        "hf-internal-testing/tiny-random-M2M100ForConditionalGeneration",
        "hyerin/m2m100_418M-finetuned-en-to-ko",
        "michaelfeil/ct2fast-nllb-200-3.3B",
        "mohdyaser/Sahban0.1",
        "neverLife/nllb-200-distilled-600M-ja-zh",
        "stas/tiny-m2m_100",
        "thefrigidliquidation/nllb-200-distilled-1.3B-bookworm",
        "thefrigidliquidation/nllb-jaen-1.3B-lightnovels",
        "trl-internal-testing/tiny-random-M2M100ForConditionalGeneration",
        "ychenNLP/nllb-200-3.3B-easyproject"
    ],
    "DistilBertModel": [
        "BeIR/sparta-msmarco-distilbert-base-v1",
        "M-CLIP/M-BERT-Distil-40",
        "Sakil/sentence_similarity_semantic_search",
        "efederici/sentence-BERTino",
        "hf-internal-testing/tiny-random-DistilBertModel",
        "hf-tiny-model-private/tiny-random-DistilBertModel",
        "hlyu/distilbert-base-nli-stsb-mean-tokens",
        "m3hrdadfi/distilbert-zwnj-wnli-mean-tokens",
        "mpjan/msmarco-distilbert-base-tas-b-mmarco-pt-300k",
        "mrm8488/distiluse-base-multilingual-cased-v2-finetuned-stsb_multi_mt-es",
        "sadakmed/distiluse-base-multilingual-cased-v2",
        "sebastian-hofstaetter/distilbert-dot-margin_mse-T2-msmarco",
        "sebastian-hofstaetter/distilbert-dot-tas_b-b256-msmarco",
        "sentence-transformers/clip-ViT-B-32-multilingual-v1",
        "sentence-transformers/distilbert-base-nli-max-tokens",
        "sentence-transformers/distilbert-base-nli-mean-tokens",
        "sentence-transformers/distilbert-base-nli-stsb-mean-tokens",
        "sentence-transformers/distilbert-base-nli-stsb-quora-ranking",
        "sentence-transformers/distilbert-multilingual-nli-stsb-quora-ranking",
        "sentence-transformers/distiluse-base-multilingual-cased",
        "sentence-transformers/distiluse-base-multilingual-cased-v1",
        "sentence-transformers/distiluse-base-multilingual-cased-v2",
        "sentence-transformers/msmarco-distilbert-base-dot-prod-v3",
        "sentence-transformers/msmarco-distilbert-base-tas-b",
        "sentence-transformers/msmarco-distilbert-base-v2",
        "sentence-transformers/msmarco-distilbert-base-v3",
        "sentence-transformers/msmarco-distilbert-base-v4",
        "sentence-transformers/msmarco-distilbert-cos-v5",
        "sentence-transformers/msmarco-distilbert-dot-v5",
        "sentence-transformers/msmarco-distilbert-multilingual-en-de-v2-tmp-lng-aligned",
        "sentence-transformers/nq-distilbert-base-v1",
        "sentence-transformers/quora-distilbert-base",
        "sentence-transformers/quora-distilbert-multilingual",
        "sentence-transformers/stsb-distilbert-base"
    ],
    "CLIPModel": [
        "Bingsu/clip-vit-base-patch32-ko",
        "Bingsu/clip-vit-large-patch14-ko",
        "Geonmo/CLIP-Giga-config-fixed",
        "OysterQAQ/DanbooruCLIP",
        "P01son/FaceCLIP-base-32",
        "Rocketknight1/tiny-random-clip-tf",
        "Searchium-ai/clip4clip-webvid150k",
        "flaviagiammarino/pubmed-clip-vit-base-patch32",
        "flax-community/clip-rsicd",
        "flax-community/clip-rsicd-v2",
        "geolocal/StreetCLIP",
        "hf-internal-testing/tiny-random-CLIPModel",
        "hf-internal-testing/tiny-random-clip-zero-shot-image-classification",
        "laion/CLIP-ViT-B-32-laion2B-s34B-b79K",
        "laion/CLIP-ViT-H-14-laion2B-s32B-b79K",
        "laion/CLIP-ViT-L-14-DataComp.XL-s13B-b90K",
        "laion/CLIP-ViT-L-14-laion2B-s32B-b82K",
        "laion/CLIP-ViT-bigG-14-laion2B-39B-b160k",
        "laion/CLIP-ViT-g-14-laion2B-s12B-b42K",
        "marcusinthesky/CLIP-ViT-B-16-DataComp.XL-s13B-b90K",
        "openai/clip-vit-base-patch16",
        "openai/clip-vit-base-patch32",
        "openai/clip-vit-large-patch14",
        "openai/clip-vit-large-patch14-336",
        "patrickjohncyh/fashion-clip",
        "philschmid/clip-zero-shot-image-classification",
        "pickapic-anonymous/PickScore_v1",
        "rinna/japanese-clip-vit-b-16",
        "vinid/plip",
        "yuvalkirstain/PickScore_v1"
    ],
    "EncoderDecoderModel": [
        "Callidior/bert2bert-base-arxiv-titlegen",
        "IlyaGusev/rubert_telegram_headlines",
        "ImanAndrea/bert2bert-finetuned-kde4-en-to-fr",
        "IndianaUniversityDatasetsModels/MIMIC-Medical-Report-Generator",
        "Narrativa/bsc_roberta2roberta_shared-spanish-finetuned-mlsum-summarization",
        "Shobhank-iiitdwd/BERT_summary",
        "Shobhank-iiitdwd/Distil_BERT_summary",
        "cahya/bert2bert-indonesian-summarization",
        "cahya/bert2gpt-indonesian-summarization",
        "gokceuludogan/WarmMolGenTwo",
        "google/bert2bert_L-24_wmt_de_en",
        "google/bert2bert_L-24_wmt_en_de",
        "google/roberta2roberta_L-24_bbc",
        "google/roberta2roberta_L-24_cnn_daily_mail",
        "google/roberta2roberta_L-24_discofuse",
        "google/roberta2roberta_L-24_gigaword",
        "google/roberta2roberta_L-24_wikisplit",
        "kykim/bertshared-kor-base",
        "leejj870/model9",
        "m3hrdadfi/bert2bert-fa-wiki-summary",
        "malmarjeh/bert2bert",
        "malmarjeh/mbert2mbert-arabic-text-summarization",
        "malmarjeh/transformer",
        "mrm8488/bert-mini2bert-mini-finetuned-cnn_daily_mail-summarization",
        "mrm8488/bert-small2bert-small-finetuned-cnn_daily_mail-summarization",
        "mrm8488/bert2bert-spanish-question-generation",
        "mrm8488/bert2bert_shared-german-finetuned-summarization",
        "mrm8488/bert2bert_shared-spanish-finetuned-summarization",
        "mrm8488/bert2bert_shared-turkish-summarization",
        "mrm8488/camembert2camembert_shared-finetuned-french-summarization",
        "patrickvonplaten/bert2bert-cnn_dailymail-fp16",
        "patrickvonplaten/bert2bert_cnn_daily_mail",
        "patrickvonplaten/bert2gpt2-cnn_dailymail-fp16",
        "patrickvonplaten/longformer2roberta-cnn_dailymail-fp16",
        "raynardj/wenyanwen-ancient-translate-to-modern",
        "raynardj/wenyanwen-chinese-translate-to-ancient",
        "sappho192/ffxiv-ja-ko-translator",
        "satyaalmasian/temporal_tagger_roberta2roberta",
        "tareknaous/bert2bert-empathetic-response-msa",
        "ydshieh/bert2bert-cnn_dailymail-fp16"
    ],
    "RobertaForTokenClassification": [
        "CyberPeace-Institute/SecureBERT-NER",
        "Dizex/InstaFoodRoBERTa-NER",
        "Hyeonseo/ko_fin_ner_roberta_small_model",
        "Jean-Baptiste/roberta-large-ner-english",
        "Jean-Baptiste/roberta-ticker",
        "KoichiYasuoka/roberta-base-english-upos",
        "KoichiYasuoka/roberta-base-thai-spm-upos",
        "KoichiYasuoka/roberta-classical-chinese-base-sentence-segmentation",
        "KoichiYasuoka/roberta-large-english-upos",
        "KoichiYasuoka/roberta-large-korean-upos",
        "MMG/roberta-base-ner-english",
        "PlanTL-GOB-ES/bsc-bio-ehr-es-cantemist",
        "PlanTL-GOB-ES/bsc-bio-ehr-es-pharmaconer",
        "PlanTL-GOB-ES/roberta-base-bne-capitel-ner",
        "PlanTL-GOB-ES/roberta-base-bne-capitel-ner-plus",
        "PlanTL-GOB-ES/roberta-base-bne-capitel-pos",
        "PlanTL-GOB-ES/roberta-large-bne-capitel-ner",
        "StivenLancheros/roberta-base-biomedical-clinical-es-finetuned-ner-CRAFT_AugmentedTransfer_ES",
        "TweebankNLP/bertweet-tb2_ewt-pos-tagging",
        "TweebankNLP/bertweet-tb2_wnut17-ner",
        "UMCU/MedRoBERTa.nl_NegationDetection",
        "ajtamayoh/Procedures_Identification_RoBERTa_fine_tuned",
        "ajtamayoh/RE_NegREF_NSD_Nubes_Training_Test_dataset_roberta-base-biomedical-clinical-es_fine_tuned_v3",
        "alifaheem94/RomanUrduPOS",
        "allenai/vila-roberta-large-s2vl-internal",
        "arnolfokam/roberta-base-pcm",
        "asahi417/tner-roberta-base-tweet-2020",
        "bertin-project/bertin-base-ner-conll2002-es",
        "carolanderson/roberta-base-food-ner",
        "dhtocks/Named-Entity-Recognition",
        "egoitz/roberta-timex-semeval",
        "ethanyt/guwen-ner",
        "ethanyt/guwen-punc",
        "ethanyt/guwen-seg",
        "hadifar/ner_v1",
        "helenai/philschmid-distilroberta-base-ner-conll2003-ov",
        "hf-internal-testing/tiny-random-RobertaForTokenClassification",
        "icelab/spaceroberta_CR",
        "julien-c/EsperBERTo-small-pos",
        "lcampillos/roberta-es-clinical-trials-ner",
        "m3hrdadfi/icelandic-ner-roberta",
        "ml6team/keyphrase-extraction-kbir-inspec",
        "ml6team/keyphrase-extraction-kbir-kpcrowd",
        "ml6team/keyphrase-extraction-kbir-kptimes",
        "mrm8488/codebert-base-finetuned-stackoverflow-ner",
        "mrojas/spanish-clinical-ner",
        "obi/deid_roberta_i2b2",
        "oliverguhr/fullstop-dutch-sonar-punctuation-prediction",
        "pdelobelle/robbert-v2-dutch-ner",
        "philschmid/distilroberta-base-ner-conll2003",
        "projecte-aina/roberta-base-ca-cased-ner",
        "projecte-aina/roberta-base-ca-cased-pos",
        "pysentimiento/robertuito-ner",
        "pysentimiento/robertuito-pos",
        "raynardj/ner-disease-ncbi-bionlp-bc5cdr-pubmed",
        "raynardj/ner-gene-dna-rna-jnlpba-pubmed",
        "silpakanneganti/roberta-cpt-medical-ner",
        "sschet/ner-disease-ncbi-bionlp-bc5cdr-pubmed",
        "tner/bertweet-large-tweetner7-all",
        "tner/roberta-large-bionlp2004",
        "tner/roberta-large-ontonotes5",
        "tner/roberta-large-tweetner7-all",
        "tner/roberta-large-wnut2017",
        "tsmatz/xlm-roberta-ner-japanese",
        "w11wo/indonesian-roberta-base-posp-tagger",
        "xooca/roberta_ner_personal_info",
        "ydshieh/roberta-large-ner-english"
    ],
    "ElectraForQuestionAnswering": [
        "Damith/AraELECTRA-discriminator-QuranQA",
        "Damith/AraELECTRA-discriminator-SOQAL",
        "Sahajtomar/German-question-answer-Electra",
        "TitanML/Electra-Large-SQUADV2",
        "ZeyadAhmed/AraElectra-Arabic-SQuADv2-QA",
        "ahotrod/electra_large_discriminator_squad2_512",
        "anakin87/electra-italian-xxl-cased-squad-it",
        "bhadresh-savani/electra-base-squad2",
        "cgutknecht/gelectra_large_gsqd-gq-LHM",
        "deepset/electra-base-squad2",
        "deepset/gelectra-base-germanquad",
        "deepset/gelectra-base-germanquad-distilled",
        "deepset/gelectra-large-germanquad",
        "deutsche-telekom/electra-base-de-squad2",
        "hf-internal-testing/tiny-random-ElectraForQuestionAnswering",
        "hf-tiny-model-private/tiny-random-ElectraForQuestionAnswering",
        "kuzgunlar/electra-turkish-qa",
        "luohy/rgx-qa-v2",
        "monologg/koelectra-base-v3-finetuned-korquad",
        "monologg/koelectra-small-v2-distilled-korquad-384",
        "mrm8488/electra-small-finetuned-squadv2",
        "salti/AraElectra-base-finetuned-ARCD",
        "sultan/BioM-ELECTRA-Base-SQuAD2-BioASQ8B",
        "sultan/BioM-ELECTRA-Large-SQuAD2",
        "valhalla/electra-base-discriminator-finetuned_squadv1",
        "wissamantoun/araelectra-base-artydiqa",
        "zohaib99k/Bert_Arabic-SQuADv2-QA"
    ],
    "XLMRobertaForMaskedLM": [
        "Davlan/afro-xlmr-base",
        "Davlan/afro-xlmr-large",
        "Davlan/afro-xlmr-large-61L",
        "Davlan/afro-xlmr-mini",
        "Davlan/afro-xlmr-small",
        "Davlan/xlm-roberta-base-finetuned-arabic",
        "Davlan/xlm-roberta-base-finetuned-swahili",
        "EMBEDDIA/litlat-bert",
        "MiMe-MeMo/MeMo-BERT-03",
        "RogerB/afro-xlmr-large-finetuned-kintweetsD",
        "UGARIT/grc-alignment",
        "bonadossou/afrolm_active_learning",
        "cardiffnlp/twitter-xlm-roberta-base",
        "castorini/afriberta_base",
        "castorini/afriberta_large",
        "castorini/afriberta_small",
        "cis-lmu/glot500-base",
        "coastalcph/fairlex-cail-minilm",
        "explosion-testing/xlm-roberta-test",
        "facebook/xlm-v-base",
        "hfl/cino-base-v2",
        "hfl/cino-large-v2",
        "hfl/cino-small-v2",
        "jhu-clsp/bernice",
        "jplu/tf-xlm-roberta-base",
        "jplu/tf-xlm-roberta-large",
        "llange/xlm-roberta-large-spanish",
        "microsoft/infoxlm-base",
        "microsoft/infoxlm-large",
        "microsoft/xlm-align-base",
        "nreimers/mMiniLMv2-L12-H384-distilled-from-XLMR-Large",
        "nreimers/mMiniLMv2-L6-H384-distilled-from-XLMR-Large",
        "osiria/flare-it",
        "soBeauty/1_20230714_01-xlm-roberta-base-confusion",
        "soBeauty/2_20230714_01-xlm-roberta-base-confusion",
        "ukr-models/xlm-roberta-base-uk",
        "vesteinn/DanskBERT",
        "xlm-roberta-base",
        "xlm-roberta-large",
        "xlm-roberta-large-finetuned-conll02-dutch",
        "xlm-roberta-large-finetuned-conll02-spanish"
    ],
    "T5EncoderModel": [
        "DeepFloyd/t5-v1_1-xxl",
        "ElnaggarLab/ankh-base-encoder",
        "ElnaggarLab/ankh-large-encoder",
        "Rostlab/prot_t5_xl_half_uniref50-enc",
        "efederici/sentence-it5-base",
        "hf-internal-testing/tiny-random-T5EncoderModel",
        "hku-nlp/instructor-base",
        "hkunlp/instructor-base",
        "hkunlp/instructor-large",
        "hkunlp/instructor-xl",
        "jinaai/jina-embedding-b-en-v1",
        "jinaai/jina-embedding-l-en-v1",
        "jinaai/jina-embedding-s-en-v1",
        "kaiyuy/leandojo-lean3-retriever-byt5-small",
        "liujch1998/vera",
        "openMUSE/t5-v1_1-large-enc",
        "pszemraj/flan-ul2-text-encoder",
        "sentence-transformers/gtr-t5-base",
        "sentence-transformers/gtr-t5-large",
        "sentence-transformers/gtr-t5-xl",
        "sentence-transformers/gtr-t5-xxl",
        "sentence-transformers/sentence-t5-base",
        "sentence-transformers/sentence-t5-large",
        "sentence-transformers/sentence-t5-xl",
        "sentence-transformers/sentence-t5-xxl"
    ],
    "Wav2Vec2ForSequenceClassification": [
        "DunnBC22/wav2vec2-base-Speech_Emotion_Recognition",
        "FerhatDk/wav2vec2-base_music_speech_both_classification",
        "HyperMoon/wav2vec2-base-960h-finetuned-deepfake",
        "Juardo/my_awesome_torgo_model",
        "Talha/urdu-audio-emotions",
        "Teapack1/model_KWS",
        "aherzberg/ser_model_fixed_label",
        "alefiury/wav2vec2-large-xlsr-53-gender-recognition-librispeech",
        "alefiury/wav2vec2-xls-r-300m-pt-br-spontaneous-speech-emotion-recognition",
        "anton-l/wav2vec2-base-lang-id",
        "anton-l/wav2vec2-random-tiny-classifier",
        "anton-l/xtreme_s_xlsr_300m_minds14",
        "bookbot/distil-wav2vec2-adult-child-cls-52m",
        "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition",
        "facebook/mms-lid-1024",
        "facebook/mms-lid-126",
        "facebook/mms-lid-2048",
        "facebook/mms-lid-256",
        "facebook/mms-lid-4017",
        "facebook/mms-lid-512",
        "hackathon-pln-es/wav2vec2-base-finetuned-sentiment-classification-MESD",
        "hafidikhsan/Wav2vec2-large-robust-Pronounciation-Evaluation",
        "hafidikhsan/wav2vec2-large-xlsr-53-english-pronunciation-evaluation-ep-v3",
        "hf-internal-testing/tiny-random-Wav2Vec2ForSequenceClassification",
        "hhsavich/accent_determinator",
        "ramonpzg/wav2musicgenre",
        "stevhliu/my_awesome_minds_model",
        "superb/wav2vec2-base-superb-er",
        "superb/wav2vec2-base-superb-ic",
        "superb/wav2vec2-base-superb-ks",
        "superb/wav2vec2-base-superb-sid"
    ],
    "ElectraForPreTraining": [
        "FPTAI/velectra-base-discriminator-cased",
        "Maltehb/aelaectra-danish-electra-small-cased",
        "NlpHUST/electra-base-vn",
        "NlpHUST/vi-electra-small",
        "Recognai/selectra_small",
        "Rostlab/prot_electra_discriminator_bfd",
        "aubmindlab/araelectra-base-discriminator",
        "beomi/KcELECTRA-base",
        "beomi/KcELECTRA-base-v2022",
        "classla/bcms-bertic",
        "csebuetnlp/banglabert",
        "csebuetnlp/banglabert_large",
        "csebuetnlp/banglabert_small",
        "csebuetnlp/banglishbert",
        "dbmdz/electra-base-german-europeana-cased-discriminator",
        "dbmdz/electra-base-italian-xxl-cased-discriminator",
        "dbmdz/electra-base-turkish-cased-discriminator",
        "dbmdz/electra-base-turkish-mc4-uncased-discriminator",
        "deepset/gelectra-base",
        "deepset/gelectra-large",
        "german-nlp-group/electra-base-german-uncased",
        "google/electra-base-discriminator",
        "google/electra-large-discriminator",
        "google/electra-small-discriminator",
        "hf-tiny-model-private/tiny-random-ElectraForPreTraining",
        "hfl/chinese-electra-180g-small-discriminator",
        "hmteams/teams-base-historic-multilingual-discriminator",
        "izumi-lab/electra-base-japanese-discriminator",
        "izumi-lab/electra-small-japanese-fin-discriminator",
        "jcblaise/electra-tagalog-small-uncased-discriminator",
        "jonfd/electra-small-nordic",
        "kamalkraj/bioelectra-base-discriminator-pubmed",
        "kamalkraj/bioelectra-base-discriminator-pubmed-pmc",
        "kykim/electra-kor-base",
        "megagonlabs/transformers-ud-japanese-electra-base-discriminator",
        "megagonlabs/transformers-ud-japanese-electra-base-ginza",
        "monologg/kocharelectra-base-discriminator",
        "monologg/kocharelectra-small-discriminator",
        "monologg/koelectra-base-discriminator",
        "monologg/koelectra-base-v2-discriminator",
        "monologg/koelectra-base-v3-discriminator",
        "monologg/koelectra-small-discriminator",
        "monologg/koelectra-small-v2-discriminator",
        "monologg/koelectra-small-v3-discriminator",
        "mrm8488/electricidad-base-discriminator",
        "snunlp/KR-ELECTRA-discriminator",
        "sultan/BioM-ELECTRA-Base-Discriminator",
        "sultan/BioM-ELECTRA-Large-Discriminator",
        "tunib/electra-ko-en-base"
    ],
    "DistilBertForMaskedLM": [
        "Geotrend/distilbert-base-25lang-cased",
        "Geotrend/distilbert-base-en-fr-cased",
        "Geotrend/distilbert-base-en-th-cased",
        "Geotrend/distilbert-base-es-cased",
        "Geotrend/distilbert-base-fr-cased",
        "Geotrend/distilbert-base-ru-cased",
        "Geotrend/distilbert-base-uk-cased",
        "Geotrend/distilbert-base-zh-cased",
        "Ghana-NLP/distilabena-base-v2-asante-twi-uncased",
        "HooshvareLab/distilbert-fa-zwnj-base",
        "MUmairAB/bert-based-MaskedLM",
        "Recognai/distilbert-base-es-multilingual-cased",
        "cahya/distilbert-base-indonesian",
        "dccuchile/distilbert-base-spanish-uncased",
        "distilbert-base-german-cased",
        "distilbert-base-multilingual-cased",
        "distilbert-base-uncased",
        "hf-internal-testing/tiny-random-DistilBertForMaskedLM",
        "hf-tiny-model-private/tiny-random-DistilBertForMaskedLM",
        "huggingface-course/distilbert-base-uncased-finetuned-imdb",
        "indigo-ai/BERTino",
        "line-corporation/line-distilbert-base-japanese",
        "medicalai/ClinicalBERT",
        "monologg/distilkobert",
        "naver/efficient-splade-V-large-doc",
        "naver/efficient-splade-V-large-query",
        "naver/splade_v2_distil",
        "naver/splade_v2_max",
        "nlpie/bio-distilbert-uncased",
        "nlpie/clinical-distilbert",
        "osiria/blaze-it",
        "osiria/distilbert-base-italian-cased",
        "quiqup/geocoding-distilbert",
        "sanjin7/distilbert_base_uncased_ad_subwords",
        "sentence-transformers/multi-qa-distilbert-cos-v1",
        "sentence-transformers/multi-qa-distilbert-dot-v1",
        "vocab-transformers/distilbert-word2vec_256k-MLM_best"
    ],
    "ElectraForTokenClassification": [
        "Hasanmurad/address_parsing_test_1",
        "Leo97/KoELECTRA-small-v3-modu-ner",
        "NlpHUST/ner-vietnamese-electra-base",
        "NlpHUST/vi-word-segmentation",
        "Ruth/gelectra-large-germeval_14",
        "bhadresh-savani/electra-base-discriminator-finetuned-conll03-english",
        "chintagunta85/electramed-small-ADE-DRUG-EFFECT-ner-v3",
        "classla/bcms-bertic-ner",
        "commanderstrife/PV-Bio_clinicalBERT-superset",
        "dbmdz/electra-large-discriminator-finetuned-conll03-english",
        "hf-internal-testing/tiny-random-ElectraForTokenClassification",
        "hf-tiny-model-private/tiny-random-ElectraForTokenClassification",
        "kamalkraj/BioELECTRA-PICO",
        "lgrobol/electra-minuscule-discriminator",
        "monologg/koelectra-base-finetuned-naver-ner",
        "monologg/koelectra-base-v3-naver-ner",
        "monologg/koelectra-small-finetuned-naver-ner",
        "nafi-zaman/celloscope-28000-ner-banglabert-finetuned",
        "richielo/small-e-czech-finetuned-ner-wikiann",
        "satyaalmasian/temporal_tagger_German_GELECTRA",
        "toastynews/electra-hongkongese-base-hkt-ws"
    ],
    "LongT5ForConditionalGeneration": [
        "Joemgu/mlong-t5-base-sumstew",
        "Joemgu/mlong-t5-large-sumstew",
        "KETI-AIR-Downstream/long-ke-t5-base-summarization",
        "KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-bidirection",
        "KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-bidirection_e1",
        "KETI-AIR-Downstream/long-ke-t5-base-translation-aihub-ko2en",
        "KETI-AIR/long-ke-t5-base",
        "Samir001/ResumeSummary-t5-Wang-Arora",
        "Stancld/longt5-tglobal-large-16384-pubmed-3k_steps",
        "agemagician/mlong-t5-tglobal-base",
        "agemagician/mlong-t5-tglobal-large",
        "google/long-t5-local-base",
        "google/long-t5-local-large",
        "google/long-t5-tglobal-base",
        "google/long-t5-tglobal-large",
        "google/long-t5-tglobal-xl",
        "hf-internal-testing/tiny-random-LongT5ForConditionalGeneration",
        "pszemraj/long-t5-tglobal-base-16384-book-summary",
        "pszemraj/long-t5-tglobal-base-16384-booksci-summary-v1",
        "pszemraj/long-t5-tglobal-base-16384-booksum-V11-big_patent-V2",
        "pszemraj/long-t5-tglobal-base-16384-booksum-V12",
        "pszemraj/long-t5-tglobal-base-sci-simplify",
        "pszemraj/long-t5-tglobal-base-sci-simplify-elife",
        "pszemraj/long-t5-tglobal-xl-16384-book-summary",
        "pszemraj/long-t5-tglobal-xl-sci-simplify-elife",
        "sumedh/biomedical_text_summarization",
        "trl-internal-testing/tiny-random-LongT5ForConditionalGeneration"
    ],
    "XGLMForCausalLM": [
        "KoboldAI/fairseq-dense-1.3B",
        "KoboldAI/fairseq-dense-125M",
        "KoboldAI/fairseq-dense-13B",
        "KoboldAI/fairseq-dense-13B-Janeway",
        "KoboldAI/fairseq-dense-13B-Nerys",
        "KoboldAI/fairseq-dense-13B-Nerys-v2",
        "KoboldAI/fairseq-dense-13B-Shinen",
        "KoboldAI/fairseq-dense-2.7B",
        "KoboldAI/fairseq-dense-2.7B-Janeway",
        "KoboldAI/fairseq-dense-2.7B-Nerys",
        "KoboldAI/fairseq-dense-355M",
        "KoboldAI/fairseq-dense-6.7B",
        "KoboldAI/fairseq-dense-6.7B-Janeway",
        "KoboldAI/fairseq-dense-6.7B-Shinen",
        "facebook/incoder-1B",
        "facebook/incoder-6B",
        "facebook/xglm-1.7B",
        "facebook/xglm-2.9B",
        "facebook/xglm-4.5B",
        "facebook/xglm-564M",
        "facebook/xglm-7.5B",
        "hf-internal-testing/tiny-random-XGLMForCausalLM",
        "pythainlp/wangchanglm-7.5B-sft-en",
        "pythainlp/wangchanglm-7.5B-sft-en-8bit-sharded",
        "pythainlp/wangchanglm-7.5B-sft-en-sharded",
        "pythainlp/wangchanglm-7.5B-sft-enth",
        "pythainlp/wangchanglm-7.5B-sft-enth-sharded"
    ],
    "CodeGenForCausalLM": [
        "NumbersStation/nsql-2B",
        "NumbersStation/nsql-350M",
        "NumbersStation/nsql-6B",
        "Salesforce/codegen-16B-mono",
        "Salesforce/codegen-16B-multi",
        "Salesforce/codegen-16B-nl",
        "Salesforce/codegen-2B-mono",
        "Salesforce/codegen-2B-multi",
        "Salesforce/codegen-2B-nl",
        "Salesforce/codegen-350M-mono",
        "Salesforce/codegen-350M-multi",
        "Salesforce/codegen-350M-nl",
        "Salesforce/codegen-6B-mono",
        "Salesforce/codegen-6B-multi",
        "Salesforce/codegen-6B-nl",
        "Salesforce/codegen2-16B",
        "Salesforce/codegen2-1B",
        "Salesforce/codegen2-3_7B",
        "Salesforce/codegen2-7B",
        "TabbyML/Codegen-2B",
        "YurtsAI/yurts-python-code-gen-30-sparse",
        "alecsharpie/codegen_350m_html",
        "hf-internal-testing/tiny-random-CodeGenForCausalLM",
        "kdf/python-docstring-generation",
        "sahil2801/instruct-codegen-16B",
        "shailja/fine-tuned-codegen-16B-Verilog",
        "shailja/fine-tuned-codegen-2B-Verilog",
        "shailja/fine-tuned-codegen-6B-Verilog",
        "sharoz/codegen-350M-mono-custom-functions-dataset-python_v2",
        "trl-internal-testing/tiny-random-CodeGenForCausalLM",
        "trl-internal-testing/tiny-random-CodeGenForCausalLM-sharded"
    ],
    "T5Model": [
        "Rostlab/prot_t5_xxl_bfd",
        "SEBIS/code_trans_t5_base_code_comment_generation_java",
        "SEBIS/code_trans_t5_base_code_documentation_generation_java",
        "SEBIS/code_trans_t5_base_code_documentation_generation_java_multitask",
        "SEBIS/code_trans_t5_base_code_documentation_generation_python",
        "SEBIS/code_trans_t5_base_code_documentation_generation_python_transfer_learning_finetune",
        "SEBIS/code_trans_t5_large_code_comment_generation_java_multitask_finetune",
        "SEBIS/code_trans_t5_large_code_documentation_generation_java_transfer_learning_finetune",
        "SEBIS/code_trans_t5_large_code_documentation_generation_javascript_multitask",
        "SEBIS/code_trans_t5_large_code_documentation_generation_javascript_transfer_learning_finetune",
        "SEBIS/code_trans_t5_large_code_documentation_generation_python_multitask",
        "SEBIS/code_trans_t5_large_source_code_summarization_csharp_multitask_finetune",
        "SEBIS/code_trans_t5_large_source_code_summarization_python_multitask_finetune",
        "SEBIS/code_trans_t5_small_code_documentation_generation_java_multitask_finetune",
        "SEBIS/code_trans_t5_small_code_documentation_generation_python",
        "SEBIS/code_trans_t5_small_program_synthese_transfer_learning_finetune",
        "SEBIS/code_trans_t5_small_source_code_summarization_sql_multitask_finetune",
        "castorini/duot5-3b-msmarco",
        "castorini/monot5-large-msmarco",
        "hf-internal-testing/tiny-random-T5Model",
        "kadasterdst/querygenerator",
        "psyche/KoT5",
        "razent/cotext-1-ccg",
        "razent/cotext-2-cc",
        "sonoisa/sentence-t5-base-ja-mean-tokens",
        "sonoisa/t5-base-japanese",
        "sunhao666/chi-sum2",
        "trl-internal-testing/tiny-random-T5Model",
        "yiqingx/AnchorDR"
    ],
    "ElectraForMaskedLM": [
        "aubmindlab/araelectra-base-generator",
        "csebuetnlp/banglabert_generator",
        "dbmdz/electra-base-french-europeana-cased-generator",
        "dbmdz/electra-base-italian-xxl-cased-generator",
        "factored/electra-fr-explorer-mlm",
        "google/electra-base-generator",
        "google/electra-large-generator",
        "google/electra-small-generator",
        "hf-internal-testing/tiny-electra",
        "hf-internal-testing/tiny-random-ElectraForMaskedLM",
        "hf-tiny-model-private/tiny-random-ElectraForMaskedLM",
        "hfl/chinese-legal-electra-small-generator",
        "izumi-lab/electra-base-japanese-generator",
        "lang-uk/electra-base-ukrainian-cased-generator",
        "lgrobol/electra-minuscule-generator",
        "monologg/koelectra-base-v3-generator",
        "monologg/koelectra-small-v3-generator",
        "sarnikowski/electra-small-generator-da-256-cased",
        "snunlp/KR-ELECTRA-generator",
        "stefan-it/electra-base-gc4-64k-0-cased-generator",
        "stefan-it/electra-base-gc4-64k-200000-cased-generator"
    ],
    "Mask2FormerForUniversalSegmentation": [
        "facebook/mask2former-swin-base-IN21k-ade-semantic",
        "facebook/mask2former-swin-base-IN21k-cityscapes-instance",
        "facebook/mask2former-swin-base-IN21k-cityscapes-panoptic",
        "facebook/mask2former-swin-base-IN21k-cityscapes-semantic",
        "facebook/mask2former-swin-base-IN21k-coco-instance",
        "facebook/mask2former-swin-base-ade-semantic",
        "facebook/mask2former-swin-base-coco-instance",
        "facebook/mask2former-swin-base-coco-panoptic",
        "facebook/mask2former-swin-large-ade-panoptic",
        "facebook/mask2former-swin-large-ade-semantic",
        "facebook/mask2former-swin-large-cityscapes-instance",
        "facebook/mask2former-swin-large-cityscapes-panoptic",
        "facebook/mask2former-swin-large-cityscapes-semantic",
        "facebook/mask2former-swin-large-coco-instance",
        "facebook/mask2former-swin-large-coco-panoptic",
        "facebook/mask2former-swin-large-mapillary-vistas-panoptic",
        "facebook/mask2former-swin-large-mapillary-vistas-semantic",
        "facebook/mask2former-swin-small-ade-semantic",
        "facebook/mask2former-swin-small-cityscapes-instance",
        "facebook/mask2former-swin-small-cityscapes-panoptic",
        "facebook/mask2former-swin-small-cityscapes-semantic",
        "facebook/mask2former-swin-small-coco-instance",
        "facebook/mask2former-swin-small-coco-panoptic",
        "facebook/mask2former-swin-tiny-ade-semantic",
        "facebook/mask2former-swin-tiny-cityscapes-instance",
        "facebook/mask2former-swin-tiny-cityscapes-panoptic",
        "facebook/mask2former-swin-tiny-cityscapes-semantic",
        "facebook/mask2former-swin-tiny-coco-instance",
        "facebook/mask2former-swin-tiny-coco-panoptic"
    ],
    "Pix2StructForConditionalGeneration": [
        "fxmarty/pix2struct-tiny-random",
        "google/deplot",
        "google/matcha-base",
        "google/matcha-chart2text-pew",
        "google/matcha-chart2text-statista",
        "google/matcha-chartqa",
        "google/matcha-plotqa-v1",
        "google/matcha-plotqa-v2",
        "google/pix2struct-ai2d-base",
        "google/pix2struct-ai2d-large",
        "google/pix2struct-base",
        "google/pix2struct-chartqa-base",
        "google/pix2struct-docvqa-base",
        "google/pix2struct-docvqa-large",
        "google/pix2struct-infographics-vqa-base",
        "google/pix2struct-infographics-vqa-large",
        "google/pix2struct-large",
        "google/pix2struct-ocrvqa-large",
        "google/pix2struct-screen2words-base",
        "google/pix2struct-screen2words-large",
        "google/pix2struct-textcaps-base",
        "google/pix2struct-textcaps-large",
        "google/pix2struct-widget-captioning-base",
        "google/pix2struct-widget-captioning-large"
    ],
    "WhisperForConditionalGeneration": [
        "bofenghuang/whisper-large-v2-cv11-german",
        "vumichien/whisper-large-v2-mix-jp",
        "pphuc25/whisper-tiny-full-data-language-v1-20ep",
        "DrishtiSharma/whisper-large-v2-marathi",
        "cahya/whisper-medium-id",
        "vasista22/whisper-hindi-medium",
        "ihanif/whisper-medium-urdu",
        "bangla-speech-processing/BanglaASR",
        "Jasper881108/whisper-small-zh",
        "biodatlab/whisper-th-medium-combined",
        "Scrya/whisper-large-v2-cantonese",
        "openai/whisper-large-v2",
        "bardsai/whisper-medium-pl",
        "pierreguillou/whisper-medium-french",
        "Shiry/whisper-large-v2-he",
        "ihanif/whisper-base-pashto",
        "steja/whisper-small-persian",
        "mn367/whisper-medium-hi",
        "ales/whisper-small-belarusian",
        "spow12/whisper-medium-zeroth_korean",
        "RetaSy/whisper-test-ar-tarteel",
        "TalTechNLP/whisper-large-et",
        "Daya7624/Fine_tune_large_v2_adam_8bit",
        "arpagon/whisper-tiny-es",
        "vasista22/whisper-hindi-large-v2",
        "NicoHi/whisper-base-voice-commands",
        "anuragshas/whisper-large-v2-ur",
        "bofenghuang/whisper-large-v2-french",
        "pnandhini/whisper_common_voice_small_en",
        "vasista22/whisper-tamil-large-v2",
        "jonatasgrosman/whisper-large-pt-cv11",
        "TalTechNLP/whisper-medium-et",
        "seastar105/whisper-medium-ko-zeroth",
        "jlondonobo/whisper-medium-pt",
        "sazzad-sit/whisper-small-bn-3ds",
        "SungBeom/whisper-small-ko",
        "openai/whisper-small.en",
        "DrishtiSharma/whisper-large-v2-hungarian",
        "simonl0909/whisper-large-v2-cantonese",
        "anuragshas/whisper-small-bn",
        "vasista22/whisper-hindi-small",
        "Zaid/whisper-large-v2-ar",
        "distil-whisper/tiny-random-whisper",
        "vasista22/whisper-telugu-large-v2",
        "bofenghuang/whisper-medium-french",
        "sanchit-gandhi/whisper-small-hi",
        "geninhu/whisper-large-v2-multiset-vi",
        "mitchelldehaven/whisper-large-v2-ru",
        "juancopi81/whisper-medium-es",
        "vphu123/whisper-base-test-vi",
        "ihanif/whisper-medium-pashto-3e-7",
        "NbAiLab/nb-whisper-small-beta",
        "jlondonobo/whisper-large-v2-pt-v3",
        "openai/whisper-base.en",
        "vasista22/whisper-telugu-base",
        "hf-internal-testing/tiny-random-WhisperForConditionalGeneration",
        "cloudqi/cqi_speech_recognize_pt_v0",
        "anuragshas/whisper-large-v2-bn",
        "Shiry/Whisper_hebrew_medium",
        "vasista22/whisper-telugu-medium",
        "hadiqa123/whisper-small-ur",
        "spow12/whisper-medium-ksponspeech",
        "vasista22/whisper-tamil-small",
        "vphu123/whisper_totaldata",
        "DrishtiSharma/whisper-large-v2-vietnamese",
        "clu-ling/whisper-large-v2-arabic-5k-steps",
        "openai/whisper-base",
        "bofenghuang/whisper-small-cv11-french",
        "bofenghuang/whisper-large-v2-cv11-french",
        "clu-ling/whisper-large-v2-spanish-5k-steps",
        "openai/whisper-medium.en",
        "KshitizPandya/GenzTranscribe-small-gu",
        "pphuc25/whisper-base-full-data-language-v1-20ep",
        "pphuc25/whisper-base-full-data-language-v2-20ep",
        "openai/whisper-tiny",
        "shhossain/whisper-base-bn",
        "steja/whisper-small-telugu",
        "Sanyam0605/whisper-large-v2-hi",
        "MohammedNasri/WHISPER-LARGE-ARABIC",
        "gigant/whisper-medium-romanian",
        "vumichien/whisper-medium-jp",
        "jonatasgrosman/whisper-large-zh-cv11",
        "byoussef/whisper-large-v2-Ko",
        "openai/whisper-small",
        "sgangireddy/whisper-medium-tr",
        "Subhaka/whisper-small-Sinhala-Fine_Tune",
        "Jingmiao/whisper-small-chinese_base",
        "openai/whisper-tiny.en",
        "seastar105/whisper-small-ko-zeroth",
        "tarteel-ai/whisper-base-ar-quran",
        "bnriiitb/whisper-small-te-146h",
        "lorenzoncina/whisper-medium-zh",
        "KshitizPandya/GenzTranscribe-small-hi",
        "sanchit-gandhi/whisper-small-dv",
        "hoonsung/CodeFairModel_asdf",
        "eai6/whisper-base",
        "Ivydata/whisper-small-japanese",
        "vumichien/whisper-large-v2-jp",
        "EricChang/Taiwanese-Whisper",
        "james-xie-rng/whisper-small-local"
    ],
    "BertForQuestionAnswering": [
        "chiendvhust/biobert_v1.1_pubmed_squad_v2-finetuned-covidQA",
        "YogaCr/kia-qa-model",
        "salti/bert-base-multilingual-cased-finetuned-squad",
        "ProfHuseyin/bert-english-fine-tuning-question-answering",
        "dmis-lab/biobert-base-cased-v1.1-squad",
        "deepset/bert-large-uncased-whole-word-masking-squad2",
        "Rifky/Indobert-QA",
        "luhua/chinese_pretrain_mrc_roberta_wwm_ext_large",
        "deepset/bert-medium-squad2-distilled",
        "fabgraziano/bert-italian-xxl-cased_squad-it_v1",
        "NeuML/bert-small-cord19qa",
        "recobo/chemical-bert-uncased-squad2",
        "alphakavi22772023/bertQA",
        "ydshieh/bert-base-cased-squad2",
        "csarron/bert-base-uncased-squad-v1",
        "anas-awadalla/bert-medium-pretrained-finetuned-squad",
        "phiyodr/bert-base-finetuned-squad2",
        "Michelvh/bert-question-answering-dutch",
        "mrm8488/bert-base-portuguese-cased-finetuned-squad-v1-pt",
        "atharvamundada99/bert-large-question-answering-finetuned-legal",
        "mrm8488/bert-small-finetuned-squadv2",
        "gfdgdfgdg/arap_qa_bert",
        "gdario/biobert_bioasq",
        "uer/roberta-base-chinese-extractive-qa",
        "yunusemreemik/logo-qna-model",
        "rsvp-ai/bertserini-bert-base-squad",
        "eraldoluis/faquad-bert-base-portuguese-cased",
        "Sahajtomar/GBERTQnA",
        "KoichiYasuoka/bert-base-japanese-wikipedia-ud-head",
        "batterydata/batterybert-uncased-squad-v1",
        "sangrimlee/bert-base-multilingual-cased-korquad",
        "pierreguillou/bert-base-cased-squad-v1.1-portuguese",
        "Shushant/biobert-v1.1-biomedicalQuestionAnswering",
        "Josue/BETO-espanhol-Squad2",
        "MMG/bert-base-spanish-wwm-cased-finetuned-squad2-es",
        "luhua/chinese_pretrain_mrc_macbert_large",
        "ckiplab/bert-base-chinese-qa",
        "LLukas22/all-MiniLM-L12-v2-qa-all",
        "bert-large-uncased-whole-word-masking-finetuned-squad",
        "helenai/csarron-bert-base-uncased-squad-v1-ov",
        "LLukas22/all-MiniLM-L12-v2-qa-en",
        "huggingface-course/bert-finetuned-squad",
        "deutsche-telekom/bert-multi-english-german-squad2",
        "madlag/bert-base-uncased-squad1.1-block-sparse-0.07-v1",
        "phd411r1/HooshvareLab_bert-fa-base-uncased_finetune-on-hoshfa",
        "mrm8488/bert-medium-finetuned-squadv2",
        "Nadav/bert-base-french-europeana-cased-squad-fr",
        "mrm8488/distill-bert-base-spanish-wwm-cased-finetuned-spa-squad2-es",
        "gfdgdfgdg/arap_qa_bert_large_v2",
        "mrm8488/spanbert-finetuned-squadv1",
        "pucpr/bioBERTpt-squad-v1.1-portuguese",
        "Shobhank-iiitdwd/Distiled-bert-medium-squad2-QA",
        "batterydata/bert-base-cased-squad-v1",
        "TingChenChang/bert-base-chinese-finetuned-squad-colab",
        "mrm8488/spanbert-finetuned-squadv2",
        "bert-large-cased-whole-word-masking-finetuned-squad",
        "MarcBrun/ixambert-finetuned-squad-eu-en",
        "kaporter/bert-base-uncased-finetuned-squad",
        "deepset/bert-base-uncased-squad2",
        "ixa-ehu/SciBERT-SQuAD-QuAC",
        "alon-albalak/bert-base-multilingual-xquad",
        "clagator/biobert_squad2_cased",
        "bigwiz83/sapbert-from-pubmedbert-squad2",
        "phiyodr/bert-large-finetuned-squad2",
        "mrm8488/bert-mini-5-finetuned-squadv2",
        "bespin-global/klue-bert-base-aihub-mrc",
        "Vidyuth/bert-finetuned-squad",
        "lserinol/bert-turkish-question-answering",
        "tdklab/hebert-finetuned-hebrew-squad",
        "twmkn9/bert-base-uncased-squad2",
        "SajjadAyoubi/bert-base-fa-qa",
        "hf-tiny-model-private/tiny-random-BertForQuestionAnswering",
        "henryk/bert-base-multilingual-cased-finetuned-polish-squad1",
        "peggyhuang/SciBERT-CoQA",
        "Salesforce/qaconv-bert-large-uncased-whole-word-masking-squad2",
        "ForutanRad/bert-fa-QA-v1",
        "hf-internal-testing/tiny-random-BertForQuestionAnswering",
        "henryk/bert-base-multilingual-cased-finetuned-polish-squad2",
        "Intel/bert-base-uncased-squad-int8-static",
        "mrm8488/bert-multi-cased-finetuned-xquadv1",
        "innocent-charles/Swahili-question-answer-latest-cased",
        "deepset/bert-base-cased-squad2",
        "alex-apostolo/legal-bert-small-cuad",
        "ZTamas/hubert-qa-milqa",
        "dmis-lab/biobert-large-cased-v1.1-squad",
        "ktrapeznikov/biobert_v1.1_pubmed_squad_v2",
        "batterydata/batterybert-cased-squad-v1",
        "susumu2357/bert-base-swedish-squad2",
        "franklu/pubmed_bert_squadv2",
        "madlag/bert-base-uncased-squadv1-x2.01-f89.2-d30-hybrid-rewind-opt-v1",
        "cahya/bert-base-indonesian-tydiqa",
        "amirdnc/HeQ",
        "henryk/bert-base-multilingual-cased-finetuned-dutch-squad2",
        "jihoonkimharu/bert-base-klue-mrc-finetuned",
        "NeuML/bert-small-cord19-squad2",
        "ainize/klue-bert-base-mrc",
        "pierreguillou/bert-large-cased-squad-v1.1-portuguese",
        "Rifky/IndoBERT-Large-P2-QA",
        "NchuNLP/Legal-Document-Question-Answering",
        "mrm8488/bert-base-spanish-wwm-cased-finetuned-spa-squad2-es"
    ],
    "GPTNeoXForCausalLM": [
        "EleutherAI/pythia-160m-hiddendropout",
        "beomi/KoAlpaca-Polyglot-5.8B",
        "PygmalionAI/pygmalion-1.3b",
        "Waterhorse/chessgpt-chat-v1",
        "squarelike/Gugugo-koen-1.3B-V0.9",
        "rinna/bilingual-gpt-neox-4b-instruction-ppo",
        "amirabdullah19852020/pythia_70m_ppo_imdb_sentiment",
        "EleutherAI/pythia-70m-deduped",
        "ethzanalytics/stablelm-tuned-alpha-7b-sharded-8bit",
        "OpenAssistant/oasst-sft-1-pythia-12b",
        "EleutherAI/pythia-160m-deduped-v0",
        "atmallen/pythia-6.9b-lora-popqa-parents-lying",
        "EleutherAI/pythia-410m-deduped-v0",
        "EleutherAI/pythia-12b-v0",
        "h2oai/h2ogpt-oasst1-512-12b",
        "zhangirazerbayev/open-web-math-dev_step11632",
        "OpenAssistant/pythia-12b-sft-v8-2.5k-steps",
        "EleutherAI/pythia-12b",
        "PORTULAN/gervasio-ptbr-base",
        "togethercomputer/Pythia-Chat-Base-7B",
        "NYTK/PULI-GPT-3SX",
        "rinna/bilingual-gpt-neox-4b",
        "EleutherAI/pythia-6.9b-deduped-v0",
        "rinna/bilingual-gpt-neox-4b-8k",
        "TabbyML/NeoX-70M",
        "andreaskoepf/pythia-6.9b-gpt4all-pretrain",
        "MerlynMind/merlyn-education-corpus-qa",
        "EleutherAI/pythia-2.8b-deduped",
        "BreadAi/MusePy-1-2",
        "rinna/japanese-gpt-neox-small",
        "lambdalabs/pythia-1.4b-deduped-synthetic-instruct",
        "KoboldAI/GPT-NeoX-20B-Erebus",
        "OpenAssistant/oasst-sft-4-pythia-12b-epoch-3.5",
        "h2oai/h2ogpt-oasst1-512-20b",
        "ethzanalytics/RedPajama-INCITE-Chat-3B-v1-GPTQ-4bit-128g",
        "togethercomputer/RedPajama-INCITE-Instruct-3B-v1",
        "sankethgadadinni/dolly-v2-7b-8bitLORA",
        "trl-internal-testing/tiny-random-GPTNeoXForCausalLM",
        "h2oai/h2ogpt-gm-oasst1-en-1024-20b",
        "h2oai/h2ogpt-gm-oasst1-multilang-1024-20b",
        "snorkelai/RedPajama-7B-Chat-Curated",
        "Trofish/KULLM-SFT-v2",
        "kyo-takano/open-calm-7b-8bit",
        "EleutherAI/pythia-70m",
        "EleutherAI/pythia-1.4b-deduped-v0",
        "EleutherAI/pythia-2.8b-deduped-v0",
        "BreadAi/StoryPy",
        "EleutherAI/pythia-1.4b-v0",
        "EleutherAI/pythia-6.9b",
        "cyberagent/open-calm-large",
        "hakurei/instruct-12b",
        "EleutherAI/pythia-12b-deduped",
        "EleutherAI/pythia-1b-deduped-v0",
        "OpenAssistant/stablelm-7b-sft-v7-epoch-3",
        "NinedayWang/PolyCoder-0.4B",
        "databricks/dolly-v2-12b",
        "OpenAssistant/pythia-12b-sft-v8-7k-steps",
        "nlpai-lab/kullm-polyglot-5.8b-v2",
        "databricks/dolly-v2-3b",
        "Pirr/pythia-13b-deduped-green_devil",
        "TDC2023/trojan-base-pythia-1.4b",
        "MerlynMind/merlyn-education-safety",
        "EleutherAI/pythia-1.4b-deduped",
        "EleutherAI/pythia-31m",
        "ewof/koishi-instruct-3b",
        "pvduy/pythia-125M-sft-summarize-tldr",
        "EleutherAI/pythia-14m",
        "vvsotnikov/stablelm-tuned-alpha-3b-16bit",
        "databricks/dolly-v2-7b",
        "concedo/Pythia-70M-ChatSalad",
        "lamini/instruct-tuned-2.8b",
        "EleutherAI/pythia-2.8b",
        "w601sxs/b1ade-1b",
        "nlpai-lab/kullm-polyglot-12.8b-v2",
        "custads23/pygmalion-1.3b",
        "KRAFTON/KORani-v1-13B",
        "BreadAi/gpt-YA-1-1_160M",
        "EleutherAI/polyglot-ko-1.3b",
        "dvruette/oasst-pythia-6.9b-4000-steps",
        "beomi/KoAlpaca-Polyglot-12.8B",
        "hakurei/Literature-7B-16384",
        "Fredithefish/RedPajama-INCITE-Chat-3B-ShareGPT-11K",
        "beomi/polyglot-ko-12.8b-safetensors",
        "cyberagent/open-calm-1b",
        "Dahoas/pythia-125M-static-sft",
        "EleutherAI/polyglot-ko-5.8b",
        "EleutherAI/pythia-160m",
        "OpenAssistant/pythia-12b-pre-v8-12.5k-steps",
        "mncai/SGPT-5.8B-insurance-only-epoch10",
        "EleutherAI/pythia-2.8b-v0",
        "mncai/SGPT-1.3B-insurance-epoch10",
        "amirabdullah19852020/pythia_70m_ppo_imdb_sentiment_v2",
        "jojo0217/ChatSKKU12.8BSFT",
        "dvruette/oasst-gpt-neox-20b-1000-steps",
        "EleutherAI/polyglot-ko-3.8b",
        "togethercomputer/RedPajama-INCITE-7B-Base",
        "wbrown/cassandra-2.8b",
        "qwopqwop/KoAlpaca-Polyglot-12.8B-GPTQ",
        "hoskinson-center/proofGPT-v0.1",
        "klosax/pythia-70m-deduped-step44k-92bt"
    ],
    "RobertaForMaskedLM": [
        "eduagarcia/r_j_v2_checkpoint_12000",
        "lexlms/legal-roberta-large",
        "ku-nlp/roberta-large-japanese-char-wwm",
        "rabindralamsal/bertweet_1",
        "PlanTL-GOB-ES/bsc-bio-ehr-es",
        "jhu-clsp/bibert-ende",
        "nreimers/MiniLMv2-L6-H384-distilled-from-RoBERTa-Large",
        "DDSC/roberta-base-danish",
        "climatebert/distilroberta-base-climate-f",
        "airesearch/wangchanberta-base-wiki-newmm",
        "PlanTL-GOB-ES/roberta-base-biomedical-clinical-es",
        "klue/roberta-large",
        "flax-community/indonesian-roberta-base",
        "facebook/dragon-roberta-context-encoder",
        "facebook/muppet-roberta-large",
        "mrm8488/chEMBL26_smiles_v2",
        "joelito/legal-croatian-roberta-base",
        "ehsanaghaei/SecureBERT",
        "DTAI-KULeuven/robbertje-1-gb-non-shuffled",
        "ai-forever/ruSciBERT",
        "kornosk/polibertweet-political-twitter-roberta-mlm",
        "nlp-waseda/roberta-large-japanese-seq512-with-auto-jumanpp",
        "KoichiYasuoka/roberta-classical-chinese-base-char",
        "timoneda/covid_roberta_40_masked",
        "DeepChem/ChemBERTa-10M-MLM",
        "johngiorgi/declutr-small",
        "eduagarcia-temp/brwac_v1_2__checkpoint_last",
        "new5558/HoogBERTa",
        "sentence-transformers/all-roberta-large-v1",
        "rabindralamsal/roberta_3",
        "vinai/phobert-large",
        "joelito/legal-xlm-roberta-large",
        "BSC-LT/roberta-base-bne",
        "svalabs/ger-roberta",
        "vinai/bertweet-covid19-base-cased",
        "gerulata/slovakbert",
        "PlanTL-GOB-ES/roberta-large-bne",
        "nreimers/MiniLMv2-L6-H768-distilled-from-RoBERTa-Large",
        "eduagarcia-temp/cnj_large_v1_2_dinkytrain__checkpoint_10_52000",
        "pdelobelle/robbert-v2-dutch-base",
        "Salesforce/grappa_large_jnt",
        "burakaytan/roberta-base-turkish-uncased",
        "josu/roberta-pt-br",
        "rabindralamsal/bertweet_3",
        "witiko/mathberta",
        "ethanyt/guwenbert-base",
        "klue/roberta-base",
        "timoneda/covid_roberta_40",
        "PetchP/distilwangchanberta-base-att-spm-uncased",
        "smallbenchnlp/roberta-small",
        "nlp-waseda/roberta-large-japanese",
        "nguyenvulebinh/envibert",
        "flax-sentence-embeddings/all_datasets_v3_roberta-large",
        "rabindralamsal/roberta_1",
        "entropy/roberta_zinc_480m",
        "vinai/bertweet-base",
        "KoichiYasuoka/roberta-classical-chinese-large-char",
        "tdobrxl/ClinicBERT",
        "klue/roberta-small",
        "facebook/dragon-roberta-query-encoder",
        "saibo/legal-roberta-base",
        "sdadas/polish-roberta-large-v2",
        "olm/olm-roberta-base-dec-2022",
        "youscan/ukr-roberta-base",
        "olm/olm-roberta-base-latest",
        "sentence-transformers/all-distilroberta-v1",
        "launch/POLITICS",
        "roberta-base",
        "johngiorgi/declutr-base",
        "KoichiYasuoka/roberta-base-chinese",
        "seyonec/SMILES_BPE_PubChem_100k_shard00",
        "facebook/muppet-roberta-base",
        "pysentimiento/robertuito-base-cased",
        "eduagarcia-temp/cnj_large_v1_2_dinkytrain_weird",
        "SCAI-BIO/bio-gottbert-base",
        "aiola/roberta-base-corener",
        "neulab/codebert-javascript",
        "blinoff/roberta-base-russian-v0",
        "stevhliu/my_awesome_eli5_mlm_model",
        "mrm8488/chEMBL_smiles_v1",
        "julien-c/dummy-diff-tokenizer",
        "eduagarcia-temp/brwac_large_v1_2__checkpoint_last",
        "vinai/xphonebert-base",
        "ethanyt/guwenbert-large",
        "neulab/codebert-java",
        "HeNLP/HeRo",
        "rinna/japanese-roberta-base",
        "ku-nlp/roberta-base-japanese-char-wwm",
        "eduagarcia-temp/cnj_v1_2__checkpoint_last",
        "InriaValda/cc_math_roberta_ep10",
        "ixa-ehu/roberta-eus-euscrawl-large-cased",
        "ku-accms/roberta-base-japanese-ssuw",
        "zzxslp/RadBERT-RoBERTa-4m",
        "joelito/legal-xlm-roberta-base",
        "lexlms/legal-roberta-base",
        "PlanTL-GOB-ES/roberta-base-biomedical-es",
        "hf-internal-testing/tiny-random-RobertaForMaskedLM",
        "mideind/IceBERT",
        "neulab/codebert-cpp",
        "cardiffnlp/twitter-roberta-base"
    ],
    "DistilBertForSequenceClassification": [
        "dima806/medium-article-titles-engagement-all",
        "valurank/finetuned-distilbert-news-article-categorization",
        "sbcBI/sentiment_analysis_model",
        "andypyc/news_classifier-distilbert-base-uncased-subject-only",
        "andi611/distilbert-base-uncased-qa-boolq",
        "DoryDing/Depression_Detection_Model_v2",
        "typeform/distilbert-base-uncased-mnli",
        "hidude562/Wiki-Complexity",
        "apple/ane-distilbert-base-uncased-finetuned-sst-2-english",
        "derekma/extreme-heat-relevancy",
        "distilbert-base-uncased-finetuned-sst-2-english",
        "stevhliu/my_awesome_model",
        "divyanshj03/pretrained_scalable_ai_model",
        "sreeniketh/cyberbullying_sentiment_dsce_2023",
        "Wi/arxiv-distilbert-base-cased",
        "autoevaluate/natural-language-inference",
        "okho0653/distilbert-base-uncased-zero-shot-sentiment-model",
        "sampathkethineedi/industry-classification",
        "bdotloh/distilbert-base-uncased-empathetic-dialogues-context",
        "Seethal/sentiment_analysis_generic_dataset",
        "cnicu/product_classifier",
        "AyoubChLin/DistilBERT_ZeroShot",
        "Souvikcmsa/SentimentAnalysisDistillBERT",
        "somm/distilbert-multilingual-uncased-en-de-fr-nov-24-epoch-1",
        "langfab/distilbert-base-uncased-finetuned-movie-genre",
        "osiloke/dilbert_uncased_product_categories",
        "umangsoni/distilbert-base-tuned",
        "arbazk/maestroqa-distilbert-negative-sentiment",
        "sgugger/tiny-distilbert-classification",
        "zaid683/my_model_683",
        "EzJustME/distilbert-base-uncased-finetuned-supply-chain-act-violations_ENGLISH",
        "rogelioplatt/distilbert-base-multilingual-cased-Sarcasmo_Esp",
        "nightlyfade/finetuning-sentiment-model-3000-samples",
        "hf-tiny-model-private/tiny-random-DistilBertForSequenceClassification",
        "ruibo-agi/distilbert-base-uncased-finetuned-toxicity",
        "Kayvane/distilbert-complaints-product",
        "philschmid/distilbert-base-multilingual-cased-sentiment-2",
        "transformersbook/distilbert-base-uncased-finetuned-emotion",
        "anth0nyhak1m/Upload_test_model",
        "Rocketknight1/distilbert-base-uncased-finetuned-cola",
        "textattack/distilbert-base-cased-CoLA",
        "lxyuan/banking-intent-distilbert-classifier",
        "Zlatislav/NSFW-Prompt-Detector",
        "SetFit/distilbert-base-uncased__enron_spam__all-train",
        "derenrich/psychiq2",
        "bhadresh-savani/distilbert-base-uncased-sentiment-sst2",
        "wesleyacheng/news-topic-classification-with-bert",
        "AntoineMC/distilbart-mnli-github-issues",
        "rdpahalavan/bert-network-packet-flow-header-payload",
        "cogitosum84/twittersentimentv5",
        "mayapapaya/Keyword-Extractor",
        "thomasavare/distilbert-ft-test3",
        "federicopascual/finetuning-sentiment-model-3000-samples",
        "JeffreyHuang/llm-selector",
        "hf-internal-testing/tiny-random-distilbert",
        "KernAI/stock-news-distilbert",
        "traberph/RedBERT",
        "danlupu/sentiment-analysis",
        "EzJustME/distilbert-base-uncased-finetuned-supply-chain-act-relevance_ENGLISH",
        "manishiitg/distilbert-resume-parts-classify",
        "austinmw/distilbert-base-uncased-finetuned-health_facts",
        "Narsil/tiny-distilbert-sequence-classification",
        "winegarj/distilbert-base-uncased-finetuned-sst2",
        "ml6team/distilbert-base-german-cased-toxic-comments",
        "mwkby/distilbert-base-uncased-sentiment-reddit-crypto",
        "knkarthick/Action_Items",
        "rarisenpai/my-awesome-model_v2",
        "amansolanki/autonlp-Tweet-Sentiment-Extraction-20114061",
        "chitra/distilbert-negation",
        "hafidikhsan/distilbert-base-uncased-english-cefr-lexical-evaluation-bs-v3",
        "IAyoub/finetuning-bert-sentiment-reviews",
        "textattack/distilbert-base-uncased-imdb",
        "satendrakumar/covid_miss_information_classification2",
        "Mraleksa/deepnote_huggingface_exitrunews_v1",
        "valurank/finetuned-distilbert-explicit-content-detection",
        "optimum/distilbert-base-uncased-finetuned-sst-2-english",
        "debate-land/paradigm-model",
        "EzJustME/distilbert-base-multilingual-cased-finetuned-supply-chain-act-violations_GERMAN",
        "citizenlab/distilbert-base-multilingual-cased-toxicity",
        "alexgshaw/hyperpartisan-classifier",
        "hazrulakmal/distilbert-optimised-finetuned-financial-sentiment",
        "echarlaix/distilbert-base-uncased-finetuned-sst-2-english-int8-dynamic",
        "PJHinAI/sentiment-model-finetuning-using-steam-data",
        "wesleyacheng/movie-review-sentiment-classifier-with-bert",
        "echarlaix/distilbert-sst2-inc-dynamic-quantization-magnitude-pruning-0.1",
        "joeddav/distilbert-base-uncased-go-emotions-student",
        "d4data/bias-detection-model",
        "dipesh/Intent-Classification-small",
        "alimazhar-110/website_classification",
        "bardsai/finance-sentiment-zh-fast",
        "ebrigham/EYY-Topic-Classification",
        "lvwerra/distilbert-imdb",
        "NLP-LTU/distilbert-sexism-detector",
        "sarahflan/distilbert-base-uncased-finetuned-AS_sentences",
        "Xenova/distilbert-base-uncased-finetuned-sst-2-english",
        "optimum/distilbert-base-uncased-finetuned-banking77",
        "Tejas3/distillbert_base_uncased_80_equal",
        "aXhyra/presentation_irony_1234567",
        "laurenmit/distilbert-base-uncased-question_classifier-3GROUPS",
        "michellejieli/inappropriate_text_classifier"
    ],
    "RobertaForSequenceClassification": [
        "samarla/RoBERTa-base-cola",
        "valurank/distilroberta-offensive",
        "zhayunduo/roberta-base-stocktwits-finetuned",
        "Heber77/paraquantizar",
        "laurens88/finetuning-crypto-tweet-sentiment-test2",
        "Andrianos/paraphrase_classification_onestop_and_adversarial",
        "pysentimiento/robertuito-emotion-analysis",
        "Hello-SimpleAI/chatgpt-qa-detector-roberta",
        "DAMO-NLP-SG/zero-shot-classify-SSTuning-large",
        "climatebert/distilroberta-base-climate-detector",
        "cardiffnlp/bertweet-base-offensive",
        "cardiffnlp/twitter-roberta-base-2021-124m-offensive",
        "valurank/distilroberta-clickbait",
        "DTAI-KULeuven/robbert-v2-dutch-sentiment",
        "cardiffnlp/bertweet-base-sentiment",
        "climatebert/distilroberta-base-climate-specificity",
        "cardiffnlp/twitter-roberta-base-hate-multiclass-latest",
        "hackathon-pln-es/bertin-roberta-base-zeroshot-esnli",
        "cross-encoder/quora-distilroberta-base",
        "grammarly/detexd-roberta-base",
        "dhtocks/Topic-Classification",
        "cardiffnlp/twitter-roberta-base-hate-latest",
        "Dzeniks/roberta-fact-check",
        "IsaacZhy/roberta-large-goemotions",
        "rabindralamsal/BERTsent",
        "ChrisLiewJY/BERTweet-Hedge",
        "Rasith/NzsentimentApp",
        "ncduy/phobert-large-finetuned-vietnamese_students_feedback",
        "PlanTL-GOB-ES/roberta-large-bne-te",
        "niksmer/PolicyBERTa-7d",
        "Xuhui/ToxDect-roberta-large",
        "pparasurama/raceBERT",
        "bhadresh-savani/roberta-base-emotion",
        "argilla/roberta-base-reward-model-falcon-dolly",
        "gtfintechlab/FOMC-RoBERTa",
        "cardiffnlp/roberta-large-tweet-topic-single-all",
        "akahana/indonesia-emotion-roberta",
        "McGill-NLP/roberta-large-faithcritic",
        "valurank/distilroberta-news-small",
        "icelab/TraceClassifier",
        "kwoncho/ko-sroberta-multitask-suspicious",
        "cointegrated/roberta-large-cola-krishna2020",
        "vg055/roberta-base-bne-finetuned-TripAdvisorDomainAdaptation-finetuned-e2-RestMex2023-polaridadDA-V1",
        "w11wo/indonesian-roberta-base-sentiment-classifier",
        "gargam/roberta-base-crest",
        "WillHeld/roberta-base-sst2",
        "vg055/roberta-base-bne-finetuned-TripAdvisorDomainAdaptation-finetuned-e2-RestMex2023-tipo",
        "cardiffnlp/twitter-roberta-base-emotion",
        "valurank/distilroberta-bias",
        "SH-W/autotrain-koichi-77017140438",
        "NTUYG/DeepSCC-RoBERTa",
        "climatebert/renewable",
        "VictorSanh/roberta-base-finetuned-yelp-polarity",
        "ibm/ColD-Fusion",
        "ayameRushia/roberta-base-indonesian-1.5G-sentiment-analysis-smsa",
        "ishaansharma/topic-detector",
        "pysentimiento/robertuito-irony",
        "cointegrated/roberta-base-formality",
        "bespin-global/klue-roberta-small-3i4k-intent-classification",
        "pongjin/roberta_with_kornli",
        "facebook/roberta-hate-speech-dynabench-r4-target",
        "SAPOSS/password-model",
        "hamzab/roberta-fake-news-classification",
        "pysentimiento/bertweet-pt-sentiment",
        "RogerKam/roberta_fine_tuned_sentiment_sst3",
        "mrm8488/distilroberta-finetuned-financial-news-sentiment-analysis",
        "Siddish/autotrain-yes-or-no-classifier-on-circa-1009033469",
        "cross-encoder/nli-MiniLM2-L6-H768",
        "dvruette/bertweet-large_augmented",
        "ikoghoemmanuell/finetuned_fake_news_roberta",
        "Narrativaai/fake-news-detection-spanish",
        "luohy/ESP-roberta-large",
        "textattack/roberta-base-CoLA",
        "huggingface/CodeBERTa-language-id",
        "badmatr11x/roberta-base-emotions-detection-from-text",
        "Sedigh/RoBERTa-large-PM-M3-Voc",
        "edumunozsala/RuPERTa_base_sentiment_analysis_es",
        "alirezamsh/quip-512-mocha",
        "shatabdi/twisent_twisent",
        "yobi/klue-roberta-base-ynat",
        "cardiffnlp/tweet-topic-latest-multi",
        "cardiffnlp/twitter-roberta-base-offensive",
        "cardiffnlp/twitter-roberta-base-dec2021-tweet-topic-multi-all",
        "mrm8488/codebert-base-finetuned-detect-insecure-code",
        "MYC007/Real-and-Fake-News-Detection",
        "RussianNLP/ruRoBERTa-large-rucola",
        "climatebert/transition-physical",
        "w11wo/indonesian-roberta-base-indolem-sentiment-classifier-fold-0",
        "RogerKam/roberta_RCADE_fine_tuned_sentiment_covid_news",
        "pysentimiento/roberta-targeted-sentiment-analysis",
        "climatebert/environmental-claims",
        "typeform/roberta-large-mnli",
        "eevvgg/StanceBERTa",
        "finiteautomata/bertweet-base-sentiment-analysis",
        "soleimanian/financial-roberta-large-sentiment",
        "pysentimiento/robertuito-sentiment-analysis",
        "ElKulako/cryptobert",
        "cardiffnlp/twitter-roberta-base-hate",
        "cross-encoder/quora-roberta-large",
        "facebook/roberta-hate-speech-dynabench-r1-target"
    ],
    "BartForConditionalGeneration": [
        "voidful/bart-distractor-generation-both",
        "kabita-choudhary/finetuned-bart-for-conversation-summary",
        "circulus/canvers-ko2en-v1",
        "Babelscape/rebel-large",
        "com3dian/Bart-large-paper2slides-expander",
        "kworts/BARTxiv",
        "Yelyzaveta/facebook-bart-large-cnn",
        "sshleifer/distilbart-xsum-12-3",
        "s-nlp/bart-base-detox",
        "slauw87/bart_summarisation",
        "cogint/in-boxbart",
        "Madan490/finetuned_multi_news_bart_text_summarisation",
        "sshleifer/distilbart-cnn-12-3",
        "fnlp/bart-base-chinese",
        "rycont/KoQuestionBART",
        "gogamza/kobart-summarization",
        "philschmid/tf-distilbart-cnn-12-6",
        "Yale-LILY/reastap-large-finetuned-wikisql",
        "ainize/bart-base-cnn",
        "morenolq/bart-it-ilpost",
        "zjunlp/MolGen-large",
        "IDEA-CCNL/Randeng-BART-139M-SUMMARY",
        "Qiliang/bart-large-cnn-samsum-ElectrifAi_v14",
        "tteofili/gplus",
        "NICFRU/bart-base-paraphrasing-review",
        "RajithaMuthukrishnan/text-summariser-english",
        "lmqg/bart-large-squad-qg-ae",
        "cloudqi/cqi_brain_memory_summarizer_large_pt_v0",
        "Debal/bart-large-samsum-action-items",
        "abc-turabit/bart_lfqa-finetuned_QA",
        "yuchenlin/BART0pp",
        "oliverguhr/spelling-correction-english-base",
        "z-dickson/bart-large-cnn-climate-change-summarization",
        "sshleifer/tiny-mbart",
        "Cynki/rtsum_abs_bart",
        "circulus/kobart-trans-dialect-v2",
        "divg07/facebook-bart-large-news",
        "sjyyj/sjyyj",
        "circulus/kobart-trans-polite-v2",
        "Salesforce/discord_qg",
        "voidful/bart-eqg-question-generator",
        "vaishali/multitabqa-base-sql",
        "tteofili/gminus",
        "kaejo98/bart-base_question_generation",
        "lidiya/bart-large-xsum-samsum",
        "rasta/BART-FHIR-summerize",
        "tanviraumi/meeting-summary",
        "lca0503/speech-chatgpt-base-ar-v2-epoch10-wotrans",
        "knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM-AMI",
        "Davidai/BART_lfqa_oracle_gpt",
        "uer/bart-chinese-6-960-cluecorpussmall",
        "circulus/kobart-chat-all-v2",
        "heegyu/kobart-text-style-transfer",
        "sshleifer/distilbart-xsum-12-6",
        "jian1114/jian_KoBART_title",
        "fnlp/cpt-large",
        "vblagoje/bart_lfqa",
        "knkarthick/MEETING_SUMMARY",
        "Salesforce/cods-bart-large-xsum-samsum",
        "knkarthick/meeting-summary-samsum",
        "Qiliang/bart-large-cnn-samsum-ElectrifAi_v13",
        "lidiya/bart-base-samsum",
        "theojolliffe/bart-cnn-science",
        "fanxiao/CGRE_CNDBPedia-Generative-Relation-Extraction",
        "cffl/bart-base-styletransfer-subjective-to-neutral",
        "circulus/kobart-trans-ko-en-v2",
        "sshleifer/tinier_bart",
        "Ybhav14/autotrain-chat-sum-dialogsum-samsum-46317114985",
        "pinglarin/summarization_papers",
        "microsoft/tapex-base",
        "harouzie/bart-base-xsum",
        "Evan-Lin/yelp-bart-base",
        "Soyoung97/gec_kr",
        "Salesforce/bart-large-xsum-samsum",
        "NICFRU/bart-base-paraphrasing-story",
        "pszemraj/bart-base-grammar-synthesis",
        "GanjinZero/biobart-base",
        "Qilex/bart-largeEN-ME",
        "eugenesiow/bart-paraphrase",
        "sshleifer/distilbart-xsum-12-1",
        "knkarthick/MEETING-SUMMARY-BART-LARGE-XSUM-SAMSUM-DIALOGSUM",
        "morenolq/bart-it",
        "morenolq/bart-it-fanpage",
        "guialfaro/korean-paraphrasing",
        "neulab/omnitab-large-1024shot-finetuned-wtq-1024shot",
        "NICFRU/bart-base-paraphrasing-news",
        "chinhon/headline_writer",
        "sander-wood/text-to-music",
        "walkerrose/cv_summarization-distilbart-cnn-16-6",
        "xfbai/AMRBART-large-finetuned-AMR3.0-AMR2Text-v2",
        "HIT-TMG/dialogue-bart-large-chinese",
        "tdopierre/ProtAugment-ParaphraseGenerator",
        "sshleifer/distilbart-cnn-12-6",
        "mismayil/comet-bart-ai2",
        "rvashurin/bart_base_aeslc",
        "morenolq/bart-it-WITS",
        "mabrouk/amazon-review-summarizer-bart",
        "Sehong/kobart-QuestionGeneration",
        "yuningm/bart-large-citesum-title",
        "RUCAIBox/elmer"
    ],
    "Wav2Vec2ForCTC": [
        "arijitx/wav2vec2-xls-r-300m-bengali",
        "birgermoell/psst-fairseq-voice-clone",
        "patrickvonplaten/wav2vec2-large-xlsr-53-spanish-with-lm",
        "vitouphy/wav2vec2-xls-r-300m-phoneme",
        "robinhad/wav2vec2-xls-r-300m-uk",
        "CuongLD/wav2vec2-large-xlsr-vietnamese",
        "alaa1997/ArabicSpeechToTextModel",
        "yongjian/wav2vec2-large-a",
        "patrickvonplaten/wav2vec2-base-100h-with-lm",
        "jonatasgrosman/wav2vec2-xls-r-1b-german",
        "facebook/mms-1b-all",
        "carlosdanielhernandezmena/wav2vec2-large-xlsr-53-spanish-ep5-944h",
        "othrif/wav2vec2-large-xlsr-moroccan",
        "lgris/wav2vec2-large-xlsr-open-brazilian-portuguese",
        "ydshieh/wav2vec2-large-xlsr-53-chinese-zh-cn-gpt",
        "omarxadel/wav2vec2-large-xlsr-53-arabic-egyptian",
        "Hyuk/wav2vec2-korean-v2",
        "mesolitica/wav2vec2-xls-r-300m-mixed",
        "facebook/wav2vec2-large-960h-lv60",
        "anton-l/wav2vec2-large-xlsr-53-russian",
        "bond005/wav2vec2-large-ru-golos",
        "jonatasgrosman/wav2vec2-large-fr-voxpopuli-french",
        "Mustafaa4a/wav2vec2-large-xls-r-300m-tr-kaggle",
        "Harveenchadha/vakyansh-wav2vec2-hindi-him-4200",
        "classla/wav2vec2-xls-r-parlaspeech-hr",
        "jonatasgrosman/wav2vec2-large-xlsr-53-portuguese",
        "AigizK/wav2vec2-large-xls-r-300m-bashkir-cv7_opt",
        "adilism/wav2vec2-large-xlsr-kazakh",
        "jonatasgrosman/wav2vec2-large-xlsr-53-hungarian",
        "gmihaila/wav2vec2-large-xlsr-53-romanian",
        "jonatasgrosman/wav2vec2-large-xlsr-53-italian",
        "arbml/wav2vec2-large-xlsr-53-arabic-egyptian",
        "khanhld/wav2vec2-base-vietnamese-160h",
        "indonesian-nlp/wav2vec2-indonesian-javanese-sundanese",
        "imvladikon/wav2vec2-xls-r-300m-hebrew",
        "ccoreilly/wav2vec2-large-100k-voxpopuli-catala",
        "Ilyes/wav2vec2-large-xlsr-53-french",
        "facebook/mms-1b-fl102",
        "mfleck/wav2vec2-large-xls-r-300m-german-with-lm",
        "jonatasgrosman/wav2vec2-large-xlsr-53-finnish",
        "ctaguchi/enja_cmu_10_4000",
        "hyyoka/wav2vec2-xlsr-korean-senior",
        "IbrahimSalah/Arabic_speech_Syllables_recognition_Using_Wav2vec2",
        "nguyenvulebinh/wav2vec2-base-vietnamese-250h",
        "voidful/wav2vec2-large-xlsr-53-tw-gpt",
        "Lemswasabi/wav2vec2-large-xlsr-53-842h-luxembourgish-11h",
        "kresnik/wav2vec2-large-xlsr-korean",
        "jonatasgrosman/wav2vec2-large-xlsr-53-french",
        "jonatasgrosman/wav2vec2-large-xlsr-53-greek",
        "infinitejoy/wav2vec2-large-xls-r-300m-slovenian",
        "unaidedelf87777/age_emotion_gender-classifier-for-audio-wav2vec2",
        "Lemswasabi/wav2vec2-large-xlsr-53-842h-luxembourgish-14h-with-lm",
        "anas/wav2vec2-large-xlsr-arabic",
        "indonesian-nlp/wav2vec2-luganda",
        "facebook/wav2vec2-base-10k-voxpopuli-ft-pl",
        "elgeish/wav2vec2-base-timit-asr",
        "m3hrdadfi/wav2vec2-large-xlsr-turkish",
        "jonatasgrosman/wav2vec2-xls-r-1b-portuguese",
        "ai4bharat/indicwav2vec_v1_gujarati",
        "DrishtiSharma/wav2vec2-large-xls-r-300m-sat-a3",
        "mpoyraz/wav2vec2-xls-r-300m-cv8-turkish",
        "indonesian-nlp/wav2vec2-large-xlsr-indonesian",
        "facebook/mms-1b-l1107",
        "boris/xlsr-en-punctuation",
        "m3hrdadfi/wav2vec2-large-xlsr-persian-v3",
        "jonatasgrosman/wav2vec2-large-xlsr-53-persian",
        "nalini2799/CDAC_hindispeechrecognition",
        "nguyenvulebinh/wav2vec2-large-vi-vlsp2020",
        "amoghsgopadi/wav2vec2-large-xlsr-kn",
        "ProgramadorArtificial/wav2vec2-large-xlsr-53-portuguese",
        "Harveenchadha/vakyansh-wav2vec2-telugu-tem-100",
        "patrickvonplaten/wav2vec2-large-960h-lv60-self-4-gram",
        "facebook/wav2vec2-base-100h",
        "facebook/wav2vec2-large-xlsr-53-french",
        "facebook/wav2vec2-large-robust-ft-swbd-300h",
        "mohammed/wav2vec2-large-xlsr-arabic",
        "glob-asr/wav2vec2-xls-r-300m-spanish-large-LM",
        "jonatasgrosman/wav2vec2-xls-r-1b-russian",
        "mpoyraz/wav2vec2-xls-r-300m-cv7-turkish",
        "comodoro/wav2vec2-xls-r-300m-cs-250",
        "vumichien/wav2vec2-large-xlsr-japanese",
        "maxidl/wav2vec2-large-xlsr-german",
        "wadhwani-ai/orf-gu-wav2vec2",
        "carlosdanielhernandezmena/wav2vec2-large-xlsr-53-faroese-100h",
        "shahukareem/wav2vec2-xls-r-1b-dv",
        "theainerd/Wav2Vec2-large-xlsr-hindi",
        "Harveenchadha/vakyansh-wav2vec2-indian-english-enm-700",
        "facebook/wav2vec2-large-xlsr-53-german",
        "jonatasgrosman/wav2vec2-large-xlsr-53-chinese-zh-cn",
        "ai4bharat/indicwav2vec-hindi",
        "shahukareem/wav2vec2-large-xlsr-53-dhivehi",
        "hf-internal-testing/tiny-random-Wav2Vec2ForCTC",
        "techiaith/wav2vec2-xlsr-ft-cy",
        "lighteternal/wav2vec2-large-xlsr-53-greek",
        "jonatasgrosman/wav2vec2-large-xlsr-53-german",
        "ashesicsis1/lv60-languageModel",
        "facebook/wav2vec2-xlsr-53-espeak-cv-ft",
        "nguyenvulebinh/lyric-alignment",
        "malay-huggingface/wav2vec2-xls-r-1b-mixed",
        "KBLab/wav2vec2-large-xlsr-53-swedish"
    ],
    "BertModel": [
        "skt/kobert-base-v1",
        "consciousAI/cai-lunaris-text-embeddings",
        "l3cube-pune/hindi-sentence-similarity-sbert",
        "intfloat/e5-large",
        "pritamdeka/BioBERT-mnli-snli-scinli-scitail-mednli-stsb",
        "mrp/simcse-model-m-bert-thai-cased",
        "valurank/MiniLM-L6-Keyword-Extraction",
        "optimum/tiny_random_bert_neuronx",
        "malteos/scincl",
        "jhgan/ko-sbert-sts",
        "princeton-nlp/sup-simcse-bert-base-uncased",
        "bongsoo/kpf-sbert-v1.1",
        "murali1996/bert-base-cased-spell-correction",
        "intfloat/simlm-base-msmarco-finetuned",
        "intfloat/e5-base",
        "microsoft/xtremedistil-l6-h384-uncased",
        "optimum/sbert-all-MiniLM-L6-with-pooler",
        "Shitao/flag-text-embedding-chinese",
        "sentence-transformers/msmarco-bert-base-dot-v5",
        "intfloat/e5-small-v2",
        "lanwuwei/GigaBERT-v3-Arabic-and-English",
        "nthakur/mcontriever-base-msmarco",
        "allegro/herbert-large-cased",
        "GanjinZero/coder_eng_pp",
        "thenlper/gte-large",
        "JeremiahZ/TinyBERT_4L_zh_backup",
        "michiyasunaga/BioLinkBERT-base",
        "sentence-transformers/nli-bert-large-max-pooling",
        "llm-book/bert-base-japanese-v3-unsup-simcse-jawiki",
        "sentence-transformers/allenai-specter",
        "rufimelo/Legal-BERTimbau-sts-large-ma-v3",
        "YoungsAhn/math_cdc",
        "hf-internal-testing/tiny-random-bert-variant-safe",
        "sentence-transformers/paraphrase-MiniLM-L12-v2",
        "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2",
        "TurkuNLP/sbert-cased-finnish-paraphrase",
        "GanjinZero/UMLSBert_ENG",
        "DeepPavlov/rubert-base-cased",
        "haisongzhang/roberta-tiny-cased",
        "hf-internal-testing/tiny-random-bert-fx-only",
        "castorini/unicoil-noexp-msmarco-passage",
        "moka-ai/m3e-small",
        "sentence-transformers/stsb-bert-base",
        "PM-AI/bi-encoder_msmarco_bert-base_german",
        "DeepPavlov/rubert-base-cased-sentence",
        "dmis-lab/biobert-v1.1",
        "rasa/LaBSE",
        "Vsevolod/company-names-similarity-sentence-transformer",
        "sentence-transformers/msmarco-MiniLM-L6-cos-v5",
        "KennethEnevoldsen/dfm-sentence-encoder-large-1",
        "castorini/mdpr-tied-pft-nq",
        "allenai/aspire-biencoder-biomed-scib",
        "sonoisa/sentence-bert-base-ja-mean-tokens-v2",
        "fionawyu/fast_coref_cn",
        "pritamdeka/S-Bluebert-snli-multinli-stsb",
        "intfloat/e5-base-unsupervised",
        "KennethEnevoldsen/dfm-sentence-encoder-medium-3",
        "sonoisa/sentence-bert-base-ja-en-mean-tokens-v2",
        "thenlper/gte-base",
        "inkoziev/sbert_pq",
        "Jerado/all-MiniLM-L6-v2-finetuned",
        "salesken/similarity-eng-hin_latin",
        "M-CLIP/M-BERT-Base-ViT-B",
        "moka-ai/m3e-base",
        "KBLab/sentence-bert-swedish-cased",
        "hiiamsid/sentence_similarity_spanish_es",
        "LoneWolfgang/bert-for-japanese-twitter",
        "castorini/tct_colbert-v2-hnp-msmarco",
        "hf-internal-testing/tiny-bert-tf-only",
        "sangmini/msmarco-cotmae-MiniLM-L12_en-ko-ja",
        "DMetaSoul/sbert-chinese-general-v2-distill",
        "Blaxzter/LaBSE-sentence-embeddings",
        "sonoisa/clip-vit-b-32-japanese-v1",
        "sentence-transformers/nli-bert-base",
        "setu4993/LaBSE",
        "sentence-transformers/paraphrase-MiniLM-L6-v2",
        "monsoon-nlp/hindi-bert",
        "jinmang2/kpfbert",
        "kmariunas/bert-triplet-50",
        "facebook/spar-wiki-bm25-lexmodel-query-encoder",
        "imxly/sentence_roberta_wwm_ext",
        "sentence-transformers/use-cmlm-multilingual",
        "sentence-transformers/LaBSE",
        "pranaydeeps/Ancient-Greek-BERT",
        "jhgan/ko-sbert-multitask",
        "BAAI/bge-large-zh",
        "sosuke/ease-bert-base-multilingual-cased",
        "monsoon-nlp/bert-base-thai",
        "moka-ai/m3e-large",
        "recobo/agri-sentence-transformer",
        "hfl/chinese-pert-base",
        "MU-Kindai/Japanese-SimCSE-BERT-base-sup",
        "flax-sentence-embeddings/all_datasets_v4_MiniLM-L6",
        "princeton-nlp/unsup-simcse-bert-base-uncased",
        "mingcai/ESimCSE-ext-chinese-bert-wwm",
        "KennethEnevoldsen/dfm-sentence-encoder-large-2",
        "snunlp/KR-SBERT-V40K-klueNLI-augSTS",
        "orai-nlp/ElhBERTeu",
        "stjiris/bert-large-portuguese-cased-legal-tsdae-gpl-nli-sts-MetaKD-v1",
        "ai-forever/sbert_large_mt_nlu_ru"
    ],
    "ViTForImageClassification": [
        "adam-bourne/food-classifier",
        "ipvikas/rare-puppers",
        "godiec/diam",
        "Ahmed9275/Vit-Cifar100",
        "hafidber/fruits",
        "firas-spanioli/beer-whisky-wine-detection",
        "google/vit-large-patch16-384",
        "router727/vit-base-patch16-224-in21k",
        "vesteinn/vit-mae-cub",
        "pittawat/vit-base-letter",
        "Amrrs/indian-foods",
        "hafidber/rare-puppers",
        "nateraw/donut-or-bagel",
        "gatecitypreservation/architectural_styles",
        "jordyvl/vit-base_tobacco",
        "nateraw/rare-puppers-09-04-2021",
        "julien-c/hotdog-not-hotdog",
        "quyc/picture",
        "joyc360/deepfakes",
        "Akshat/DysphagiaCls2label",
        "skyau/dog-breed-classifier-vit",
        "hgarg/fruits",
        "nickmuchi/vit-finetuned-chest-xray-pneumonia",
        "carbon225/vit-base-patch16-224-hentai",
        "hf-internal-testing/tiny-random-ViTForImageClassification",
        "nateraw/pasta-shapes",
        "AykeeSalazar/vc-bantai-vit-withoutAMBI",
        "google/vit-base-patch16-384",
        "jonathanfernandes/vit-base-patch16-224-finetuned-flower",
        "AhmedSayeem/VIT_Basic",
        "johnnydevriese/vit_beans",
        "nateraw/baseball-stadium-foods",
        "abhishek/autotrain_fashion_mnist_vit_base",
        "nateraw/ex-for-evan",
        "akahana/vit-base-cats-vs-dogs",
        "rizvandwiki/gender-classification-2",
        "tzhao3/vit-L-GTSRB",
        "domluna/vit-base-patch16-224-in21k-shiba-inu-detector",
        "johnnydevriese/vit-airplanes",
        "nateraw/vit-base-beans",
        "Frodnar/bee-likes",
        "tzhao3/vit-CIFAR10",
        "nateraw/denver-nyc-paris",
        "oschamp/vit-artworkclassifier",
        "driboune/skin_type",
        "iyzg/computer-stuff",
        "AkshatSurolia/ViT-FaceMask-Finetuned",
        "vincentclaes/mit-indoor-scenes",
        "varun1505/face-characteristics",
        "hf-internal-testing/tiny-random-vit",
        "hgarg/indian-snacks",
        "lewtun/oz-fauna",
        "satwikapaul/braille_classifier_3",
        "Amrrs/south-indian-foods",
        "filipafcastro/beer_vs_wine",
        "LorenzoDeMattei/lawn-weeds",
        "WT-MM/vit-base-blur",
        "UnipaPolitoUnimore/vit-large-patch32-384-melanoma",
        "nateraw/rare-puppers",
        "black/simple_kitchen",
        "Intel/vit-base-patch16-224-int8-static",
        "eslamxm/vit-base-food101",
        "abdusah/CarViT",
        "Rajaram1996/FacialEmoRecog",
        "jaygala24/finetuned-vit-base-patch16-224-upside-down-detector",
        "juanfiguera/ice_cream",
        "victor/autotrain-satellite-image-classification-40975105875",
        "ismgar01/vit-base-cats-vs-dogs",
        "meame2010/rare-puppers",
        "samipfjo/deer-detection",
        "satwikapaul/braille_4",
        "nateraw/vit-base-beans-demo-v3",
        "karthiksv/vit-base-patch16-224-in21k-finetuned-cifar10",
        "IDEA-CCNL/Taiyi-vit-87M-D",
        "DrishtiSharma/finetuned-ViT-human-action-recognition-v1",
        "nickmuchi/vit-finetuned-cats-dogs",
        "davanstrien/deit_flyswot",
        "Sena/flowers",
        "jordyvl/vit-base_rvl-cdip",
        "lysandre/tiny-vit-random",
        "aalonso-developer/vit-base-clothing-leafs-example-full-simple_highres",
        "nateraw/huggingpics-package-demo-2",
        "facebook/deit-small-patch16-224",
        "mrm8488/vit-base-patch16-224_finetuned-pneumothorax",
        "imjeffhi/pokemon_classifier",
        "ahishamm/vit-base-isic-patch-32",
        "nateraw/rare-puppers-demo",
        "edumunozsala/vit_base-224-in21k-ft-cifar100",
        "Zayn/VIT_Basic",
        "nateraw/vit-base-beans-demo-v2",
        "farleyknight/mnist-digit-classification-2022-09-04",
        "nateraw/vit-base-food101",
        "mmekias/vit-base-beans",
        "Aftabhussain/Tomato_Leaf_Classifier",
        "facebook/deit-base-patch16-384",
        "nateraw/planes-trains-automobiles",
        "Kevin-M-Smith/vit_300_300_5000",
        "kakaobrain/vit-large-patch16-384",
        "ferdinand/rare-puppers",
        "nateraw/pasta-pizza-ravioli"
    ],
    "MarianMTModel": [
        "liam168/trans-opus-mt-zh-en",
        "hf-internal-testing/tiny-random-MarianMTModel",
        "Helsinki-NLP/opus-mt-pt-ca",
        "Helsinki-NLP/opus-mt-en-hu",
        "Helsinki-NLP/opus-mt-en-zls",
        "salesken/translation-spanish-and-portuguese-to-english",
        "Helsinki-NLP/opus-mt-ca-pt",
        "Helsinki-NLP/opus-mt-tc-big-ar-en",
        "Helsinki-NLP/opus-mt-en-nl",
        "Helsinki-NLP/opus-mt-es-fi",
        "Helsinki-NLP/opus-mt-ko-ru",
        "Helsinki-NLP/opus-mt-tc-big-en-gmq",
        "Helsinki-NLP/opus-mt-de-da",
        "Helsinki-NLP/opus-mt-en-gl",
        "Helsinki-NLP/opus-mt-ine-en",
        "Helsinki-NLP/opus-mt-tc-base-en-sh",
        "Shularp/model-translate-en-to-ar-from-120k-dataset-ar-en-th230111447",
        "Helsinki-NLP/opus-mt-az-en",
        "Helsinki-NLP/opus-mt-de-fi",
        "gsarti/opus-mt-tc-big-en-de",
        "Helsinki-NLP/opus-mt-war-en",
        "Helsinki-NLP/opus-mt-en-zlw",
        "Helsinki-NLP/opus-mt-fi-de",
        "Helsinki-NLP/opus-mt-de-es",
        "Helsinki-NLP/opus-mt-en-gmq",
        "Helsinki-NLP/opus-mt-es-uk",
        "Helsinki-NLP/opus-mt-tc-big-en-fr",
        "AbhirupGhosh/opus-mt-finetuned-en-hi",
        "Helsinki-NLP/opus-mt-en-he",
        "luoyixin/marian-finetuned-kde4-en-to-zh",
        "Helsinki-NLP/opus-mt-ar-ru",
        "Helsinki-NLP/opus-mt-it-de",
        "sshleifer/tiny-marian-en-de",
        "Helsinki-NLP/opus-mt-ht-en",
        "cw1521/en-st-20",
        "Helsinki-NLP/opus-mt-en-de",
        "Helsinki-NLP/opus-mt-hu-en",
        "Helsinki-NLP/opus-mt-eu-es",
        "Helsinki-NLP/opus-mt-grk-en",
        "jmbt22/marian-finetuned-opus-mt-en-tl",
        "Helsinki-NLP/opus-mt-en-ur",
        "zhaozh/radiology-report-en-zh-ft-base",
        "Helsinki-NLP/opus-mt-en-zle",
        "Helsinki-NLP/opus-mt-tc-big-he-en",
        "Helsinki-NLP/opus-mt-en-zh",
        "Helsinki-NLP/opus-mt-fr-ar",
        "staka/fugumt-en-ja",
        "Helsinki-NLP/opus-mt-tc-big-fi-en",
        "Helsinki-NLP/opus-mt-it-fr",
        "Helsinki-NLP/opus-mt-en-jap",
        "Helsinki-NLP/opus-mt-el-fr",
        "context-mt/scat-marian-big-target-ctx4-cwd0-en-fr",
        "Helsinki-NLP/opus-mt-da-en",
        "Helsinki-NLP/opus-mt-pl-fr",
        "Helsinki-NLP/opus-mt-fr-pl",
        "Helsinki-NLP/opus-mt-tc-big-zls-en",
        "cw1521/en-st-30",
        "Helsinki-NLP/opus-mt-fi-fr",
        "Shularp/model-translate-en-to-ar-from-320k-dataset-ar-en-th2301191458",
        "Helsinki-NLP/opus-mt-it-en",
        "Helsinki-NLP/opus-mt-en-ca",
        "Helsinki-NLP/opus-mt-en-sk",
        "context-mt/scat-marian-big-ctx4-cwd1-en-fr",
        "zhaozh/medical_chat-en-zh",
        "Helsinki-NLP/opus-mt-en-fr",
        "Helsinki-NLP/opus-mt-en-cs",
        "Helsinki-NLP/opus-mt-lg-en",
        "Helsinki-NLP/opus-mt-ru-ar",
        "Helsinki-NLP/opus-mt-nl-en",
        "Helsinki-NLP/opus-mt-en-et",
        "Helsinki-NLP/opus-mt-tc-big-en-bg",
        "Helsinki-NLP/opus-mt-bat-en",
        "Helsinki-NLP/opus-mt-ru-en",
        "Helsinki-NLP/opus-mt-tl-en",
        "Helsinki-NLP/opus-mt-st-en",
        "Vidyuth/marian-finetuned-kde4-en-to-fr",
        "Helsinki-NLP/opus-mt-en-ar",
        "Helsinki-NLP/opus-mt-dra-en",
        "Helsinki-NLP/opus-mt-en-uk",
        "Helsinki-NLP/opus-mt-ja-ru",
        "Helsinki-NLP/opus-mt-sv-ru",
        "Helsinki-NLP/opus-mt-tc-big-en-ar",
        "Helsinki-NLP/opus-mt-fr-en",
        "Helsinki-NLP/opus-mt-en-mr",
        "Helsinki-NLP/opus-mt-en-itc",
        "Helsinki-NLP/opus-mt-de-ar",
        "Helsinki-NLP/opus-mt-roa-en",
        "Helsinki-NLP/opus-mt-en-tw",
        "Helsinki-NLP/opus-mt-gmq-en",
        "Helsinki-NLP/opus-mt-sv-fr",
        "Helsinki-NLP/opus-mt-fi-en",
        "Helsinki-NLP/opus-mt-nl-fi",
        "Helsinki-NLP/opus-mt-es-ro",
        "Helsinki-NLP/opus-mt-jap-en",
        "Helsinki-NLP/opus-mt-es-ar",
        "Helsinki-NLP/opus-mt-et-en",
        "Helsinki-NLP/opus-mt-es-fr",
        "Helsinki-NLP/opus-tatoeba-en-tr",
        "Helsinki-NLP/opus-mt-tc-big-zle-de",
        "Helsinki-NLP/opus-mt-fr-de"
    ],
    "BertForSequenceClassification": [
        "textattack/bert-base-uncased-rotten-tomatoes",
        "dlahiri/my_awesome_model",
        "deepset/gbert-base-germandpr-reranking",
        "jamescalam/bert-stsb-cross-encoder",
        "sismetanin/rubert-ru-sentiment-rusentiment",
        "llm-book/bert-base-japanese-v3-jnli",
        "savasy/bert-base-turkish-sentiment-cased",
        "DenilsenAxel/nlp-text-classification",
        "barissayil/bert-sentiment-analysis-sst",
        "abhishek/autonlp-bbc-news-classification-37229289",
        "philschmid/BERT-Banking77",
        "transformersbook/bert-base-uncased-finetuned-clinc",
        "saroarj/BanglaHateBert",
        "Hello-SimpleAI/chatgpt-detector-roberta-chinese",
        "m3hrdadfi/bert-fa-base-uncased-wikinli",
        "Jeevesh8/bert_ft_qqp_6ep-2",
        "DanL/scientific-challenges-and-directions",
        "LiYuan/amazon-review-sentiment-analysis",
        "nateraw/bert-base-uncased-imdb",
        "nateraw/bert-base-uncased-emotion",
        "hw2942/bert-base-chinese-finetuning-financial-news-sentiment-v2",
        "bongsoo/klue-cross-encoder-v1",
        "finiteautomata/beto-emotion-analysis",
        "cross-encoder/ms-marco-MiniLM-L-12-v2",
        "kit-nlp/bert-base-japanese-sentiment-cyberbullying",
        "HooshvareLab/bert-fa-base-uncased-sentiment-snappfood",
        "sackoh/bert-base-multilingual-cased-nsmc",
        "avichr/heBERT_sentiment_analysis",
        "CAMeL-Lab/bert-base-arabic-camelbert-mix-did-madar-corpus6",
        "avichr/hebEMO_surprise",
        "apanc/russian-sensitive-topics",
        "cross-encoder/ms-marco-TinyBERT-L-6",
        "ModelTC/bert-base-uncased-mnli",
        "ziadA123/adultcontentclassifier",
        "Maximgitman/bert-dates-classifier",
        "sismetanin/rubert-toxic-pikabu-2ch",
        "seara/rubert-tiny2-russian-sentiment",
        "sismetanin/rubert_conversational-ru-sentiment-rusentiment",
        "rohanrajpal/bert-base-codemixed-uncased-sentiment",
        "amedvedev/bert-tiny-cognitive-bias",
        "Hate-speech-CNERG/dehatebert-mono-german",
        "at2507/finetuned_model",
        "bdotloh/distilbert-base-uncased-go-emotion-empathetic-dialogues-context-v2",
        "Aniemore/rubert-tiny-emotion-russian-cedr-m7",
        "navteca/ms-marco-MiniLM-L-6-v2",
        "navteca/ms-marco-MiniLM-L-12-v2",
        "Jeevesh8/bert_ft_qqp_6ep-7",
        "ltkw98/Bert1",
        "DATEXIS/CORe-clinical-mortality-prediction",
        "cross-encoder/stsb-TinyBERT-L-4",
        "iarfmoose/bert-base-cased-qa-evaluator",
        "aiknowyou/it-emotion-analyzer",
        "dobbytk/letr-sol-profanity-filter",
        "morenolq/spotify-podcast-advertising-classification",
        "helinivan/italian-sarcasm-detector",
        "jonas/bert-base-uncased-finetuned-sdg-Mar23",
        "maxspad/nlp-qual-qual",
        "CAMeL-Lab/bert-base-arabic-camelbert-da-sentiment",
        "textattack/bert-base-uncased-snli",
        "buddhist-nlp/bod-eng-similarity",
        "marieke93/MiniLM-evidence-types",
        "ishan/bert-base-uncased-mnli",
        "KPF/KPF-bert-cls2",
        "maymuni/bert-base-turkish-cased-emotion-analysis",
        "z-dickson/multilingual_sentiment_newspaper_headlines",
        "thu-coai/roberta-base-cdconv",
        "marianna13/bert-multilingual-sentiment",
        "textattack/bert-base-uncased-SST-2",
        "bucketresearch/politicalBiasBERT",
        "pysentimiento/bertabaporu-pt-hate-speech",
        "Jeevesh8/bert_ft_qqp_6ep-8",
        "pritamdeka/PubMedBert-PubMed200kRCT",
        "alexandrainst/da-hatespeech-detection-base",
        "KAlex13/sq_news_city_features",
        "sasha/regardv3",
        "cross-encoder/ms-marco-MiniLM-L-6-v2",
        "jingwora/language-emotion-classification-ja",
        "textattack/bert-base-uncased-MNLI",
        "Junr-syl/sentiments_analysis_upgrade",
        "Elron/bleurt-large-512",
        "gokuls/BERT-tiny-sst2",
        "nbroad/sciwiki-e5-sm",
        "dpkrm/NepaliSentimentAnalysis",
        "JeremiahZ/bert-base-uncased-mnli",
        "Kodiks/news-category-classification-turkish",
        "nickmuchi/optimum-finbert-tone-finetuned-finance-topic-classification",
        "avichr/hebEMO_anticipation",
        "hemekci/off_detection_turkish",
        "IDEA-CCNL/Erlangshen-Roberta-330M-NLI",
        "maxspad/nlp-qual-q3i",
        "HooshvareLab/bert-fa-base-uncased-sentiment-deepsentipers-binary",
        "rohanrajpal/bert-base-multilingual-codemixed-cased-sentiment",
        "Souvikcmsa/BERT_sentiment_analysis",
        "bioformers/bioformer-8L-mnli",
        "Elron/bleurt-large-128",
        "Jeevesh8/bert_ft_qqp_6ep-19",
        "hf-internal-testing/tiny-random-BertForSequenceClassification",
        "lucasresck/bert-base-cased-ag-news",
        "NbAiLab/nb-bert-base-mnli",
        "llm-book/bert-base-japanese-v3-jsts"
    ],
    "BertForMaskedLM": [
        "KBLab/bert-base-swedish-cased-new",
        "IDEA-CCNL/Erlangshen-UniEX-RoBERTa-330M-Chinese",
        "osiria/bert-base-italian-uncased",
        "dbmdz/bert-base-italian-xxl-cased",
        "himanimaheshwari3/bert-base-uncased-finetuned-BERT-mlm9",
        "mosaicml/mosaic-bert-base-seqlen-1024",
        "explosion-testing/bert-test",
        "m3rg-iitd/matscibert",
        "Rajan/NepaliBERT",
        "qahq/CL-AraBERTv0.1-base",
        "ai4bharat/IndicBERTv2-MLM-only",
        "ckiplab/bert-tiny-chinese",
        "IDEA-CCNL/Erlangshen-MacBERT-110M-BinaryClassification-Chinese",
        "Geotrend/bert-base-fr-cased",
        "deepsense-ai/trelbert",
        "uer/chinese_roberta_L-2_H-256",
        "Langboat/mengzi-bert-base",
        "l3cube-pune/marathi-bert",
        "alabnii/jmedroberta-base-manbyo-wordpiece-vocab50000",
        "aubmindlab/bert-large-arabertv02-twitter",
        "nlpie/compact-biobert",
        "dccuchile/tulio-chilean-spanish-bert",
        "alfaneo/jurisbert-base-portuguese-uncased",
        "imvladikon/alephbertgimmel-base-512",
        "cl-tohoku/bert-base-japanese-char-v2",
        "nairaxo/bantu-bert",
        "yosuke/bert-base-japanese-char",
        "bert-base-german-cased",
        "HooshvareLab/bert-fa-zwnj-base",
        "TODBERT/TOD-BERT-JNT-V1",
        "cl-tohoku/bert-base-japanese-v2",
        "asafaya/bert-base-arabic",
        "facebook/dragon-plus-query-encoder",
        "shibing624/macbert4csc-base-chinese",
        "NepBERTa/NepBERTa",
        "GKLMIP/bert-tagalog-base-uncased",
        "nlpie/tiny-clinicalbert",
        "Luyu/condenser",
        "amine/bert-base-5lang-cased",
        "shafin/chemical-bert-uncased-finetuned-cust-c2",
        "yarongef/DistilProtBert",
        "alabnii/jmedroberta-base-sentencepiece",
        "aubmindlab/bert-base-arabertv2",
        "kykim/bert-kor-base",
        "tdopierre/ProtAugment-LM-Liu",
        "tbs17/MathBERT",
        "bert-base-german-dbmdz-uncased",
        "TurkuNLP/bert-base-finnish-uncased-v1",
        "rahular/varta-bert",
        "KM4STfulltext/SSCI-SciBERT-e2",
        "pranav-s/MaterialsBERT",
        "ltg/norbert2",
        "cahya/bert-base-indonesian-522M",
        "jjzha/jobbert-base-cased",
        "gwlms/bert-base-dewiki-v1",
        "bert-base-cased",
        "shahrukhx01/smole-bert",
        "eliolio/bert-base-tapt-govreport",
        "UBC-NLP/MARBERT",
        "tsantos/PathologyBERT",
        "linhd-postdata/alberti-bert-base-multilingual-cased",
        "zhihan1996/DNABERT-2-117M",
        "bert-base-cased-finetuned-mrpc",
        "GroNLP/bert-base-dutch-cased",
        "Shushant/nepaliBERT",
        "hf-tiny-model-private/tiny-random-BertForMaskedLM",
        "recobo/agriculture-bert-uncased",
        "chcaa/dfm-encoder-large-v1",
        "avichr/Legal-heBERT",
        "hfl/chinese-macbert-base",
        "bert-large-uncased-whole-word-masking",
        "malay-huggingface/bert-base-bahasa-cased",
        "Twitter/twhin-bert-large",
        "Rostlab/prot_bert",
        "ayansinha/lic-class-scancode-bert-base-cased-L32-1",
        "cahya/bert-base-indonesian-1.5G",
        "ai-forever/ruBert-base",
        "Geotrend/bert-base-en-zh-cased",
        "ayansinha/false-positives-scancode-bert-base-uncased-L8-1",
        "remi/bertabs-finetuned-cnndm-extractive-abstractive-summarization",
        "SIKU-BERT/sikuroberta",
        "aubmindlab/bert-base-arabertv02-twitter",
        "dbmdz/bert-base-german-cased",
        "uer/roberta-small-wwm-chinese-cluecorpussmall",
        "uer/chinese_roberta_L-10_H-128",
        "hfl/chinese-bert-wwm",
        "tbs17/MathBERT-custom",
        "snunlp/KR-FinBert",
        "marcosgg/bert-base-gl-cased",
        "CAMeL-Lab/bert-base-arabic-camelbert-ca",
        "IVN-RIN/medBIT-r3-plus",
        "flax-community/alberti-bert-base-multilingual-cased",
        "m-polignano-uniba/bert_uncased_L-12_H-768_A-12_italian_alb3rt0",
        "flax-community/bert-base-uncased-swahili",
        "hfl/rbt3",
        "soBeauty/5_20230714_01-bert-base-multilingual-cased-confusion",
        "UBC-NLP/ARBERTv2",
        "uer/chinese_roberta_L-8_H-512",
        "soBeauty/6_20230714_01-bert-base-multilingual-cased-confusion",
        "avichr/heBERT"
    ],
    "T5ForConditionalGeneration": [
        "jdchang/t5_10_bc",
        "razent/SciFive-base-PMC",
        "PrimeQA/t5-base-hybrid-question-generator",
        "newsrx/t5-base-en-generate-headline",
        "patrickvonplaten/t5-tiny-random",
        "jordiclive/flan-t5-11b-summarizer-filtered",
        "allenai/unifiedqa-t5-3b",
        "hetpandya/t5-base-tapaco",
        "mohammadhia/t5_recommendation_sports_equipment_english",
        "vishal2014/updated_t5_squad_mcq_vam",
        "cointegrated/rut5-base",
        "google/t5-large-ssm",
        "it5/it5-large-question-generation",
        "mrm8488/t5-small-finetuned-quora-for-paraphrasing",
        "uer/t5-small-chinese-cluecorpussmall",
        "ThomasNLG/t5-qg_squad1-en",
        "castorini/t5-base-canard",
        "ConvLab/t5-small-dst-sgd",
        "north/t5_small_NCC_lm",
        "sayanmandal/t5-small_6_3-hinglish",
        "retrieva-jp/t5-large-medium",
        "ishajo/meeting_summarization_usingT5",
        "yarika/cocktail_maker",
        "metamyth/jennyNew",
        "ufal/byt5-small-multilexnorm2021-nl",
        "razent/SciFive-large-Pubmed_PMC-MedNLI",
        "it5/it5-base-news-summarization",
        "deep-learning-analytics/wikihow-t5-small",
        "scieditor/citation-generation-t5",
        "declare-lab/flan-alpaca-xl",
        "sultan/ArabicT5-Base",
        "sagard21/python-code-explainer",
        "traintogpb/pko-t5-large-kor-for-colloquial-summarization-finetuned",
        "hmbyt5-preliminary/byt5-small-multilingual-4g-3e",
        "MingZhong/unieval-dialog",
        "google/flan-t5-small",
        "google/t5-efficient-small",
        "mamiksik/T5-commit-message-generation",
        "cometrain/stocks-news-t5",
        "lvwerra/t5-imdb",
        "Salesforce/mixqg-large",
        "michelecafagna26/t5-base-finetuned-sst2-sentiment",
        "ClueAI/PromptCLUE-base",
        "Wikidepia/IndoT5-base-paraphrase",
        "lmsys/fastchat-t5-3b-v1.0",
        "srirammadduri-ts/autotrain-pocnl2keywords-75118139836",
        "Bhuvana/t5-base-spellchecker",
        "charsiu/g2p_multilingual_byT5_tiny_8_layers_100",
        "hetpandya/t5-small-tapaco",
        "valhalla/t5-small-e2e-qg",
        "pragmatic-programs/speaker-prefix-idx-300k",
        "ozcangundes/T5-base-for-BioQA",
        "csebuetnlp/banglat5",
        "bitadin/gpt-4-medium-titles-v2-flan-t5-base-llm-6",
        "LarkAI/codet5p-770m_nl2sql_oig",
        "ZWK/InstructUIE",
        "Rostlab/prot_t5_xxl_uniref50",
        "paust/pko-t5-large",
        "sysresearch101/t5-large-finetuned-xsum",
        "allenai/entailer-large",
        "fabiochiu/t5-small-medium-title-generation",
        "t5-base",
        "VietAI/vit5-base-vietnews-summarization",
        "sysresearch101/t5-large-finetuned-xsum-cnn",
        "it5/it5-efficient-small-el32-news-summarization",
        "efederici/text2tags",
        "ThoughtFocusAI/CodeGeneration-CodeT5-base",
        "VietAI/vit5-large-vietnews-summarization",
        "google/t5-efficient-tiny-nl2",
        "malmarjeh/t5-arabic-text-summarization",
        "megagonlabs/t5-base-japanese-web",
        "Den4ikAI/FRED-T5-XL_instructor",
        "allenai/tk-instruct-base-def-pos",
        "SEBIS/legal_t5_small_trans_fr_en",
        "lmqg/t5-small-squad-qa",
        "muchad/idt5-qa-qg",
        "razent/SciFive-base-Pubmed",
        "hafidikhsan/happy-transformer-t5-base-grammar-correction-ep-v1",
        "Rostlab/ProstT5",
        "north/t5_base_NCC",
        "GT4SD/multitask-text-and-chemistry-t5-base-standard",
        "llm-blender/gen_fuser_3b",
        "ClueAI/ChatYuan-large-v1",
        "bitadin/gpt-4-long-titles-v2-flan-t5-base-llm-12",
        "jmeadows17/MathT5-large",
        "BeIR/query-gen-msmarco-t5-large-v1",
        "toloka/t5-large-for-text-aggregation",
        "google/t5-xxl-lm-adapt",
        "google/ul2",
        "IlyaGusev/rut5_base_sum_gazeta",
        "google/flan-ul2",
        "dawei756/text-to-sql-t5-spider-fine-tuned",
        "sanjay-m1/informal-to-formal",
        "laituan245/molt5-large-smiles2caption",
        "SivilTaram/tapex-t5-large-finetuned-wtq",
        "allenai/tk-instruct-large-def-pos",
        "ElnaggarLab/ankh-base",
        "tscholak/2e826ioa",
        "valhalla/t5-base-qg-hl",
        "lmqg/flan-t5-large-squad-qg-ae"
    ],
    "LlamaForCausalLM": [
        "OpenAssistant/llama2-13b-orca-v2-8k-3166",
        "dvruette/llama-13b-pretrained",
        "TheBloke/Llama-2-13B-Chat-fp16",
        "openthaigpt/openthaigpt-0.1.0-beta-ckpt-hf",
        "TheBloke/llama2-7b-chat-codeCherryPop-qLoRA-GPTQ",
        "FPHam/Pure_Sydney_13b_GPTQ",
        "TheBloke/airoboros-13b-gpt4-fp16",
        "AtomEchoAI/AtomGPT_14k_chat_4bit",
        "yahma/llama-7b-hf",
        "jondurbin/airoboros-33b-gpt4-m2.0",
        "taozi555/waifu",
        "TheBloke/airoboros-l2-7B-gpt4-m2.0-GPTQ",
        "sharpbai/Llama-2-13b-chat-hf",
        "TheBloke/llama-30b-supercot-SuperHOT-8K-GPTQ",
        "nbroad/llama_sm_hd128",
        "TheBloke/Vicuna-13B-CoT-GPTQ",
        "VMware/open-llama-7b-v2-open-instruct",
        "TheBloke/Llama-2-7B-GPTQ",
        "nkpz/llama2-22b-chat-wizard-uncensored",
        "OpenBuddy/openbuddy-openllama-7b-v5-fp16",
        "bjoernp/thorsten_v0.1",
        "teknium/Base-GPT4-x-Alpaca-Roleplay-Lora",
        "digitous/13B-HyperMantis",
        "nbroad/llama_sm_hd64",
        "psmathur/orca_mini_v2_13b",
        "jphme/orca_mini_v2_ger_7b",
        "alexl83/LLaMA-33B-HF",
        "TheBloke/koala-13B-GPTQ",
        "abhinavkulkarni/meta-llama-Llama-2-7b-chat-hf-w4-g128-awq",
        "camenduru/MiniGPT4",
        "XuYipei/kw-cutegpt-13b-ift",
        "allenai/tulu-7b",
        "TheBloke/airoboros-13B-gpt4-1.4-GPTQ",
        "wordcab/llama-natural-instructions-7b",
        "TheBloke/orca_mini_v2_13b-GPTQ",
        "TheBloke/Guanaco-33B-SuperHOT-8K-GPTQ",
        "klosax/open_llama_3b_350bt_preview",
        "ToolBench/ToolLLaMA-7b",
        "TheBloke/WizardLM-30B-fp16",
        "LLMs/WizardLM-13B-V1.0",
        "bofenghuang/vigogne-13b-instruct",
        "gurgutan/saiga2-13b-4bit",
        "Austism/chronos-wizardlm-uc-scot-st-13b",
        "Salesforce/codegen25-7b-instruct",
        "illuin/test-custom-llama",
        "jphme/Llama-2-13b-chat-german",
        "jondurbin/airoboros-l2-13b-gpt4-2.0",
        "TheBloke/Llama-2-70B-fp16",
        "meta-llama/Llama-2-13b-chat-hf",
        "TheBloke/WizardLM-30B-GPTQ",
        "pillowtalks-ai/delta13b",
        "localmodels/Llama-2-13B-Chat-GPTQ",
        "TheBloke/Vicuna-13B-1-3-SuperHOT-8K-GPTQ",
        "jinxuewen/vicuna-13b",
        "rabitt/Chinese-Alpaca-Plus-13B-GPTQ",
        "localmodels/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ",
        "asifhugs/open_llama_13b_8k",
        "jeffwan/vicuna-13b",
        "TheBloke/wizard-vicuna-13B-GPTQ",
        "circulus/Llama-2-13b-orca-v1",
        "togethercomputer/LLaMA-2-7B-32K",
        "ashercn97/giraffe-7b",
        "openlm-research/open_llama_3b_v2",
        "IDEA-CCNL/Ziya-Writing-LLaMa-13B-v1",
        "samwit/koala-7b",
        "Neko-Institute-of-Science/LLaMA-7B-4bit-128g",
        "TheBloke/AlpacaCielo-13B-GPTQ",
        "bofenghuang/vigogne-33b-instruct",
        "digitous/Alpacino30b",
        "OpenAssistant/llama2-13b-orca-8k-3319",
        "jploski/llama-7b-hf",
        "mrm8488/llama-2-coder-7b",
        "reeducator/vicuna-13b-free",
        "elinas/chronos-13b-4bit",
        "lmsys/vicuna-7b-delta-v0",
        "daryl149/llama-2-70b-chat-hf",
        "VMware/open-llama-0.7T-7B-open-instruct-v1.1",
        "TheBloke/Nous-Hermes-13B-SuperHOT-8K-GPTQ",
        "TheBloke/Wizard-Vicuna-13B-Uncensored-SuperHOT-8K-GPTQ",
        "4bit/Llama-2-7b-Chat-GPTQ",
        "jondurbin/airoboros-7b",
        "conceptofmind/Flan-Open-Llama-3b",
        "TheBloke/vicuna-7B-1.1-GPTQ-4bit-128g",
        "elinas/chronos-13b-8k-GPTQ",
        "psymon/KoLlama2-7b",
        "karlbooster/pygmalion7b-20230517",
        "TheBloke/Chronoboros-33B-GPTQ",
        "mindrage/Manticore-13B-Chat-Pyg-Guanaco-GGML",
        "jondurbin/airoboros-7b-gpt4-1.2",
        "cnut1648/llama-7b_helpful_only_0718",
        "bofenghuang/vigogne-2-7b-instruct",
        "TheBloke/orca_mini_7B-GPTQ",
        "clibrain/Llama-2-ft-instruct-es",
        "NousResearch/Llama-2-7b-hf",
        "MagicLEMP/llama-2-13B-vigogne",
        "TheBloke/WizardLM-33B-V1-0-Uncensored-SuperHOT-8K-GPTQ",
        "TheBloke/Llama-2-7B-fp16",
        "elinas/llama-30b-hf-transformers-4.29",
        "wahaha1987/llama_7b_sharegpt94k_fastchat",
        "TheBloke/Manticore-13B-Chat-Pyg-SuperHOT-8K-GPTQ"
    ],
    "MT5ForConditionalGeneration": [
        "doc2query/msmarco-japanese-mt5-base-v1",
        "lmqg/mt5-small-jaquad-qg-ae",
        "lmqg/mt5-small-itquad-ae",
        "lmqg/mt5-small-jaquad-ae",
        "kriton/greek-text-summarization",
        "DKYoon/mt5-large-lm-adapt",
        "deutsche-telekom/mt5-small-sum-de-mit-v1",
        "AhiyaB/mt5-small-finetuned-Big-Patent-h",
        "alan-turing-institute/mt5-large-finetuned-mnli-xtreme-xnli",
        "junsun10/mt5-base-kor-paper-summary",
        "lmqg/mt5-small-frquad-ae",
        "bigscience/mt0-xxl",
        "persiannlp/mt5-large-parsinlu-translation_en_fa",
        "secometo/mt5-base-turkish-question-paraphrase-generator",
        "lmqg/mt5-small-esquad-qag",
        "google/mt5-xl",
        "Narrativa/mT5-base-finetuned-tydiQA-xqa",
        "erlingh/mt5-large-no",
        "lmqg/mt5-small-koquad-qg-ae",
        "lmqg/mt5-small-ruquad-qg-ae",
        "trl-internal-testing/tiny-random-MT5ForConditionalGeneration",
        "mwz/UrduSum",
        "csebuetnlp/mT5_m2m_crossSum",
        "persiannlp/mt5-small-parsinlu-translation_en_fa",
        "ozcangundes/mt5-multitask-qa-qg-turkish",
        "sarakolding/daT5-base",
        "lmqg/mt5-small-dequad-qg-ae",
        "qcz/en-sv-UFAL-medical",
        "lmqg/mt5-small-ruquad-qg",
        "lemon234071/t5-base-Chinese",
        "3BDOAi3/finetuned_with_labeled_dataset",
        "bigscience/mt0-small",
        "csebuetnlp/mT5_m2o_arabic_crossSum",
        "ahmeddbahaa/mT5_multilingual_XLSum-finetuned-wikilingua-ar",
        "dzadvornov/fin-mt5-long-extract4000",
        "lmqg/mt5-small-koquad-ae",
        "bigscience/mt0-large",
        "erikgrip2/mt5-finetuned-for-motion-title",
        "T-Systems-onsite/mt5-small-sum-de-en-v2",
        "IDEA-CCNL/Randeng-T5-784M-QA-Chinese",
        "lmqg/mt5-small-jaquad-qg",
        "csebuetnlp/mT5_m2o_english_crossSum",
        "lmqg/mt5-small-frquad-qg",
        "lmqg/mt5-small-dequad-qg",
        "google/mt5-large",
        "spursyy/mT5_multilingual_XLSum_rust",
        "cointegrated/rut5-small",
        "doc2query/msmarco-german-mt5-base-v1",
        "uer/t5-v1_1-base-chinese-cluecorpussmall",
        "persiannlp/mt5-base-parsinlu-translation_en_fa",
        "imvladikon/het5_small_summarization",
        "csebuetnlp/mT5_m2o_chinese_simplified_crossSum",
        "aiautomationlab/german-news-title-gen-mt5",
        "lalon/autotrain-taz-deep-social-66601136628",
        "lmqg/mt5-small-frquad-qag",
        "lmqg/mt5-base-jaquad-qag",
        "persiannlp/mt5-large-parsinlu-opus-translation_fa_en",
        "bigscience/mt0-base",
        "jalbarracin/spanish-alpaca-mT5",
        "doc2query/msmarco-14langs-mt5-base-v1",
        "lmqg/mt5-small-esquad-qg",
        "csebuetnlp/mT5_m2o_russian_crossSum",
        "persiannlp/mt5-base-parsinlu-qqp-query-paraphrasing",
        "yihsuan/mt5_chinese_small",
        "DKYoon/mt5-base-lm-adapt",
        "google/mt5-small",
        "SGaleshchuk/t5-large-ua-news",
        "K024/mt5-zh-ja-en-trimmed",
        "lalon/autotrain-taz-deep-social-66601136627",
        "tsmatz/mt5_summarize_japanese",
        "ell-hol/mT5-dialogSum",
        "persiannlp/mt5-base-parsinlu-sentiment-analysis",
        "lmqg/mt5-small-itquad-qg-ae",
        "noah-ai/mt5-base-question-generation-vi",
        "csebuetnlp/mT5_m2o_hindi_crossSum",
        "ahmeddbahaa/mT5_multilingual_XLSum-finetuned-fa",
        "persiannlp/mt5-small-parsinlu-squad-reading-comprehension",
        "lmqg/mt5-small-frquad-qg-ae",
        "bigscience/mt0-xxl-mt",
        "theblackcat102/alpaca-title-generator-mt0-large",
        "csebuetnlp/mT5_multilingual_XLSum",
        "lmqg/mt5-base-ruquad-qag",
        "lmqg/mt5-small-koquad-qg",
        "thilina/mt5-sinhalese-english",
        "algolet/mt5-base-chinese-qg",
        "persiannlp/mt5-small-parsinlu-qqp-query-paraphrasing",
        "josmunpen/mt5-small-spanish-summarization",
        "eslamxm/mt5-base-finetuned-persian",
        "csebuetnlp/mT5_m2m_crossSum_enhanced",
        "IIC/mt5-spanish-mlsum",
        "persiannlp/mt5-base-parsinlu-squad-reading-comprehension",
        "botisan-ai/mt5-translate-yue-zh",
        "ctu-aic/mt5-base-multilingual-summarization-multilarge-cs",
        "bigscience/mt0-xl",
        "traintogpb/mt5-large-kor-qa-generation-finetuned",
        "obss/mt5-base-3task-highlight-tquad2",
        "unicamp-dl/mt5-13b-mmarco-100k",
        "doc2query/msmarco-portuguese-mt5-base-v1",
        "persiannlp/mt5-base-parsinlu-opus-translation_fa_en",
        "unicamp-dl/mt5-base-mmarco-v2"
    ],
    "BertForTokenClassification": [
        "akdeniz27/bert-base-turkish-cased-ner-quantized",
        "Andrija/M-bert-NER",
        "aitslab/biobert_huner_species_v1",
        "CAMeL-Lab/bert-base-arabic-camelbert-ca-ner",
        "HooshvareLab/bert-fa-zwnj-base-ner",
        "hatmimoha/arabic-ner",
        "pucpr/clinicalnerpt-healthcare",
        "lfcc/bert-portuguese-ner-archive",
        "ken11/bert-japanese-ner",
        "noahjadallah/cause-effect-detection",
        "iguanodon-ai/bert-base-finnish-uncased-ner",
        "HooshvareLab/bert-fa-base-uncased-ner-peyma",
        "DimasikKurd/sbert_large_nlu_ru_ner",
        "aitslab/biobert_huner_disease_v1",
        "RecordedFuture/Swedish-NER",
        "ronoys/PyRX",
        "dslim/bert-large-NER",
        "hf-internal-testing/tiny-random-BertForTokenClassification",
        "pucpr/clinicalnerpt-laboratory",
        "jurabi/bert-ner-japanese",
        "sagorsarker/mbert-bengali-ner",
        "monilouise/ner_news_portuguese",
        "sshleifer/tiny-distilbert-base-cased",
        "Davlan/bert-base-multilingual-cased-ner-hrl",
        "abhibisht89/spanbert-large-cased-finetuned-ade_corpus_v2",
        "tesemnikov-av/rubert-ner-toxicity",
        "pkushiqiang/bert-degree-major-ner-1000",
        "Mizuiro-sakura/bert-large-japanese-v2-finetuned-ner",
        "gilf/french-postag-model",
        "shubham555/biobert-finetuned-ner",
        "KoichiYasuoka/bert-base-russian-upos",
        "wietsedv/bert-base-dutch-cased-finetuned-udlassy-ner",
        "rajpurkarlab/gilbert",
        "ArunaSaraswathy/bert-finetuned-ner-pii",
        "Maltehb/danish-bert-botxo-ner-dane",
        "sshleifer/tiny-dbmdz-bert-large-cased-finetuned-conll03-english",
        "camila-ud/DrBERT-CASM2",
        "CAMeL-Lab/bert-base-arabic-camelbert-mix-pos-msa",
        "ml6team/bert-base-uncased-city-country-ner",
        "ckiplab/bert-base-han-chinese-ws",
        "sociocom/MedNER-CR-JA",
        "CAMeL-Lab/bert-base-arabic-camelbert-ca-pos-egy",
        "Maltehb/danish-bert-botxo",
        "KoichiYasuoka/bert-large-japanese-upos",
        "samrawal/bert-large-uncased_med-ner",
        "felflare/bert-restore-punctuation",
        "ckiplab/bert-base-han-chinese-pos-zhonggu",
        "alvaroalon2/biobert_chemical_ner",
        "KB/bert-base-swedish-cased-ner",
        "Trail/chem-bert-attempt",
        "CAMeL-Lab/bert-base-arabic-camelbert-msa-ner",
        "p208p2002/zh-wiki-punctuation-restore",
        "pruas/BENT-PubMedBERT-NER-Chemical",
        "HooshvareLab/bert-base-parsbert-peymaner-uncased",
        "ugaray96/biobert_ncbi_disease_ner",
        "batterydata/bde-pos-bert-cased-base",
        "ukkendane/bert-medical-ner",
        "KoichiYasuoka/bert-base-slavic-cyrillic-upos",
        "CarlaSoe/personal-noun-detection-german-bert",
        "sachaarbonel/bert-italian-cased-finetuned-pos",
        "mrm8488/bert-spanish-cased-finetuned-ner",
        "girinlp-i2i/phibert-finetuned-ner",
        "HooshvareLab/bert-base-parsbert-armanner-uncased",
        "dslim/bert-base-NER",
        "cahya/bert-base-indonesian-NER",
        "batterydata/bde-abbrev-batteryonlybert-cased-base",
        "osiria/bert-italian-uncased-ner",
        "MohametSena/bio_srl",
        "tner/bert-base-tweetner7-2021",
        "ai4bharat/IndicNER",
        "Jorgeutd/bert-large-uncased-finetuned-ner",
        "tanfiona/unicausal-tok-baseline",
        "nickprock/bert-italian-finetuned-ner",
        "surdan/LaBSE_ner_nerel",
        "QCRI/bert-base-multilingual-cased-pos-english",
        "IlyaGusev/rubert_ext_sum_gazeta",
        "sschet/bert-base-uncased_clinical-ner",
        "savasy/bert-base-turkish-ner-cased",
        "pietruszkowiec/herbert-base-ner",
        "yanekyuk/bert-keyword-extractor",
        "raynardj/classical-chinese-punctuation-guwen-biaodian",
        "Salvatore/bert-finetuned-mutation-recognition-1",
        "ageng-anugrah/indobert-large-p2-finetuned-ner",
        "cointegrated/rubert-base-lesha17-punctuation",
        "Dizex/FoodBaseBERT-NER",
        "cfilt/HiNER-original-muril-base-cased",
        "sxandie/autotrain-re_syn_cleanedtext_bert-55272128958",
        "pucpr/clinicalnerpt-disorder",
        "kamalkraj/bert-base-cased-ner-conll2003",
        "avichr/heBERT_NER",
        "pucpr/clinicalnerpt-disease",
        "0x7194633/rubert-base-massive-ner",
        "CAMeL-Lab/bert-base-arabic-camelbert-ca-pos-msa",
        "ckiplab/bert-tiny-chinese-ner",
        "johnyyhk/bert-finetuned-ner-chinese-people-daily",
        "joon09/kor-naver-ner-name-v2",
        "ghadeermobasher/BC5CDR-Chemical-Disease-balanced-biobert-base-cased-v1.2",
        "aakorolyova/primary_and_secondary_outcome_extraction",
        "st1992/bert-restore-punctuation",
        "ckiplab/bert-tiny-chinese-ws"
    ],
    "GPT2LMHeadModel": [
        "egonrp/gpt2-medium-squadv11-portuguese",
        "xkianteb/alg_ppo_separate_lr_1e-6_n_epochs_10_v_epochs_10_kl_target_1.0_clip_range_0.2",
        "Soumyajit1008/DialoGPT-small-harryPotterssen",
        "lxyuan/distilgpt2-finetuned-finance",
        "Narsil/gpt3",
        "KhanAdeeb/model-tony-stark",
        "shahp7575/gpt2-horoscopes",
        "ss1612/loki-chat",
        "abjbpi/Dwight_Schrute",
        "procesaur/gpt2-srlat-synt",
        "MBZUAI/LaMini-Cerebras-256M",
        "Kirili4ik/ruDialoGpt3-medium-finetuned-telegram",
        "huggingtweets/wallstreetbets",
        "datatab/gpt2-serbian-base",
        "KnutJaegersberg/gpt-2-xl-EvolInstruct",
        "skt/ko-gpt-trinity-1.2B-v0.5",
        "florentiino/DialoGPT-small-harrypotter",
        "ChukSamuels/DialoGPT-small-Dr.FauciBot",
        "PlanTL-GOB-ES/gpt2-base-bne",
        "aspis/gpt2-genre-story-generation",
        "SaylorTwift/gpt2_test",
        "Locutusque/gpt2-large-conversational",
        "IlyaGusev/rugpt3medium_sum_gazeta",
        "DAMO-NLP-MT/polylm-multialpaca-13b",
        "miguelvictor/python-gpt2-large",
        "spoudel/tweets-small",
        "AmbricJohnson5888/claura",
        "EnterNameBros/Senko-san-medium-sc",
        "skt/kogpt2-base-v2",
        "spital/gpt2-small-czech-cs",
        "satvikag/chatbot",
        "abhiramtirumala/DialoGPT-sarcastic",
        "Tidum/DialoGPT-large-Michael",
        "jerteh/sr-gpt2-large",
        "daspartho/prompt-extend",
        "microsoft/CodeGPT-small-java",
        "ingen51/DialoGPT-medium-GPT4",
        "BlightZz/DialoGPT-medium-Kurisu",
        "Dinocroth/DialoGPT-medium-Trevor-PhilipsV2",
        "AUTOMATIC/promptgen-lexart",
        "stanford-crfm/battlestar-gpt2-small-x49",
        "rwl4/gpt2-medium-chat",
        "heegyu/kodialogpt-v0",
        "MBZUAI/LaMini-Cerebras-590M",
        "vanilladucky/Friends_chatting_bot_redefined",
        "Meli/GPT2-Prompt",
        "microsoft/CodeGPT-small-py-adaptedGPT2",
        "olm/olm-gpt2-dec-2022",
        "shyamsn97/Mario-GPT2-700-context-length",
        "codeparrot/codeparrot-small-code-to-text",
        "MarkyMarx/DialoGPT-medium-jimmybot2",
        "pearsonkyle/gpt2-arxiv",
        "Corianas/Quokka_256m",
        "HamidRezaAttar/gpt2-product-description-generator",
        "Ashypaws/DialoGPT-medium-Ashybot",
        "SebastianSchramm/Cerebras-GPT-111M-instruction",
        "rinna/japanese-gpt2-small",
        "AUTOMATIC/promptgen-majinai-safe",
        "huggingtweets/elonmusk",
        "LorenzoDeMattei/GePpeTto",
        "jackoyoungblood/TinyStoriesTest-epoch1-2",
        "dbddv01/gpt2-french-small",
        "cedpsam/chatbot_fr",
        "MYX4567/distilgpt2-finetuned-wikitext2",
        "lighteternal/gpt2-finetuned-greek-small",
        "imperialwool/ai-dungeon-medium-rus",
        "woodmtaylor/DialoGPT-medium-Heej",
        "Ashypaws/DialoGPT-medium-Kitaibot",
        "DunnBC22/gpt2-Causal_Language_Model-AG_News",
        "AlekseyKorshuk/gpt2-jokes",
        "armandnlp/gpt2-TOD_finetuned_SGD",
        "cahya/indochat-tiny",
        "gpt2-xl",
        "kopeqwerty/DialoGPT-medium-idotbot",
        "DAMO-NLP-MT/polylm-1.7b",
        "Aj-Cdr/jokes-gpt",
        "codeparrot/codeparrot-small",
        "Stromello/DialoGPT-medium-ZeroTwo",
        "seeksery/DialoGPT-calig3",
        "ml6team/gpt-2-medium-conditional-quote-generator",
        "lysandre/arxiv-nlp",
        "stanford-crfm/beren-gpt2-medium-x49",
        "polandball/GPT-Polen",
        "Maxwere/DiabloGPT-medium-maxbot",
        "Karzan/kurdishbert",
        "wanderer/DialoGPT-small-Phoebe",
        "olm/olm-gpt2-oct-2022",
        "danyaljj/gpt2_question_answering_squad2",
        "huggingtweets/gordonramsay",
        "GroNLP/gpt2-medium-dutch-embeddings",
        "stefan-it/german-gpt2-larger",
        "MysteriousAmazon/DialoGPT-medium-freddy",
        "Grendar/Dialo-GPT-medium-shiro",
        "usmiva/gpt-web-bg",
        "Pcik/DialoGPT-medium-Kirby",
        "stanford-crfm/darkmatter-gpt2-small-x343",
        "CarperAI/randomwalks",
        "TFLai/gpt2-turkish-uncased",
        "saiful9379/Bangla_GPT2",
        "pratultandon/recipe-nlg-gpt2-train11_15"
    ]
}