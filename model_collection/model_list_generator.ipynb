{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ALBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ALIGN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALIGN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALTCLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ALTCLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ASTConfig',\n",
       " 'ASTFeatureExtractor',\n",
       " 'ASTForAudioClassification',\n",
       " 'ASTModel',\n",
       " 'ASTPreTrainedModel',\n",
       " 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'AUDIO_SPECTROGRAM_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'Adafactor',\n",
       " 'AdamW',\n",
       " 'AdamWeightDecay',\n",
       " 'AdaptiveEmbedding',\n",
       " 'AddedToken',\n",
       " 'AlbertConfig',\n",
       " 'AlbertForMaskedLM',\n",
       " 'AlbertForMultipleChoice',\n",
       " 'AlbertForPreTraining',\n",
       " 'AlbertForQuestionAnswering',\n",
       " 'AlbertForSequenceClassification',\n",
       " 'AlbertForTokenClassification',\n",
       " 'AlbertModel',\n",
       " 'AlbertPreTrainedModel',\n",
       " 'AlbertTokenizer',\n",
       " 'AlbertTokenizerFast',\n",
       " 'AlignConfig',\n",
       " 'AlignModel',\n",
       " 'AlignPreTrainedModel',\n",
       " 'AlignProcessor',\n",
       " 'AlignTextConfig',\n",
       " 'AlignTextModel',\n",
       " 'AlignVisionConfig',\n",
       " 'AlignVisionModel',\n",
       " 'AltCLIPConfig',\n",
       " 'AltCLIPModel',\n",
       " 'AltCLIPPreTrainedModel',\n",
       " 'AltCLIPProcessor',\n",
       " 'AltCLIPTextConfig',\n",
       " 'AltCLIPTextModel',\n",
       " 'AltCLIPVisionConfig',\n",
       " 'AltCLIPVisionModel',\n",
       " 'AudioClassificationPipeline',\n",
       " 'AutoBackbone',\n",
       " 'AutoConfig',\n",
       " 'AutoFeatureExtractor',\n",
       " 'AutoImageProcessor',\n",
       " 'AutoModel',\n",
       " 'AutoModelForAudioClassification',\n",
       " 'AutoModelForAudioFrameClassification',\n",
       " 'AutoModelForAudioXVector',\n",
       " 'AutoModelForCTC',\n",
       " 'AutoModelForCausalLM',\n",
       " 'AutoModelForDepthEstimation',\n",
       " 'AutoModelForDocumentQuestionAnswering',\n",
       " 'AutoModelForImageClassification',\n",
       " 'AutoModelForImageSegmentation',\n",
       " 'AutoModelForInstanceSegmentation',\n",
       " 'AutoModelForMaskedImageModeling',\n",
       " 'AutoModelForMaskedLM',\n",
       " 'AutoModelForMultipleChoice',\n",
       " 'AutoModelForNextSentencePrediction',\n",
       " 'AutoModelForObjectDetection',\n",
       " 'AutoModelForPreTraining',\n",
       " 'AutoModelForQuestionAnswering',\n",
       " 'AutoModelForSemanticSegmentation',\n",
       " 'AutoModelForSeq2SeqLM',\n",
       " 'AutoModelForSequenceClassification',\n",
       " 'AutoModelForSpeechSeq2Seq',\n",
       " 'AutoModelForTableQuestionAnswering',\n",
       " 'AutoModelForTokenClassification',\n",
       " 'AutoModelForUniversalSegmentation',\n",
       " 'AutoModelForVideoClassification',\n",
       " 'AutoModelForVision2Seq',\n",
       " 'AutoModelForVisualQuestionAnswering',\n",
       " 'AutoModelForZeroShotImageClassification',\n",
       " 'AutoModelForZeroShotObjectDetection',\n",
       " 'AutoModelWithLMHead',\n",
       " 'AutoProcessor',\n",
       " 'AutoTokenizer',\n",
       " 'AutomaticSpeechRecognitionPipeline',\n",
       " 'BART_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BEIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BEIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIGBIRD_PEGASUS_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIGBIRD_PEGASUS_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIG_BIRD_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIG_BIRD_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIOGPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIOGPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLENDERBOT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLENDERBOT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLENDERBOT_SMALL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLENDERBOT_SMALL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLIP_2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLIP_2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BLOOM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BLOOM_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BRIDGETOWER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'BRIDGETOWER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'BartConfig',\n",
       " 'BartForCausalLM',\n",
       " 'BartForConditionalGeneration',\n",
       " 'BartForQuestionAnswering',\n",
       " 'BartForSequenceClassification',\n",
       " 'BartModel',\n",
       " 'BartPretrainedModel',\n",
       " 'BartTokenizer',\n",
       " 'BartTokenizerFast',\n",
       " 'BarthezTokenizer',\n",
       " 'BarthezTokenizerFast',\n",
       " 'BartphoTokenizer',\n",
       " 'BasicTokenizer',\n",
       " 'BatchEncoding',\n",
       " 'BatchFeature',\n",
       " 'BeamScorer',\n",
       " 'BeamSearchScorer',\n",
       " 'BeitConfig',\n",
       " 'BeitFeatureExtractor',\n",
       " 'BeitForImageClassification',\n",
       " 'BeitForMaskedImageModeling',\n",
       " 'BeitForSemanticSegmentation',\n",
       " 'BeitImageProcessor',\n",
       " 'BeitModel',\n",
       " 'BeitPreTrainedModel',\n",
       " 'BertConfig',\n",
       " 'BertForMaskedLM',\n",
       " 'BertForMultipleChoice',\n",
       " 'BertForNextSentencePrediction',\n",
       " 'BertForPreTraining',\n",
       " 'BertForQuestionAnswering',\n",
       " 'BertForSequenceClassification',\n",
       " 'BertForTokenClassification',\n",
       " 'BertGenerationConfig',\n",
       " 'BertGenerationDecoder',\n",
       " 'BertGenerationEncoder',\n",
       " 'BertGenerationPreTrainedModel',\n",
       " 'BertGenerationTokenizer',\n",
       " 'BertJapaneseTokenizer',\n",
       " 'BertLMHeadModel',\n",
       " 'BertLayer',\n",
       " 'BertModel',\n",
       " 'BertPreTrainedModel',\n",
       " 'BertTokenizer',\n",
       " 'BertTokenizerFast',\n",
       " 'BertweetTokenizer',\n",
       " 'BigBirdConfig',\n",
       " 'BigBirdForCausalLM',\n",
       " 'BigBirdForMaskedLM',\n",
       " 'BigBirdForMultipleChoice',\n",
       " 'BigBirdForPreTraining',\n",
       " 'BigBirdForQuestionAnswering',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdForTokenClassification',\n",
       " 'BigBirdLayer',\n",
       " 'BigBirdModel',\n",
       " 'BigBirdPegasusConfig',\n",
       " 'BigBirdPegasusForCausalLM',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BigBirdPegasusForQuestionAnswering',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'BigBirdPegasusModel',\n",
       " 'BigBirdPegasusPreTrainedModel',\n",
       " 'BigBirdPreTrainedModel',\n",
       " 'BigBirdTokenizer',\n",
       " 'BigBirdTokenizerFast',\n",
       " 'BioGptConfig',\n",
       " 'BioGptForCausalLM',\n",
       " 'BioGptModel',\n",
       " 'BioGptPreTrainedModel',\n",
       " 'BioGptTokenizer',\n",
       " 'BitBackbone',\n",
       " 'BitConfig',\n",
       " 'BitForImageClassification',\n",
       " 'BitImageProcessor',\n",
       " 'BitModel',\n",
       " 'BitPreTrainedModel',\n",
       " 'BitsAndBytesConfig',\n",
       " 'BlenderbotConfig',\n",
       " 'BlenderbotForCausalLM',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotModel',\n",
       " 'BlenderbotPreTrainedModel',\n",
       " 'BlenderbotSmallConfig',\n",
       " 'BlenderbotSmallForCausalLM',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'BlenderbotSmallModel',\n",
       " 'BlenderbotSmallPreTrainedModel',\n",
       " 'BlenderbotSmallTokenizer',\n",
       " 'BlenderbotSmallTokenizerFast',\n",
       " 'BlenderbotTokenizer',\n",
       " 'BlenderbotTokenizerFast',\n",
       " 'Blip2Config',\n",
       " 'Blip2ForConditionalGeneration',\n",
       " 'Blip2Model',\n",
       " 'Blip2PreTrainedModel',\n",
       " 'Blip2Processor',\n",
       " 'Blip2QFormerConfig',\n",
       " 'Blip2QFormerModel',\n",
       " 'Blip2VisionConfig',\n",
       " 'Blip2VisionModel',\n",
       " 'BlipConfig',\n",
       " 'BlipForConditionalGeneration',\n",
       " 'BlipForImageTextRetrieval',\n",
       " 'BlipForQuestionAnswering',\n",
       " 'BlipImageProcessor',\n",
       " 'BlipModel',\n",
       " 'BlipPreTrainedModel',\n",
       " 'BlipProcessor',\n",
       " 'BlipTextConfig',\n",
       " 'BlipTextModel',\n",
       " 'BlipVisionConfig',\n",
       " 'BlipVisionModel',\n",
       " 'BloomConfig',\n",
       " 'BloomForCausalLM',\n",
       " 'BloomForQuestionAnswering',\n",
       " 'BloomForSequenceClassification',\n",
       " 'BloomForTokenClassification',\n",
       " 'BloomModel',\n",
       " 'BloomPreTrainedModel',\n",
       " 'BloomTokenizerFast',\n",
       " 'BridgeTowerConfig',\n",
       " 'BridgeTowerForContrastiveLearning',\n",
       " 'BridgeTowerForImageAndTextRetrieval',\n",
       " 'BridgeTowerForMaskedLM',\n",
       " 'BridgeTowerImageProcessor',\n",
       " 'BridgeTowerModel',\n",
       " 'BridgeTowerPreTrainedModel',\n",
       " 'BridgeTowerProcessor',\n",
       " 'BridgeTowerTextConfig',\n",
       " 'BridgeTowerVisionConfig',\n",
       " 'ByT5Tokenizer',\n",
       " 'CAMEMBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CAMEMBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CANINE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CANINE_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CHINESE_CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CHINESE_CLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLAP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLIPConfig',\n",
       " 'CLIPFeatureExtractor',\n",
       " 'CLIPImageProcessor',\n",
       " 'CLIPModel',\n",
       " 'CLIPPreTrainedModel',\n",
       " 'CLIPProcessor',\n",
       " 'CLIPSEG_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CLIPSEG_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLIPSegConfig',\n",
       " 'CLIPSegForImageSegmentation',\n",
       " 'CLIPSegModel',\n",
       " 'CLIPSegPreTrainedModel',\n",
       " 'CLIPSegProcessor',\n",
       " 'CLIPSegTextConfig',\n",
       " 'CLIPSegTextModel',\n",
       " 'CLIPSegVisionConfig',\n",
       " 'CLIPSegVisionModel',\n",
       " 'CLIPTextConfig',\n",
       " 'CLIPTextModel',\n",
       " 'CLIPTextModelWithProjection',\n",
       " 'CLIPTokenizer',\n",
       " 'CLIPTokenizerFast',\n",
       " 'CLIPVisionConfig',\n",
       " 'CLIPVisionModel',\n",
       " 'CLIPVisionModelWithProjection',\n",
       " 'CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CODEGEN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CODEGEN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONDITIONAL_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONDITIONAL_DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONFIG_MAPPING',\n",
       " 'CONFIG_NAME',\n",
       " 'CONVBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONVBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONVNEXTV2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONVNEXTV2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CONVNEXT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CONVNEXT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CTRLConfig',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CTRLLMHeadModel',\n",
       " 'CTRLModel',\n",
       " 'CTRLPreTrainedModel',\n",
       " 'CTRLTokenizer',\n",
       " 'CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CTRL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CVT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CVT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CamembertConfig',\n",
       " 'CamembertForCausalLM',\n",
       " 'CamembertForMaskedLM',\n",
       " 'CamembertForMultipleChoice',\n",
       " 'CamembertForQuestionAnswering',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CamembertForTokenClassification',\n",
       " 'CamembertModel',\n",
       " 'CamembertPreTrainedModel',\n",
       " 'CamembertTokenizer',\n",
       " 'CamembertTokenizerFast',\n",
       " 'CanineConfig',\n",
       " 'CanineForMultipleChoice',\n",
       " 'CanineForQuestionAnswering',\n",
       " 'CanineForSequenceClassification',\n",
       " 'CanineForTokenClassification',\n",
       " 'CanineLayer',\n",
       " 'CanineModel',\n",
       " 'CaninePreTrainedModel',\n",
       " 'CanineTokenizer',\n",
       " 'CharSpan',\n",
       " 'CharacterTokenizer',\n",
       " 'ChineseCLIPConfig',\n",
       " 'ChineseCLIPFeatureExtractor',\n",
       " 'ChineseCLIPImageProcessor',\n",
       " 'ChineseCLIPModel',\n",
       " 'ChineseCLIPPreTrainedModel',\n",
       " 'ChineseCLIPProcessor',\n",
       " 'ChineseCLIPTextConfig',\n",
       " 'ChineseCLIPTextModel',\n",
       " 'ChineseCLIPVisionConfig',\n",
       " 'ChineseCLIPVisionModel',\n",
       " 'ClapAudioConfig',\n",
       " 'ClapAudioModel',\n",
       " 'ClapAudioModelWithProjection',\n",
       " 'ClapConfig',\n",
       " 'ClapFeatureExtractor',\n",
       " 'ClapModel',\n",
       " 'ClapPreTrainedModel',\n",
       " 'ClapProcessor',\n",
       " 'ClapTextConfig',\n",
       " 'ClapTextModel',\n",
       " 'ClapTextModelWithProjection',\n",
       " 'CodeGenConfig',\n",
       " 'CodeGenForCausalLM',\n",
       " 'CodeGenModel',\n",
       " 'CodeGenPreTrainedModel',\n",
       " 'CodeGenTokenizer',\n",
       " 'CodeGenTokenizerFast',\n",
       " 'ConditionalDetrConfig',\n",
       " 'ConditionalDetrFeatureExtractor',\n",
       " 'ConditionalDetrForObjectDetection',\n",
       " 'ConditionalDetrForSegmentation',\n",
       " 'ConditionalDetrImageProcessor',\n",
       " 'ConditionalDetrModel',\n",
       " 'ConditionalDetrPreTrainedModel',\n",
       " 'ConstrainedBeamSearchScorer',\n",
       " 'Constraint',\n",
       " 'ConstraintListState',\n",
       " 'Conv1D',\n",
       " 'ConvBertConfig',\n",
       " 'ConvBertForMaskedLM',\n",
       " 'ConvBertForMultipleChoice',\n",
       " 'ConvBertForQuestionAnswering',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'ConvBertForTokenClassification',\n",
       " 'ConvBertLayer',\n",
       " 'ConvBertModel',\n",
       " 'ConvBertPreTrainedModel',\n",
       " 'ConvBertTokenizer',\n",
       " 'ConvBertTokenizerFast',\n",
       " 'ConvNextBackbone',\n",
       " 'ConvNextConfig',\n",
       " 'ConvNextFeatureExtractor',\n",
       " 'ConvNextForImageClassification',\n",
       " 'ConvNextImageProcessor',\n",
       " 'ConvNextModel',\n",
       " 'ConvNextPreTrainedModel',\n",
       " 'ConvNextV2Backbone',\n",
       " 'ConvNextV2Config',\n",
       " 'ConvNextV2ForImageClassification',\n",
       " 'ConvNextV2Model',\n",
       " 'ConvNextV2PreTrainedModel',\n",
       " 'Conversation',\n",
       " 'ConversationalPipeline',\n",
       " 'CpmTokenizer',\n",
       " 'CpmTokenizerFast',\n",
       " 'CsvPipelineDataFormat',\n",
       " 'CvtConfig',\n",
       " 'CvtForImageClassification',\n",
       " 'CvtModel',\n",
       " 'CvtPreTrainedModel',\n",
       " 'DATA2VEC_AUDIO_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DATA2VEC_TEXT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DATA2VEC_TEXT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DATA2VEC_VISION_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DATA2VEC_VISION_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEBERTA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEBERTA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEBERTA_V2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEBERTA_V2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DECISION_TRANSFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DECISION_TRANSFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEFORMABLE_DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEFORMABLE_DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DEIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DEIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DETA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DETA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DETR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DETR_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DINAT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DINAT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DISTILBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DISTILBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DONUT_SWIN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DONUT_SWIN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPRConfig',\n",
       " 'DPRContextEncoder',\n",
       " 'DPRContextEncoderTokenizer',\n",
       " 'DPRContextEncoderTokenizerFast',\n",
       " 'DPRPreTrainedModel',\n",
       " 'DPRPretrainedContextEncoder',\n",
       " 'DPRPretrainedQuestionEncoder',\n",
       " 'DPRPretrainedReader',\n",
       " 'DPRQuestionEncoder',\n",
       " 'DPRQuestionEncoderTokenizer',\n",
       " 'DPRQuestionEncoderTokenizerFast',\n",
       " 'DPRReader',\n",
       " 'DPRReaderOutput',\n",
       " 'DPRReaderTokenizer',\n",
       " 'DPRReaderTokenizerFast',\n",
       " 'DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPTConfig',\n",
       " 'DPTFeatureExtractor',\n",
       " 'DPTForDepthEstimation',\n",
       " 'DPTForSemanticSegmentation',\n",
       " 'DPTImageProcessor',\n",
       " 'DPTModel',\n",
       " 'DPTPreTrainedModel',\n",
       " 'DPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'Data2VecAudioConfig',\n",
       " 'Data2VecAudioForAudioFrameClassification',\n",
       " 'Data2VecAudioForCTC',\n",
       " 'Data2VecAudioForSequenceClassification',\n",
       " 'Data2VecAudioForXVector',\n",
       " 'Data2VecAudioModel',\n",
       " 'Data2VecAudioPreTrainedModel',\n",
       " 'Data2VecTextConfig',\n",
       " 'Data2VecTextForCausalLM',\n",
       " 'Data2VecTextForMaskedLM',\n",
       " 'Data2VecTextForMultipleChoice',\n",
       " 'Data2VecTextForQuestionAnswering',\n",
       " 'Data2VecTextForSequenceClassification',\n",
       " 'Data2VecTextForTokenClassification',\n",
       " 'Data2VecTextModel',\n",
       " 'Data2VecTextPreTrainedModel',\n",
       " 'Data2VecVisionConfig',\n",
       " 'Data2VecVisionForImageClassification',\n",
       " 'Data2VecVisionForSemanticSegmentation',\n",
       " 'Data2VecVisionModel',\n",
       " 'Data2VecVisionPreTrainedModel',\n",
       " 'DataCollator',\n",
       " 'DataCollatorForLanguageModeling',\n",
       " 'DataCollatorForPermutationLanguageModeling',\n",
       " 'DataCollatorForSOP',\n",
       " 'DataCollatorForSeq2Seq',\n",
       " 'DataCollatorForTokenClassification',\n",
       " 'DataCollatorForWholeWordMask',\n",
       " 'DataCollatorWithPadding',\n",
       " 'DataProcessor',\n",
       " 'DebertaConfig',\n",
       " 'DebertaForMaskedLM',\n",
       " 'DebertaForQuestionAnswering',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaForTokenClassification',\n",
       " 'DebertaModel',\n",
       " 'DebertaPreTrainedModel',\n",
       " 'DebertaTokenizer',\n",
       " 'DebertaTokenizerFast',\n",
       " 'DebertaV2Config',\n",
       " 'DebertaV2ForMaskedLM',\n",
       " 'DebertaV2ForMultipleChoice',\n",
       " 'DebertaV2ForQuestionAnswering',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DebertaV2ForTokenClassification',\n",
       " 'DebertaV2Model',\n",
       " 'DebertaV2PreTrainedModel',\n",
       " 'DebertaV2Tokenizer',\n",
       " 'DebertaV2TokenizerFast',\n",
       " 'DecisionTransformerConfig',\n",
       " 'DecisionTransformerGPT2Model',\n",
       " 'DecisionTransformerGPT2PreTrainedModel',\n",
       " 'DecisionTransformerModel',\n",
       " 'DecisionTransformerPreTrainedModel',\n",
       " 'DefaultDataCollator',\n",
       " 'DefaultFlowCallback',\n",
       " 'DeformableDetrConfig',\n",
       " 'DeformableDetrFeatureExtractor',\n",
       " 'DeformableDetrForObjectDetection',\n",
       " 'DeformableDetrImageProcessor',\n",
       " 'DeformableDetrModel',\n",
       " 'DeformableDetrPreTrainedModel',\n",
       " 'DeiTConfig',\n",
       " 'DeiTFeatureExtractor',\n",
       " 'DeiTForImageClassification',\n",
       " 'DeiTForImageClassificationWithTeacher',\n",
       " 'DeiTForMaskedImageModeling',\n",
       " 'DeiTImageProcessor',\n",
       " 'DeiTModel',\n",
       " 'DeiTPreTrainedModel',\n",
       " 'DepthEstimationPipeline',\n",
       " 'DetaConfig',\n",
       " 'DetaForObjectDetection',\n",
       " 'DetaImageProcessor',\n",
       " 'DetaModel',\n",
       " 'DetaPreTrainedModel',\n",
       " 'DetrConfig',\n",
       " 'DetrFeatureExtractor',\n",
       " 'DetrForObjectDetection',\n",
       " 'DetrForSegmentation',\n",
       " 'DetrImageProcessor',\n",
       " 'DetrModel',\n",
       " 'DetrPreTrainedModel',\n",
       " 'DinatBackbone',\n",
       " 'DinatConfig',\n",
       " 'DinatForImageClassification',\n",
       " 'DinatModel',\n",
       " 'DinatPreTrainedModel',\n",
       " 'DisjunctiveConstraint',\n",
       " 'DistilBertConfig',\n",
       " 'DistilBertForMaskedLM',\n",
       " 'DistilBertForMultipleChoice',\n",
       " 'DistilBertForQuestionAnswering',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'DistilBertForTokenClassification',\n",
       " 'DistilBertModel',\n",
       " 'DistilBertPreTrainedModel',\n",
       " 'DistilBertTokenizer',\n",
       " 'DistilBertTokenizerFast',\n",
       " 'DocumentQuestionAnsweringPipeline',\n",
       " 'DonutFeatureExtractor',\n",
       " 'DonutImageProcessor',\n",
       " 'DonutProcessor',\n",
       " 'DonutSwinConfig',\n",
       " 'DonutSwinModel',\n",
       " 'DonutSwinPreTrainedModel',\n",
       " 'DummyObject',\n",
       " 'EFFICIENTFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'EFFICIENTFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'EFFICIENTNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'EFFICIENTNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ELECTRA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ELECTRA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ERNIE_M_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ERNIE_M_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ERNIE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ERNIE_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ESM_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'ESM_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'EarlyStoppingCallback',\n",
       " 'EfficientFormerConfig',\n",
       " 'EfficientFormerForImageClassification',\n",
       " 'EfficientFormerForImageClassificationWithTeacher',\n",
       " 'EfficientFormerImageProcessor',\n",
       " 'EfficientFormerModel',\n",
       " 'EfficientFormerPreTrainedModel',\n",
       " 'EfficientNetConfig',\n",
       " 'EfficientNetForImageClassification',\n",
       " 'EfficientNetImageProcessor',\n",
       " 'EfficientNetModel',\n",
       " 'EfficientNetPreTrainedModel',\n",
       " 'ElectraConfig',\n",
       " 'ElectraForCausalLM',\n",
       " 'ElectraForMaskedLM',\n",
       " 'ElectraForMultipleChoice',\n",
       " 'ElectraForPreTraining',\n",
       " 'ElectraForQuestionAnswering',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'ElectraForTokenClassification',\n",
       " 'ElectraModel',\n",
       " 'ElectraPreTrainedModel',\n",
       " 'ElectraTokenizer',\n",
       " 'ElectraTokenizerFast',\n",
       " 'EncoderDecoderConfig',\n",
       " 'EncoderDecoderModel',\n",
       " 'ErnieConfig',\n",
       " 'ErnieForCausalLM',\n",
       " 'ErnieForMaskedLM',\n",
       " 'ErnieForMultipleChoice',\n",
       " 'ErnieForNextSentencePrediction',\n",
       " 'ErnieForPreTraining',\n",
       " 'ErnieForQuestionAnswering',\n",
       " 'ErnieForSequenceClassification',\n",
       " 'ErnieForTokenClassification',\n",
       " 'ErnieMConfig',\n",
       " 'ErnieMForInformationExtraction',\n",
       " 'ErnieMForMultipleChoice',\n",
       " 'ErnieMForQuestionAnswering',\n",
       " 'ErnieMForSequenceClassification',\n",
       " 'ErnieMForTokenClassification',\n",
       " 'ErnieMModel',\n",
       " 'ErnieMPreTrainedModel',\n",
       " 'ErnieMTokenizer',\n",
       " 'ErnieModel',\n",
       " 'ErniePreTrainedModel',\n",
       " 'EsmConfig',\n",
       " 'EsmFoldPreTrainedModel',\n",
       " 'EsmForMaskedLM',\n",
       " 'EsmForProteinFolding',\n",
       " 'EsmForSequenceClassification',\n",
       " 'EsmForTokenClassification',\n",
       " 'EsmModel',\n",
       " 'EsmPreTrainedModel',\n",
       " 'EsmTokenizer',\n",
       " 'EvalPrediction',\n",
       " 'FEATURE_EXTRACTOR_MAPPING',\n",
       " 'FLAUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FLAUBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FLAVA_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FLAVA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FLAX_MODEL_FOR_CAUSAL_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_IMAGE_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_MASKED_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_MULTIPLE_CHOICE_MAPPING',\n",
       " 'FLAX_MODEL_FOR_NEXT_SENTENCE_PREDICTION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_PRETRAINING_MAPPING',\n",
       " 'FLAX_MODEL_FOR_QUESTION_ANSWERING_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SEQUENCE_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SEQ_TO_SEQ_CAUSAL_LM_MAPPING',\n",
       " 'FLAX_MODEL_FOR_SPEECH_SEQ_2_SEQ_MAPPING',\n",
       " 'FLAX_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING',\n",
       " 'FLAX_MODEL_FOR_VISION_2_SEQ_MAPPING',\n",
       " 'FLAX_MODEL_MAPPING',\n",
       " 'FLAX_XLM_ROBERTA_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FNET_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FNET_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FNetConfig',\n",
       " 'FNetForMaskedLM',\n",
       " 'FNetForMultipleChoice',\n",
       " 'FNetForNextSentencePrediction',\n",
       " 'FNetForPreTraining',\n",
       " 'FNetForQuestionAnswering',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FNetForTokenClassification',\n",
       " 'FNetLayer',\n",
       " 'FNetModel',\n",
       " 'FNetPreTrainedModel',\n",
       " 'FNetTokenizer',\n",
       " 'FNetTokenizerFast',\n",
       " 'FSMTConfig',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'FSMTModel',\n",
       " 'FSMTTokenizer',\n",
       " 'FSMT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FUNNEL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FUNNEL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'FeatureExtractionMixin',\n",
       " 'FeatureExtractionPipeline',\n",
       " 'FillMaskPipeline',\n",
       " 'FlaubertConfig',\n",
       " 'FlaubertForMultipleChoice',\n",
       " 'FlaubertForQuestionAnswering',\n",
       " 'FlaubertForQuestionAnsweringSimple',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FlaubertForTokenClassification',\n",
       " 'FlaubertModel',\n",
       " 'FlaubertPreTrainedModel',\n",
       " 'FlaubertTokenizer',\n",
       " 'FlaubertWithLMHeadModel',\n",
       " 'FlavaConfig',\n",
       " 'FlavaFeatureExtractor',\n",
       " 'FlavaForPreTraining',\n",
       " 'FlavaImageCodebook',\n",
       " 'FlavaImageCodebookConfig',\n",
       " 'FlavaImageConfig',\n",
       " 'FlavaImageModel',\n",
       " 'FlavaImageProcessor',\n",
       " 'FlavaModel',\n",
       " 'FlavaMultimodalConfig',\n",
       " 'FlavaMultimodalModel',\n",
       " 'FlavaPreTrainedModel',\n",
       " 'FlavaProcessor',\n",
       " 'FlavaTextConfig',\n",
       " 'FlavaTextModel',\n",
       " 'FlaxAlbertForMaskedLM',\n",
       " 'FlaxAlbertForMultipleChoice',\n",
       " 'FlaxAlbertForPreTraining',\n",
       " 'FlaxAlbertForQuestionAnswering',\n",
       " 'FlaxAlbertForSequenceClassification',\n",
       " 'FlaxAlbertForTokenClassification',\n",
       " 'FlaxAlbertModel',\n",
       " 'FlaxAlbertPreTrainedModel',\n",
       " 'FlaxAutoModel',\n",
       " 'FlaxAutoModelForCausalLM',\n",
       " 'FlaxAutoModelForImageClassification',\n",
       " 'FlaxAutoModelForMaskedLM',\n",
       " 'FlaxAutoModelForMultipleChoice',\n",
       " 'FlaxAutoModelForNextSentencePrediction',\n",
       " 'FlaxAutoModelForPreTraining',\n",
       " 'FlaxAutoModelForQuestionAnswering',\n",
       " 'FlaxAutoModelForSeq2SeqLM',\n",
       " 'FlaxAutoModelForSequenceClassification',\n",
       " 'FlaxAutoModelForSpeechSeq2Seq',\n",
       " 'FlaxAutoModelForTokenClassification',\n",
       " 'FlaxAutoModelForVision2Seq',\n",
       " 'FlaxBartDecoderPreTrainedModel',\n",
       " 'FlaxBartForCausalLM',\n",
       " 'FlaxBartForConditionalGeneration',\n",
       " 'FlaxBartForQuestionAnswering',\n",
       " 'FlaxBartForSequenceClassification',\n",
       " 'FlaxBartModel',\n",
       " 'FlaxBartPreTrainedModel',\n",
       " 'FlaxBeitForImageClassification',\n",
       " 'FlaxBeitForMaskedImageModeling',\n",
       " 'FlaxBeitModel',\n",
       " 'FlaxBeitPreTrainedModel',\n",
       " 'FlaxBertForCausalLM',\n",
       " 'FlaxBertForMaskedLM',\n",
       " 'FlaxBertForMultipleChoice',\n",
       " 'FlaxBertForNextSentencePrediction',\n",
       " 'FlaxBertForPreTraining',\n",
       " 'FlaxBertForQuestionAnswering',\n",
       " 'FlaxBertForSequenceClassification',\n",
       " 'FlaxBertForTokenClassification',\n",
       " 'FlaxBertModel',\n",
       " 'FlaxBertPreTrainedModel',\n",
       " 'FlaxBigBirdForCausalLM',\n",
       " 'FlaxBigBirdForMaskedLM',\n",
       " 'FlaxBigBirdForMultipleChoice',\n",
       " 'FlaxBigBirdForPreTraining',\n",
       " 'FlaxBigBirdForQuestionAnswering',\n",
       " 'FlaxBigBirdForSequenceClassification',\n",
       " 'FlaxBigBirdForTokenClassification',\n",
       " 'FlaxBigBirdModel',\n",
       " 'FlaxBigBirdPreTrainedModel',\n",
       " 'FlaxBlenderbotForConditionalGeneration',\n",
       " 'FlaxBlenderbotModel',\n",
       " 'FlaxBlenderbotPreTrainedModel',\n",
       " 'FlaxBlenderbotSmallForConditionalGeneration',\n",
       " 'FlaxBlenderbotSmallModel',\n",
       " 'FlaxBlenderbotSmallPreTrainedModel',\n",
       " 'FlaxCLIPModel',\n",
       " 'FlaxCLIPPreTrainedModel',\n",
       " 'FlaxCLIPTextModel',\n",
       " 'FlaxCLIPTextPreTrainedModel',\n",
       " 'FlaxCLIPVisionModel',\n",
       " 'FlaxCLIPVisionPreTrainedModel',\n",
       " 'FlaxDistilBertForMaskedLM',\n",
       " 'FlaxDistilBertForMultipleChoice',\n",
       " 'FlaxDistilBertForQuestionAnswering',\n",
       " 'FlaxDistilBertForSequenceClassification',\n",
       " 'FlaxDistilBertForTokenClassification',\n",
       " 'FlaxDistilBertModel',\n",
       " 'FlaxDistilBertPreTrainedModel',\n",
       " 'FlaxElectraForCausalLM',\n",
       " 'FlaxElectraForMaskedLM',\n",
       " 'FlaxElectraForMultipleChoice',\n",
       " 'FlaxElectraForPreTraining',\n",
       " 'FlaxElectraForQuestionAnswering',\n",
       " 'FlaxElectraForSequenceClassification',\n",
       " 'FlaxElectraForTokenClassification',\n",
       " 'FlaxElectraModel',\n",
       " 'FlaxElectraPreTrainedModel',\n",
       " 'FlaxEncoderDecoderModel',\n",
       " 'FlaxForcedBOSTokenLogitsProcessor',\n",
       " 'FlaxForcedEOSTokenLogitsProcessor',\n",
       " 'FlaxGPT2LMHeadModel',\n",
       " 'FlaxGPT2Model',\n",
       " 'FlaxGPT2PreTrainedModel',\n",
       " 'FlaxGPTJForCausalLM',\n",
       " 'FlaxGPTJModel',\n",
       " 'FlaxGPTJPreTrainedModel',\n",
       " 'FlaxGPTNeoForCausalLM',\n",
       " 'FlaxGPTNeoModel',\n",
       " 'FlaxGPTNeoPreTrainedModel',\n",
       " 'FlaxGenerationMixin',\n",
       " 'FlaxLogitsProcessor',\n",
       " 'FlaxLogitsProcessorList',\n",
       " 'FlaxLogitsWarper',\n",
       " 'FlaxLongT5ForConditionalGeneration',\n",
       " 'FlaxLongT5Model',\n",
       " 'FlaxLongT5PreTrainedModel',\n",
       " 'FlaxMBartForConditionalGeneration',\n",
       " 'FlaxMBartForQuestionAnswering',\n",
       " 'FlaxMBartForSequenceClassification',\n",
       " 'FlaxMBartModel',\n",
       " 'FlaxMBartPreTrainedModel',\n",
       " 'FlaxMT5EncoderModel',\n",
       " 'FlaxMT5ForConditionalGeneration',\n",
       " 'FlaxMT5Model',\n",
       " 'FlaxMarianMTModel',\n",
       " 'FlaxMarianModel',\n",
       " 'FlaxMarianPreTrainedModel',\n",
       " 'FlaxMinLengthLogitsProcessor',\n",
       " 'FlaxOPTForCausalLM',\n",
       " 'FlaxOPTModel',\n",
       " 'FlaxOPTPreTrainedModel',\n",
       " 'FlaxPegasusForConditionalGeneration',\n",
       " 'FlaxPegasusModel',\n",
       " 'FlaxPegasusPreTrainedModel',\n",
       " 'FlaxPreTrainedModel',\n",
       " 'FlaxRoFormerForMaskedLM',\n",
       " 'FlaxRoFormerForMultipleChoice',\n",
       " 'FlaxRoFormerForQuestionAnswering',\n",
       " 'FlaxRoFormerForSequenceClassification',\n",
       " 'FlaxRoFormerForTokenClassification',\n",
       " 'FlaxRoFormerModel',\n",
       " 'FlaxRoFormerPreTrainedModel',\n",
       " 'FlaxRobertaForCausalLM',\n",
       " 'FlaxRobertaForMaskedLM',\n",
       " 'FlaxRobertaForMultipleChoice',\n",
       " 'FlaxRobertaForQuestionAnswering',\n",
       " 'FlaxRobertaForSequenceClassification',\n",
       " 'FlaxRobertaForTokenClassification',\n",
       " 'FlaxRobertaModel',\n",
       " 'FlaxRobertaPreLayerNormForCausalLM',\n",
       " 'FlaxRobertaPreLayerNormForMaskedLM',\n",
       " 'FlaxRobertaPreLayerNormForMultipleChoice',\n",
       " 'FlaxRobertaPreLayerNormForQuestionAnswering',\n",
       " 'FlaxRobertaPreLayerNormForSequenceClassification',\n",
       " 'FlaxRobertaPreLayerNormForTokenClassification',\n",
       " 'FlaxRobertaPreLayerNormModel',\n",
       " 'FlaxRobertaPreLayerNormPreTrainedModel',\n",
       " 'FlaxRobertaPreTrainedModel',\n",
       " 'FlaxSpeechEncoderDecoderModel',\n",
       " 'FlaxT5EncoderModel',\n",
       " 'FlaxT5ForConditionalGeneration',\n",
       " 'FlaxT5Model',\n",
       " 'FlaxT5PreTrainedModel',\n",
       " 'FlaxTemperatureLogitsWarper',\n",
       " 'FlaxTopKLogitsWarper',\n",
       " 'FlaxTopPLogitsWarper',\n",
       " 'FlaxViTForImageClassification',\n",
       " 'FlaxViTModel',\n",
       " 'FlaxViTPreTrainedModel',\n",
       " 'FlaxVisionEncoderDecoderModel',\n",
       " 'FlaxVisionTextDualEncoderModel',\n",
       " 'FlaxWav2Vec2ForCTC',\n",
       " 'FlaxWav2Vec2ForPreTraining',\n",
       " 'FlaxWav2Vec2Model',\n",
       " 'FlaxWav2Vec2PreTrainedModel',\n",
       " 'FlaxWhisperForConditionalGeneration',\n",
       " 'FlaxWhisperModel',\n",
       " 'FlaxWhisperPreTrainedModel',\n",
       " 'FlaxXGLMForCausalLM',\n",
       " 'FlaxXGLMModel',\n",
       " 'FlaxXGLMPreTrainedModel',\n",
       " 'FlaxXLMRobertaForCausalLM',\n",
       " 'FlaxXLMRobertaForMaskedLM',\n",
       " 'FlaxXLMRobertaForMultipleChoice',\n",
       " 'FlaxXLMRobertaForQuestionAnswering',\n",
       " 'FlaxXLMRobertaForSequenceClassification',\n",
       " 'FlaxXLMRobertaForTokenClassification',\n",
       " 'FlaxXLMRobertaModel',\n",
       " 'FlaxXLMRobertaPreTrainedModel',\n",
       " 'ForcedBOSTokenLogitsProcessor',\n",
       " 'ForcedEOSTokenLogitsProcessor',\n",
       " 'FunnelBaseModel',\n",
       " 'FunnelConfig',\n",
       " 'FunnelForMaskedLM',\n",
       " 'FunnelForMultipleChoice',\n",
       " 'FunnelForPreTraining',\n",
       " 'FunnelForQuestionAnswering',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'FunnelForTokenClassification',\n",
       " 'FunnelModel',\n",
       " 'FunnelPreTrainedModel',\n",
       " 'FunnelTokenizer',\n",
       " 'FunnelTokenizerFast',\n",
       " 'GIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GLPNConfig',\n",
       " 'GLPNFeatureExtractor',\n",
       " 'GLPNForDepthEstimation',\n",
       " 'GLPNImageProcessor',\n",
       " 'GLPNModel',\n",
       " 'GLPNPreTrainedModel',\n",
       " 'GLPN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GLPN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPT2Config',\n",
       " 'GPT2DoubleHeadsModel',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPT2ForTokenClassification',\n",
       " 'GPT2LMHeadModel',\n",
       " 'GPT2Model',\n",
       " 'GPT2PreTrainedModel',\n",
       " 'GPT2Tokenizer',\n",
       " 'GPT2TokenizerFast',\n",
       " 'GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTJConfig',\n",
       " 'GPTJForCausalLM',\n",
       " 'GPTJForQuestionAnswering',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTJModel',\n",
       " 'GPTJPreTrainedModel',\n",
       " 'GPTJ_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPTJ_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTNeoConfig',\n",
       " 'GPTNeoForCausalLM',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'GPTNeoModel',\n",
       " 'GPTNeoPreTrainedModel',\n",
       " 'GPTNeoXConfig',\n",
       " 'GPTNeoXForCausalLM',\n",
       " 'GPTNeoXJapaneseConfig',\n",
       " 'GPTNeoXJapaneseForCausalLM',\n",
       " 'GPTNeoXJapaneseLayer',\n",
       " 'GPTNeoXJapaneseModel',\n",
       " 'GPTNeoXJapanesePreTrainedModel',\n",
       " 'GPTNeoXJapaneseTokenizer',\n",
       " 'GPTNeoXLayer',\n",
       " 'GPTNeoXModel',\n",
       " 'GPTNeoXPreTrainedModel',\n",
       " 'GPTNeoXTokenizerFast',\n",
       " 'GPTSAN_JAPANESE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPTSAN_JAPANESE_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTSanJapaneseConfig',\n",
       " 'GPTSanJapaneseForConditionalGeneration',\n",
       " 'GPTSanJapaneseModel',\n",
       " 'GPTSanJapanesePreTrainedModel',\n",
       " 'GPTSanJapaneseTokenizer',\n",
       " 'GPTSw3Tokenizer',\n",
       " 'GPT_NEOX_JAPANESE_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT_NEOX_JAPANESE_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPT_NEOX_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT_NEOX_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPT_NEO_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT_NEO_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GRAPHORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GRAPHORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GROUPVIT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GROUPVIT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GenerationConfig',\n",
       " 'GenerationMixin',\n",
       " 'GitConfig',\n",
       " 'GitForCausalLM',\n",
       " 'GitModel',\n",
       " 'GitPreTrainedModel',\n",
       " 'GitProcessor',\n",
       " 'GitVisionConfig',\n",
       " 'GitVisionModel',\n",
       " 'GlueDataTrainingArguments',\n",
       " 'GlueDataset',\n",
       " 'GradientAccumulator',\n",
       " 'GraphormerConfig',\n",
       " 'GraphormerForGraphClassification',\n",
       " 'GraphormerModel',\n",
       " 'GraphormerPreTrainedModel',\n",
       " 'GroupViTConfig',\n",
       " 'GroupViTModel',\n",
       " 'GroupViTPreTrainedModel',\n",
       " 'GroupViTTextConfig',\n",
       " 'GroupViTTextModel',\n",
       " 'GroupViTVisionConfig',\n",
       " 'GroupViTVisionModel',\n",
       " 'HUBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'HUBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'HammingDiversityLogitsProcessor',\n",
       " 'HerbertTokenizer',\n",
       " 'HerbertTokenizerFast',\n",
       " 'HfArgumentParser',\n",
       " 'HubertConfig',\n",
       " 'HubertForCTC',\n",
       " 'HubertForSequenceClassification',\n",
       " 'HubertModel',\n",
       " 'HubertPreTrainedModel',\n",
       " 'IBERT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'IBERT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'IBertConfig',\n",
       " 'IBertForMaskedLM',\n",
       " 'IBertForMultipleChoice',\n",
       " 'IBertForQuestionAnswering',\n",
       " 'IBertForSequenceClassification',\n",
       " 'IBertForTokenClassification',\n",
       " 'IBertModel',\n",
       " 'IBertPreTrainedModel',\n",
       " 'IMAGEGPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'IMAGEGPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'IMAGE_PROCESSOR_MAPPING',\n",
       " 'INFORMER_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'INFORMER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'ImageClassificationPipeline',\n",
       " 'ImageFeatureExtractionMixin',\n",
       " 'ImageGPTConfig',\n",
       " 'ImageGPTFeatureExtractor',\n",
       " 'ImageGPTForCausalImageModeling',\n",
       " 'ImageGPTForImageClassification',\n",
       " 'ImageGPTImageProcessor',\n",
       " 'ImageGPTModel',\n",
       " 'ImageGPTPreTrainedModel',\n",
       " 'ImageProcessingMixin',\n",
       " 'ImageSegmentationPipeline',\n",
       " 'ImageToTextPipeline',\n",
       " 'InfNanRemoveLogitsProcessor',\n",
       " 'InformerConfig',\n",
       " 'InformerForPrediction',\n",
       " ...]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import transformers\n",
    "dir(transformers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of config_names: 211\n",
      "Number of model_names: 335\n",
      "Number of pretrainedmdoel_names: 260\n"
     ]
    }
   ],
   "source": [
    "config_names = [name for name in dir(transformers) if name.endswith('Config')]\n",
    "model_names = [name for name in dir(transformers) if name.endswith('Model') and not name.endswith('PreTrainedModel') and not name.endswith('PretrainedModel')]\n",
    "pretrainedmdoel_names = [name for name in dir(transformers) if name.endswith('PreTrainedModel') or name.endswith('PretrainedModel')]\n",
    "\n",
    "print(f'Number of config_names: {len(config_names)}')\n",
    "print(f'Number of model_names: {len(model_names)}')\n",
    "print(f'Number of pretrainedmdoel_names: {len(pretrainedmdoel_names)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ASTConfig', 'AlbertConfig', 'AlignConfig', 'AlignTextConfig', 'AlignVisionConfig', 'AltCLIPConfig', 'AltCLIPTextConfig', 'AltCLIPVisionConfig', 'AutoConfig', 'BartConfig', 'BeitConfig', 'BertConfig', 'BertGenerationConfig', 'BigBirdConfig', 'BigBirdPegasusConfig', 'BioGptConfig', 'BitConfig', 'BitsAndBytesConfig', 'BlenderbotConfig', 'BlenderbotSmallConfig', 'Blip2Config', 'Blip2QFormerConfig', 'Blip2VisionConfig', 'BlipConfig', 'BlipTextConfig', 'BlipVisionConfig', 'BloomConfig', 'BridgeTowerConfig', 'BridgeTowerTextConfig', 'BridgeTowerVisionConfig', 'CLIPConfig', 'CLIPSegConfig', 'CLIPSegTextConfig', 'CLIPSegVisionConfig', 'CLIPTextConfig', 'CLIPVisionConfig', 'CTRLConfig', 'CamembertConfig', 'CanineConfig', 'ChineseCLIPConfig', 'ChineseCLIPTextConfig', 'ChineseCLIPVisionConfig', 'ClapAudioConfig', 'ClapConfig', 'ClapTextConfig', 'CodeGenConfig', 'ConditionalDetrConfig', 'ConvBertConfig', 'ConvNextConfig', 'ConvNextV2Config', 'CvtConfig', 'DPRConfig', 'DPTConfig', 'Data2VecAudioConfig', 'Data2VecTextConfig', 'Data2VecVisionConfig', 'DebertaConfig', 'DebertaV2Config', 'DecisionTransformerConfig', 'DeformableDetrConfig', 'DeiTConfig', 'DetaConfig', 'DetrConfig', 'DinatConfig', 'DistilBertConfig', 'DonutSwinConfig', 'EfficientFormerConfig', 'EfficientNetConfig', 'ElectraConfig', 'EncoderDecoderConfig', 'ErnieConfig', 'ErnieMConfig', 'EsmConfig', 'FNetConfig', 'FSMTConfig', 'FlaubertConfig', 'FlavaConfig', 'FlavaImageCodebookConfig', 'FlavaImageConfig', 'FlavaMultimodalConfig', 'FlavaTextConfig', 'FunnelConfig', 'GLPNConfig', 'GPT2Config', 'GPTJConfig', 'GPTNeoConfig', 'GPTNeoXConfig', 'GPTNeoXJapaneseConfig', 'GPTSanJapaneseConfig', 'GenerationConfig', 'GitConfig', 'GitVisionConfig', 'GraphormerConfig', 'GroupViTConfig', 'GroupViTTextConfig', 'GroupViTVisionConfig', 'HubertConfig', 'IBertConfig', 'ImageGPTConfig', 'InformerConfig', 'JukeboxConfig', 'JukeboxPriorConfig', 'JukeboxVQVAEConfig', 'LEDConfig', 'LayoutLMConfig', 'LayoutLMv2Config', 'LayoutLMv3Config', 'LevitConfig', 'LiltConfig', 'LongT5Config', 'LongformerConfig', 'LukeConfig', 'LxmertConfig', 'M2M100Config', 'MBartConfig', 'MCTCTConfig', 'MMBTConfig', 'MPNetConfig', 'MT5Config', 'MarianConfig', 'MarkupLMConfig', 'Mask2FormerConfig', 'MaskFormerConfig', 'MaskFormerSwinConfig', 'MegatronBertConfig', 'MgpstrConfig', 'MobileBertConfig', 'MobileNetV1Config', 'MobileNetV2Config', 'MobileViTConfig', 'MvpConfig', 'NatConfig', 'NezhaConfig', 'NystromformerConfig', 'OPTConfig', 'OneFormerConfig', 'OpenAIGPTConfig', 'OwlViTConfig', 'OwlViTTextConfig', 'OwlViTVisionConfig', 'PLBartConfig', 'PegasusConfig', 'PegasusXConfig', 'PerceiverConfig', 'PoolFormerConfig', 'PretrainedConfig', 'ProphetNetConfig', 'QDQBertConfig', 'RagConfig', 'RealmConfig', 'ReformerConfig', 'RegNetConfig', 'RemBertConfig', 'ResNetConfig', 'RetriBertConfig', 'RoCBertConfig', 'RoFormerConfig', 'RobertaConfig', 'RobertaPreLayerNormConfig', 'SEWConfig', 'SEWDConfig', 'SegformerConfig', 'Speech2Text2Config', 'Speech2TextConfig', 'SpeechEncoderDecoderConfig', 'SpeechT5Config', 'SpeechT5HifiGanConfig', 'SplinterConfig', 'SqueezeBertConfig', 'Swin2SRConfig', 'SwinConfig', 'Swinv2Config', 'SwitchTransformersConfig', 'T5Config', 'TableTransformerConfig', 'TapasConfig', 'TimeSeriesTransformerConfig', 'TimesformerConfig', 'TrOCRConfig', 'TrajectoryTransformerConfig', 'TransfoXLConfig', 'TvltConfig', 'UniSpeechConfig', 'UniSpeechSatConfig', 'UperNetConfig', 'VanConfig', 'ViTConfig', 'ViTHybridConfig', 'ViTMAEConfig', 'ViTMSNConfig', 'VideoMAEConfig', 'ViltConfig', 'VisionEncoderDecoderConfig', 'VisionTextDualEncoderConfig', 'VisualBertConfig', 'Wav2Vec2Config', 'Wav2Vec2ConformerConfig', 'WavLMConfig', 'WhisperConfig', 'XCLIPConfig', 'XCLIPTextConfig', 'XCLIPVisionConfig', 'XGLMConfig', 'XLMConfig', 'XLMProphetNetConfig', 'XLMRobertaConfig', 'XLMRobertaXLConfig', 'XLNetConfig', 'XmodConfig', 'YolosConfig', 'YosoConfig']\n",
      "['ASTModel', 'AlbertModel', 'AlignModel', 'AlignTextModel', 'AlignVisionModel', 'AltCLIPModel', 'AltCLIPTextModel', 'AltCLIPVisionModel', 'AutoModel', 'BartModel', 'BeitModel', 'BertLMHeadModel', 'BertModel', 'BigBirdModel', 'BigBirdPegasusModel', 'BioGptModel', 'BitModel', 'BlenderbotModel', 'BlenderbotSmallModel', 'Blip2Model', 'Blip2QFormerModel', 'Blip2VisionModel', 'BlipModel', 'BlipTextModel', 'BlipVisionModel', 'BloomModel', 'BridgeTowerModel', 'CLIPModel', 'CLIPSegModel', 'CLIPSegTextModel', 'CLIPSegVisionModel', 'CLIPTextModel', 'CLIPVisionModel', 'CTRLLMHeadModel', 'CTRLModel', 'CamembertModel', 'CanineModel', 'ChineseCLIPModel', 'ChineseCLIPTextModel', 'ChineseCLIPVisionModel', 'ClapAudioModel', 'ClapModel', 'ClapTextModel', 'CodeGenModel', 'ConditionalDetrModel', 'ConvBertModel', 'ConvNextModel', 'ConvNextV2Model', 'CvtModel', 'DPTModel', 'Data2VecAudioModel', 'Data2VecTextModel', 'Data2VecVisionModel', 'DebertaModel', 'DebertaV2Model', 'DecisionTransformerGPT2Model', 'DecisionTransformerModel', 'DeformableDetrModel', 'DeiTModel', 'DetaModel', 'DetrModel', 'DinatModel', 'DistilBertModel', 'DonutSwinModel', 'EfficientFormerModel', 'EfficientNetModel', 'ElectraModel', 'EncoderDecoderModel', 'ErnieMModel', 'ErnieModel', 'EsmModel', 'FNetModel', 'FSMTModel', 'FlaubertModel', 'FlaubertWithLMHeadModel', 'FlavaImageModel', 'FlavaModel', 'FlavaMultimodalModel', 'FlavaTextModel', 'FlaxAlbertModel', 'FlaxAutoModel', 'FlaxBartModel', 'FlaxBeitModel', 'FlaxBertModel', 'FlaxBigBirdModel', 'FlaxBlenderbotModel', 'FlaxBlenderbotSmallModel', 'FlaxCLIPModel', 'FlaxCLIPTextModel', 'FlaxCLIPVisionModel', 'FlaxDistilBertModel', 'FlaxElectraModel', 'FlaxEncoderDecoderModel', 'FlaxGPT2LMHeadModel', 'FlaxGPT2Model', 'FlaxGPTJModel', 'FlaxGPTNeoModel', 'FlaxLongT5Model', 'FlaxMBartModel', 'FlaxMT5EncoderModel', 'FlaxMT5Model', 'FlaxMarianMTModel', 'FlaxMarianModel', 'FlaxOPTModel', 'FlaxPegasusModel', 'FlaxRoFormerModel', 'FlaxRobertaModel', 'FlaxRobertaPreLayerNormModel', 'FlaxSpeechEncoderDecoderModel', 'FlaxT5EncoderModel', 'FlaxT5Model', 'FlaxViTModel', 'FlaxVisionEncoderDecoderModel', 'FlaxVisionTextDualEncoderModel', 'FlaxWav2Vec2Model', 'FlaxWhisperModel', 'FlaxXGLMModel', 'FlaxXLMRobertaModel', 'FunnelBaseModel', 'FunnelModel', 'GLPNModel', 'GPT2DoubleHeadsModel', 'GPT2LMHeadModel', 'GPT2Model', 'GPTJModel', 'GPTNeoModel', 'GPTNeoXJapaneseModel', 'GPTNeoXModel', 'GPTSanJapaneseModel', 'GitModel', 'GitVisionModel', 'GraphormerModel', 'GroupViTModel', 'GroupViTTextModel', 'GroupViTVisionModel', 'HubertModel', 'IBertModel', 'ImageGPTModel', 'InformerModel', 'JukeboxModel', 'LEDModel', 'LayoutLMModel', 'LayoutLMv2Model', 'LayoutLMv3Model', 'LevitModel', 'LiltModel', 'LongT5EncoderModel', 'LongT5Model', 'LongformerModel', 'LukeModel', 'LxmertModel', 'M2M100Model', 'MBartModel', 'MCTCTModel', 'MMBTModel', 'MPNetModel', 'MT5EncoderModel', 'MT5Model', 'MarianMTModel', 'MarianModel', 'MarkupLMModel', 'Mask2FormerModel', 'MaskFormerModel', 'MegatronBertModel', 'MgpstrModel', 'MobileBertModel', 'MobileNetV1Model', 'MobileNetV2Model', 'MobileViTModel', 'MvpModel', 'NatModel', 'NezhaModel', 'NystromformerModel', 'OPTModel', 'OneFormerModel', 'OpenAIGPTDoubleHeadsModel', 'OpenAIGPTLMHeadModel', 'OpenAIGPTModel', 'OwlViTModel', 'OwlViTTextModel', 'OwlViTVisionModel', 'PLBartModel', 'PegasusModel', 'PegasusXModel', 'PerceiverModel', 'PoolFormerModel', 'PretrainedBartModel', 'PretrainedFSMTModel', 'ProphetNetModel', 'QDQBertLMHeadModel', 'QDQBertModel', 'RagModel', 'ReformerModel', 'RegNetModel', 'RemBertModel', 'ResNetModel', 'RetriBertModel', 'RoCBertModel', 'RoFormerModel', 'RobertaModel', 'RobertaPreLayerNormModel', 'SEWDModel', 'SEWModel', 'SegformerModel', 'Speech2TextModel', 'SpeechEncoderDecoderModel', 'SpeechT5Model', 'SplinterModel', 'SqueezeBertModel', 'Swin2SRModel', 'SwinModel', 'Swinv2Model', 'SwitchTransformersEncoderModel', 'SwitchTransformersModel', 'T5EncoderModel', 'T5Model', 'TFAlbertModel', 'TFAutoModel', 'TFBartModel', 'TFBertLMHeadModel', 'TFBertModel', 'TFBlenderbotModel', 'TFBlenderbotSmallModel', 'TFCLIPModel', 'TFCLIPTextModel', 'TFCLIPVisionModel', 'TFCTRLLMHeadModel', 'TFCTRLModel', 'TFCamembertModel', 'TFConvBertModel', 'TFConvNextModel', 'TFCvtModel', 'TFData2VecVisionModel', 'TFDebertaModel', 'TFDebertaV2Model', 'TFDeiTModel', 'TFDistilBertModel', 'TFElectraModel', 'TFEncoderDecoderModel', 'TFEsmModel', 'TFFlaubertModel', 'TFFlaubertWithLMHeadModel', 'TFFunnelBaseModel', 'TFFunnelModel', 'TFGPT2DoubleHeadsModel', 'TFGPT2LMHeadModel', 'TFGPT2Model', 'TFGPTJModel', 'TFGroupViTModel', 'TFGroupViTTextModel', 'TFGroupViTVisionModel', 'TFHubertModel', 'TFLEDModel', 'TFLayoutLMModel', 'TFLayoutLMv3Model', 'TFLongformerModel', 'TFLxmertModel', 'TFMBartModel', 'TFMPNetModel', 'TFMT5EncoderModel', 'TFMT5Model', 'TFMarianMTModel', 'TFMarianModel', 'TFMobileBertModel', 'TFMobileViTModel', 'TFOPTModel', 'TFOpenAIGPTDoubleHeadsModel', 'TFOpenAIGPTLMHeadModel', 'TFOpenAIGPTModel', 'TFPegasusModel', 'TFRagModel', 'TFRegNetModel', 'TFRemBertModel', 'TFResNetModel', 'TFRoFormerModel', 'TFRobertaModel', 'TFRobertaPreLayerNormModel', 'TFSegformerModel', 'TFSpeech2TextModel', 'TFSwinModel', 'TFT5EncoderModel', 'TFT5Model', 'TFTapasModel', 'TFTransfoXLLMHeadModel', 'TFTransfoXLModel', 'TFViTMAEModel', 'TFViTModel', 'TFVisionEncoderDecoderModel', 'TFVisionTextDualEncoderModel', 'TFWav2Vec2Model', 'TFWhisperModel', 'TFXGLMModel', 'TFXLMModel', 'TFXLMRobertaModel', 'TFXLMWithLMHeadModel', 'TFXLNetLMHeadModel', 'TFXLNetModel', 'TableTransformerModel', 'TapasModel', 'TimeSeriesTransformerModel', 'TimesformerModel', 'TrajectoryTransformerModel', 'TransfoXLLMHeadModel', 'TransfoXLModel', 'TvltModel', 'UniSpeechModel', 'UniSpeechSatModel', 'VanModel', 'ViTHybridModel', 'ViTMAEModel', 'ViTMSNModel', 'ViTModel', 'VideoMAEModel', 'ViltModel', 'VisionEncoderDecoderModel', 'VisionTextDualEncoderModel', 'VisualBertModel', 'Wav2Vec2ConformerModel', 'Wav2Vec2Model', 'WavLMModel', 'WhisperModel', 'XCLIPModel', 'XCLIPTextModel', 'XCLIPVisionModel', 'XGLMModel', 'XLMModel', 'XLMProphetNetModel', 'XLMRobertaModel', 'XLMRobertaXLModel', 'XLMWithLMHeadModel', 'XLNetLMHeadModel', 'XLNetModel', 'XmodModel', 'YolosModel', 'YosoModel']\n",
      "['ASTPreTrainedModel', 'AlbertPreTrainedModel', 'AlignPreTrainedModel', 'AltCLIPPreTrainedModel', 'BartPretrainedModel', 'BeitPreTrainedModel', 'BertGenerationPreTrainedModel', 'BertPreTrainedModel', 'BigBirdPegasusPreTrainedModel', 'BigBirdPreTrainedModel', 'BioGptPreTrainedModel', 'BitPreTrainedModel', 'BlenderbotPreTrainedModel', 'BlenderbotSmallPreTrainedModel', 'Blip2PreTrainedModel', 'BlipPreTrainedModel', 'BloomPreTrainedModel', 'BridgeTowerPreTrainedModel', 'CLIPPreTrainedModel', 'CLIPSegPreTrainedModel', 'CTRLPreTrainedModel', 'CamembertPreTrainedModel', 'CaninePreTrainedModel', 'ChineseCLIPPreTrainedModel', 'ClapPreTrainedModel', 'CodeGenPreTrainedModel', 'ConditionalDetrPreTrainedModel', 'ConvBertPreTrainedModel', 'ConvNextPreTrainedModel', 'ConvNextV2PreTrainedModel', 'CvtPreTrainedModel', 'DPRPreTrainedModel', 'DPTPreTrainedModel', 'Data2VecAudioPreTrainedModel', 'Data2VecTextPreTrainedModel', 'Data2VecVisionPreTrainedModel', 'DebertaPreTrainedModel', 'DebertaV2PreTrainedModel', 'DecisionTransformerGPT2PreTrainedModel', 'DecisionTransformerPreTrainedModel', 'DeformableDetrPreTrainedModel', 'DeiTPreTrainedModel', 'DetaPreTrainedModel', 'DetrPreTrainedModel', 'DinatPreTrainedModel', 'DistilBertPreTrainedModel', 'DonutSwinPreTrainedModel', 'EfficientFormerPreTrainedModel', 'EfficientNetPreTrainedModel', 'ElectraPreTrainedModel', 'ErnieMPreTrainedModel', 'ErniePreTrainedModel', 'EsmFoldPreTrainedModel', 'EsmPreTrainedModel', 'FNetPreTrainedModel', 'FlaubertPreTrainedModel', 'FlavaPreTrainedModel', 'FlaxAlbertPreTrainedModel', 'FlaxBartDecoderPreTrainedModel', 'FlaxBartPreTrainedModel', 'FlaxBeitPreTrainedModel', 'FlaxBertPreTrainedModel', 'FlaxBigBirdPreTrainedModel', 'FlaxBlenderbotPreTrainedModel', 'FlaxBlenderbotSmallPreTrainedModel', 'FlaxCLIPPreTrainedModel', 'FlaxCLIPTextPreTrainedModel', 'FlaxCLIPVisionPreTrainedModel', 'FlaxDistilBertPreTrainedModel', 'FlaxElectraPreTrainedModel', 'FlaxGPT2PreTrainedModel', 'FlaxGPTJPreTrainedModel', 'FlaxGPTNeoPreTrainedModel', 'FlaxLongT5PreTrainedModel', 'FlaxMBartPreTrainedModel', 'FlaxMarianPreTrainedModel', 'FlaxOPTPreTrainedModel', 'FlaxPegasusPreTrainedModel', 'FlaxPreTrainedModel', 'FlaxRoFormerPreTrainedModel', 'FlaxRobertaPreLayerNormPreTrainedModel', 'FlaxRobertaPreTrainedModel', 'FlaxT5PreTrainedModel', 'FlaxViTPreTrainedModel', 'FlaxWav2Vec2PreTrainedModel', 'FlaxWhisperPreTrainedModel', 'FlaxXGLMPreTrainedModel', 'FlaxXLMRobertaPreTrainedModel', 'FunnelPreTrainedModel', 'GLPNPreTrainedModel', 'GPT2PreTrainedModel', 'GPTJPreTrainedModel', 'GPTNeoPreTrainedModel', 'GPTNeoXJapanesePreTrainedModel', 'GPTNeoXPreTrainedModel', 'GPTSanJapanesePreTrainedModel', 'GitPreTrainedModel', 'GraphormerPreTrainedModel', 'GroupViTPreTrainedModel', 'HubertPreTrainedModel', 'IBertPreTrainedModel', 'ImageGPTPreTrainedModel', 'InformerPreTrainedModel', 'JukeboxPreTrainedModel', 'LEDPreTrainedModel', 'LayoutLMPreTrainedModel', 'LayoutLMv2PreTrainedModel', 'LayoutLMv3PreTrainedModel', 'LevitPreTrainedModel', 'LiltPreTrainedModel', 'LongT5PreTrainedModel', 'LongformerPreTrainedModel', 'LukePreTrainedModel', 'LxmertPreTrainedModel', 'M2M100PreTrainedModel', 'MBartPreTrainedModel', 'MCTCTPreTrainedModel', 'MPNetPreTrainedModel', 'MT5PreTrainedModel', 'MarkupLMPreTrainedModel', 'Mask2FormerPreTrainedModel', 'MaskFormerPreTrainedModel', 'MegatronBertPreTrainedModel', 'MgpstrPreTrainedModel', 'MobileBertPreTrainedModel', 'MobileNetV1PreTrainedModel', 'MobileNetV2PreTrainedModel', 'MobileViTPreTrainedModel', 'MvpPreTrainedModel', 'NatPreTrainedModel', 'NezhaPreTrainedModel', 'NystromformerPreTrainedModel', 'OPTPreTrainedModel', 'OneFormerPreTrainedModel', 'OpenAIGPTPreTrainedModel', 'OwlViTPreTrainedModel', 'PLBartPreTrainedModel', 'PegasusPreTrainedModel', 'PegasusXPreTrainedModel', 'PerceiverPreTrainedModel', 'PoolFormerPreTrainedModel', 'PreTrainedModel', 'ProphetNetPreTrainedModel', 'QDQBertPreTrainedModel', 'RagPreTrainedModel', 'RealmPreTrainedModel', 'ReformerPreTrainedModel', 'RegNetPreTrainedModel', 'RemBertPreTrainedModel', 'ResNetPreTrainedModel', 'RetriBertPreTrainedModel', 'RoCBertPreTrainedModel', 'RoFormerPreTrainedModel', 'RobertaPreLayerNormPreTrainedModel', 'RobertaPreTrainedModel', 'SEWDPreTrainedModel', 'SEWPreTrainedModel', 'SegformerPreTrainedModel', 'Speech2Text2PreTrainedModel', 'Speech2TextPreTrainedModel', 'SpeechT5PreTrainedModel', 'SplinterPreTrainedModel', 'SqueezeBertPreTrainedModel', 'Swin2SRPreTrainedModel', 'SwinPreTrainedModel', 'Swinv2PreTrainedModel', 'SwitchTransformersPreTrainedModel', 'T5PreTrainedModel', 'TFAlbertPreTrainedModel', 'TFBartPretrainedModel', 'TFBertPreTrainedModel', 'TFBlenderbotPreTrainedModel', 'TFBlenderbotSmallPreTrainedModel', 'TFCLIPPreTrainedModel', 'TFCTRLPreTrainedModel', 'TFCamembertPreTrainedModel', 'TFConvBertPreTrainedModel', 'TFConvNextPreTrainedModel', 'TFCvtPreTrainedModel', 'TFData2VecVisionPreTrainedModel', 'TFDebertaPreTrainedModel', 'TFDebertaV2PreTrainedModel', 'TFDeiTPreTrainedModel', 'TFDistilBertPreTrainedModel', 'TFElectraPreTrainedModel', 'TFEsmPreTrainedModel', 'TFFlaubertPreTrainedModel', 'TFFunnelPreTrainedModel', 'TFGPT2PreTrainedModel', 'TFGPTJPreTrainedModel', 'TFGroupViTPreTrainedModel', 'TFHubertPreTrainedModel', 'TFLEDPreTrainedModel', 'TFLayoutLMPreTrainedModel', 'TFLayoutLMv3PreTrainedModel', 'TFLongformerPreTrainedModel', 'TFLxmertPreTrainedModel', 'TFMBartPreTrainedModel', 'TFMPNetPreTrainedModel', 'TFMarianPreTrainedModel', 'TFMobileBertPreTrainedModel', 'TFMobileViTPreTrainedModel', 'TFOPTPreTrainedModel', 'TFOpenAIGPTPreTrainedModel', 'TFPegasusPreTrainedModel', 'TFPreTrainedModel', 'TFRagPreTrainedModel', 'TFRegNetPreTrainedModel', 'TFRemBertPreTrainedModel', 'TFResNetPreTrainedModel', 'TFRoFormerPreTrainedModel', 'TFRobertaPreLayerNormPreTrainedModel', 'TFRobertaPreTrainedModel', 'TFSegformerPreTrainedModel', 'TFSpeech2TextPreTrainedModel', 'TFSwinPreTrainedModel', 'TFT5PreTrainedModel', 'TFTapasPreTrainedModel', 'TFTransfoXLPreTrainedModel', 'TFViTMAEPreTrainedModel', 'TFViTPreTrainedModel', 'TFWav2Vec2PreTrainedModel', 'TFWhisperPreTrainedModel', 'TFXGLMPreTrainedModel', 'TFXLMPreTrainedModel', 'TFXLMRobertaPreTrainedModel', 'TFXLNetPreTrainedModel', 'TableTransformerPreTrainedModel', 'TapasPreTrainedModel', 'TimeSeriesTransformerPreTrainedModel', 'TimesformerPreTrainedModel', 'TrOCRPreTrainedModel', 'TrajectoryTransformerPreTrainedModel', 'TransfoXLPreTrainedModel', 'TvltPreTrainedModel', 'UniSpeechPreTrainedModel', 'UniSpeechSatPreTrainedModel', 'UperNetPreTrainedModel', 'VanPreTrainedModel', 'ViTHybridPreTrainedModel', 'ViTMAEPreTrainedModel', 'ViTMSNPreTrainedModel', 'ViTPreTrainedModel', 'VideoMAEPreTrainedModel', 'ViltPreTrainedModel', 'VisualBertPreTrainedModel', 'Wav2Vec2ConformerPreTrainedModel', 'Wav2Vec2PreTrainedModel', 'WavLMPreTrainedModel', 'WhisperPreTrainedModel', 'XCLIPPreTrainedModel', 'XGLMPreTrainedModel', 'XLMPreTrainedModel', 'XLMProphetNetPreTrainedModel', 'XLMRobertaPreTrainedModel', 'XLMRobertaXLPreTrainedModel', 'XLNetPreTrainedModel', 'XmodPreTrainedModel', 'YolosPreTrainedModel', 'YosoPreTrainedModel']\n"
     ]
    }
   ],
   "source": [
    "print(config_names)\n",
    "print(model_names)\n",
    "print(pretrainedmdoel_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_config_names = []\n",
    "new_model_names = []\n",
    "new_ptm_names = []\n",
    "for config_names in config_names:\n",
    "    new_config_names.append(config_names.replace('Config', ''))\n",
    "\n",
    "for model_names in model_names:\n",
    "    new_model_names.append(model_names.replace('Model', ''))\n",
    "\n",
    "for pretrainedmdoel_names in pretrainedmdoel_names:\n",
    "    new_ptm_names.append(pretrainedmdoel_names.replace('PreTrainedModel', '').replace('PretrainedModel', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new_config_names: 211\n",
      "['AST', 'Albert', 'Align', 'AlignText', 'AlignVision', 'AltCLIP', 'AltCLIPText', 'AltCLIPVision', 'Auto', 'Bart', 'Beit', 'Bert', 'BertGeneration', 'BigBird', 'BigBirdPegasus', 'BioGpt', 'Bit', 'BitsAndBytes', 'Blenderbot', 'BlenderbotSmall', 'Blip2', 'Blip2QFormer', 'Blip2Vision', 'Blip', 'BlipText', 'BlipVision', 'Bloom', 'BridgeTower', 'BridgeTowerText', 'BridgeTowerVision', 'CLIP', 'CLIPSeg', 'CLIPSegText', 'CLIPSegVision', 'CLIPText', 'CLIPVision', 'CTRL', 'Camembert', 'Canine', 'ChineseCLIP', 'ChineseCLIPText', 'ChineseCLIPVision', 'ClapAudio', 'Clap', 'ClapText', 'CodeGen', 'ConditionalDetr', 'ConvBert', 'ConvNext', 'ConvNextV2', 'Cvt', 'DPR', 'DPT', 'Data2VecAudio', 'Data2VecText', 'Data2VecVision', 'Deberta', 'DebertaV2', 'DecisionTransformer', 'DeformableDetr', 'DeiT', 'Deta', 'Detr', 'Dinat', 'DistilBert', 'DonutSwin', 'EfficientFormer', 'EfficientNet', 'Electra', 'EncoderDecoder', 'Ernie', 'ErnieM', 'Esm', 'FNet', 'FSMT', 'Flaubert', 'Flava', 'FlavaImageCodebook', 'FlavaImage', 'FlavaMultimodal', 'FlavaText', 'Funnel', 'GLPN', 'GPT2', 'GPTJ', 'GPTNeo', 'GPTNeoX', 'GPTNeoXJapanese', 'GPTSanJapanese', 'Generation', 'Git', 'GitVision', 'Graphormer', 'GroupViT', 'GroupViTText', 'GroupViTVision', 'Hubert', 'IBert', 'ImageGPT', 'Informer', 'Jukebox', 'JukeboxPrior', 'JukeboxVQVAE', 'LED', 'LayoutLM', 'LayoutLMv2', 'LayoutLMv3', 'Levit', 'Lilt', 'LongT5', 'Longformer', 'Luke', 'Lxmert', 'M2M100', 'MBart', 'MCTCT', 'MMBT', 'MPNet', 'MT5', 'Marian', 'MarkupLM', 'Mask2Former', 'MaskFormer', 'MaskFormerSwin', 'MegatronBert', 'Mgpstr', 'MobileBert', 'MobileNetV1', 'MobileNetV2', 'MobileViT', 'Mvp', 'Nat', 'Nezha', 'Nystromformer', 'OPT', 'OneFormer', 'OpenAIGPT', 'OwlViT', 'OwlViTText', 'OwlViTVision', 'PLBart', 'Pegasus', 'PegasusX', 'Perceiver', 'PoolFormer', 'Pretrained', 'ProphetNet', 'QDQBert', 'Rag', 'Realm', 'Reformer', 'RegNet', 'RemBert', 'ResNet', 'RetriBert', 'RoCBert', 'RoFormer', 'Roberta', 'RobertaPreLayerNorm', 'SEW', 'SEWD', 'Segformer', 'Speech2Text2', 'Speech2Text', 'SpeechEncoderDecoder', 'SpeechT5', 'SpeechT5HifiGan', 'Splinter', 'SqueezeBert', 'Swin2SR', 'Swin', 'Swinv2', 'SwitchTransformers', 'T5', 'TableTransformer', 'Tapas', 'TimeSeriesTransformer', 'Timesformer', 'TrOCR', 'TrajectoryTransformer', 'TransfoXL', 'Tvlt', 'UniSpeech', 'UniSpeechSat', 'UperNet', 'Van', 'ViT', 'ViTHybrid', 'ViTMAE', 'ViTMSN', 'VideoMAE', 'Vilt', 'VisionEncoderDecoder', 'VisionTextDualEncoder', 'VisualBert', 'Wav2Vec2', 'Wav2Vec2Conformer', 'WavLM', 'Whisper', 'XCLIP', 'XCLIPText', 'XCLIPVision', 'XGLM', 'XLM', 'XLMProphetNet', 'XLMRoberta', 'XLMRobertaXL', 'XLNet', 'Xmod', 'Yolos', 'Yoso']\n",
      "Number of new_model_names: 335\n",
      "['AST', 'Albert', 'Align', 'AlignText', 'AlignVision', 'AltCLIP', 'AltCLIPText', 'AltCLIPVision', 'Auto', 'Bart', 'Beit', 'BertLMHead', 'Bert', 'BigBird', 'BigBirdPegasus', 'BioGpt', 'Bit', 'Blenderbot', 'BlenderbotSmall', 'Blip2', 'Blip2QFormer', 'Blip2Vision', 'Blip', 'BlipText', 'BlipVision', 'Bloom', 'BridgeTower', 'CLIP', 'CLIPSeg', 'CLIPSegText', 'CLIPSegVision', 'CLIPText', 'CLIPVision', 'CTRLLMHead', 'CTRL', 'Camembert', 'Canine', 'ChineseCLIP', 'ChineseCLIPText', 'ChineseCLIPVision', 'ClapAudio', 'Clap', 'ClapText', 'CodeGen', 'ConditionalDetr', 'ConvBert', 'ConvNext', 'ConvNextV2', 'Cvt', 'DPT', 'Data2VecAudio', 'Data2VecText', 'Data2VecVision', 'Deberta', 'DebertaV2', 'DecisionTransformerGPT2', 'DecisionTransformer', 'DeformableDetr', 'DeiT', 'Deta', 'Detr', 'Dinat', 'DistilBert', 'DonutSwin', 'EfficientFormer', 'EfficientNet', 'Electra', 'EncoderDecoder', 'ErnieM', 'Ernie', 'Esm', 'FNet', 'FSMT', 'Flaubert', 'FlaubertWithLMHead', 'FlavaImage', 'Flava', 'FlavaMultimodal', 'FlavaText', 'FlaxAlbert', 'FlaxAuto', 'FlaxBart', 'FlaxBeit', 'FlaxBert', 'FlaxBigBird', 'FlaxBlenderbot', 'FlaxBlenderbotSmall', 'FlaxCLIP', 'FlaxCLIPText', 'FlaxCLIPVision', 'FlaxDistilBert', 'FlaxElectra', 'FlaxEncoderDecoder', 'FlaxGPT2LMHead', 'FlaxGPT2', 'FlaxGPTJ', 'FlaxGPTNeo', 'FlaxLongT5', 'FlaxMBart', 'FlaxMT5Encoder', 'FlaxMT5', 'FlaxMarianMT', 'FlaxMarian', 'FlaxOPT', 'FlaxPegasus', 'FlaxRoFormer', 'FlaxRoberta', 'FlaxRobertaPreLayerNorm', 'FlaxSpeechEncoderDecoder', 'FlaxT5Encoder', 'FlaxT5', 'FlaxViT', 'FlaxVisionEncoderDecoder', 'FlaxVisionTextDualEncoder', 'FlaxWav2Vec2', 'FlaxWhisper', 'FlaxXGLM', 'FlaxXLMRoberta', 'FunnelBase', 'Funnel', 'GLPN', 'GPT2DoubleHeads', 'GPT2LMHead', 'GPT2', 'GPTJ', 'GPTNeo', 'GPTNeoXJapanese', 'GPTNeoX', 'GPTSanJapanese', 'Git', 'GitVision', 'Graphormer', 'GroupViT', 'GroupViTText', 'GroupViTVision', 'Hubert', 'IBert', 'ImageGPT', 'Informer', 'Jukebox', 'LED', 'LayoutLM', 'LayoutLMv2', 'LayoutLMv3', 'Levit', 'Lilt', 'LongT5Encoder', 'LongT5', 'Longformer', 'Luke', 'Lxmert', 'M2M100', 'MBart', 'MCTCT', 'MMBT', 'MPNet', 'MT5Encoder', 'MT5', 'MarianMT', 'Marian', 'MarkupLM', 'Mask2Former', 'MaskFormer', 'MegatronBert', 'Mgpstr', 'MobileBert', 'MobileNetV1', 'MobileNetV2', 'MobileViT', 'Mvp', 'Nat', 'Nezha', 'Nystromformer', 'OPT', 'OneFormer', 'OpenAIGPTDoubleHeads', 'OpenAIGPTLMHead', 'OpenAIGPT', 'OwlViT', 'OwlViTText', 'OwlViTVision', 'PLBart', 'Pegasus', 'PegasusX', 'Perceiver', 'PoolFormer', 'PretrainedBart', 'PretrainedFSMT', 'ProphetNet', 'QDQBertLMHead', 'QDQBert', 'Rag', 'Reformer', 'RegNet', 'RemBert', 'ResNet', 'RetriBert', 'RoCBert', 'RoFormer', 'Roberta', 'RobertaPreLayerNorm', 'SEWD', 'SEW', 'Segformer', 'Speech2Text', 'SpeechEncoderDecoder', 'SpeechT5', 'Splinter', 'SqueezeBert', 'Swin2SR', 'Swin', 'Swinv2', 'SwitchTransformersEncoder', 'SwitchTransformers', 'T5Encoder', 'T5', 'TFAlbert', 'TFAuto', 'TFBart', 'TFBertLMHead', 'TFBert', 'TFBlenderbot', 'TFBlenderbotSmall', 'TFCLIP', 'TFCLIPText', 'TFCLIPVision', 'TFCTRLLMHead', 'TFCTRL', 'TFCamembert', 'TFConvBert', 'TFConvNext', 'TFCvt', 'TFData2VecVision', 'TFDeberta', 'TFDebertaV2', 'TFDeiT', 'TFDistilBert', 'TFElectra', 'TFEncoderDecoder', 'TFEsm', 'TFFlaubert', 'TFFlaubertWithLMHead', 'TFFunnelBase', 'TFFunnel', 'TFGPT2DoubleHeads', 'TFGPT2LMHead', 'TFGPT2', 'TFGPTJ', 'TFGroupViT', 'TFGroupViTText', 'TFGroupViTVision', 'TFHubert', 'TFLED', 'TFLayoutLM', 'TFLayoutLMv3', 'TFLongformer', 'TFLxmert', 'TFMBart', 'TFMPNet', 'TFMT5Encoder', 'TFMT5', 'TFMarianMT', 'TFMarian', 'TFMobileBert', 'TFMobileViT', 'TFOPT', 'TFOpenAIGPTDoubleHeads', 'TFOpenAIGPTLMHead', 'TFOpenAIGPT', 'TFPegasus', 'TFRag', 'TFRegNet', 'TFRemBert', 'TFResNet', 'TFRoFormer', 'TFRoberta', 'TFRobertaPreLayerNorm', 'TFSegformer', 'TFSpeech2Text', 'TFSwin', 'TFT5Encoder', 'TFT5', 'TFTapas', 'TFTransfoXLLMHead', 'TFTransfoXL', 'TFViTMAE', 'TFViT', 'TFVisionEncoderDecoder', 'TFVisionTextDualEncoder', 'TFWav2Vec2', 'TFWhisper', 'TFXGLM', 'TFXLM', 'TFXLMRoberta', 'TFXLMWithLMHead', 'TFXLNetLMHead', 'TFXLNet', 'TableTransformer', 'Tapas', 'TimeSeriesTransformer', 'Timesformer', 'TrajectoryTransformer', 'TransfoXLLMHead', 'TransfoXL', 'Tvlt', 'UniSpeech', 'UniSpeechSat', 'Van', 'ViTHybrid', 'ViTMAE', 'ViTMSN', 'ViT', 'VideoMAE', 'Vilt', 'VisionEncoderDecoder', 'VisionTextDualEncoder', 'VisualBert', 'Wav2Vec2Conformer', 'Wav2Vec2', 'WavLM', 'Whisper', 'XCLIP', 'XCLIPText', 'XCLIPVision', 'XGLM', 'XLM', 'XLMProphetNet', 'XLMRoberta', 'XLMRobertaXL', 'XLMWithLMHead', 'XLNetLMHead', 'XLNet', 'Xmod', 'Yolos', 'Yoso']\n",
      "Number of new_ptm_names: 260\n",
      "['AST', 'Albert', 'Align', 'AltCLIP', 'Bart', 'Beit', 'BertGeneration', 'Bert', 'BigBirdPegasus', 'BigBird', 'BioGpt', 'Bit', 'Blenderbot', 'BlenderbotSmall', 'Blip2', 'Blip', 'Bloom', 'BridgeTower', 'CLIP', 'CLIPSeg', 'CTRL', 'Camembert', 'Canine', 'ChineseCLIP', 'Clap', 'CodeGen', 'ConditionalDetr', 'ConvBert', 'ConvNext', 'ConvNextV2', 'Cvt', 'DPR', 'DPT', 'Data2VecAudio', 'Data2VecText', 'Data2VecVision', 'Deberta', 'DebertaV2', 'DecisionTransformerGPT2', 'DecisionTransformer', 'DeformableDetr', 'DeiT', 'Deta', 'Detr', 'Dinat', 'DistilBert', 'DonutSwin', 'EfficientFormer', 'EfficientNet', 'Electra', 'ErnieM', 'Ernie', 'EsmFold', 'Esm', 'FNet', 'Flaubert', 'Flava', 'FlaxAlbert', 'FlaxBartDecoder', 'FlaxBart', 'FlaxBeit', 'FlaxBert', 'FlaxBigBird', 'FlaxBlenderbot', 'FlaxBlenderbotSmall', 'FlaxCLIP', 'FlaxCLIPText', 'FlaxCLIPVision', 'FlaxDistilBert', 'FlaxElectra', 'FlaxGPT2', 'FlaxGPTJ', 'FlaxGPTNeo', 'FlaxLongT5', 'FlaxMBart', 'FlaxMarian', 'FlaxOPT', 'FlaxPegasus', 'Flax', 'FlaxRoFormer', 'FlaxRobertaPreLayerNorm', 'FlaxRoberta', 'FlaxT5', 'FlaxViT', 'FlaxWav2Vec2', 'FlaxWhisper', 'FlaxXGLM', 'FlaxXLMRoberta', 'Funnel', 'GLPN', 'GPT2', 'GPTJ', 'GPTNeo', 'GPTNeoXJapanese', 'GPTNeoX', 'GPTSanJapanese', 'Git', 'Graphormer', 'GroupViT', 'Hubert', 'IBert', 'ImageGPT', 'Informer', 'Jukebox', 'LED', 'LayoutLM', 'LayoutLMv2', 'LayoutLMv3', 'Levit', 'Lilt', 'LongT5', 'Longformer', 'Luke', 'Lxmert', 'M2M100', 'MBart', 'MCTCT', 'MPNet', 'MT5', 'MarkupLM', 'Mask2Former', 'MaskFormer', 'MegatronBert', 'Mgpstr', 'MobileBert', 'MobileNetV1', 'MobileNetV2', 'MobileViT', 'Mvp', 'Nat', 'Nezha', 'Nystromformer', 'OPT', 'OneFormer', 'OpenAIGPT', 'OwlViT', 'PLBart', 'Pegasus', 'PegasusX', 'Perceiver', 'PoolFormer', '', 'ProphetNet', 'QDQBert', 'Rag', 'Realm', 'Reformer', 'RegNet', 'RemBert', 'ResNet', 'RetriBert', 'RoCBert', 'RoFormer', 'RobertaPreLayerNorm', 'Roberta', 'SEWD', 'SEW', 'Segformer', 'Speech2Text2', 'Speech2Text', 'SpeechT5', 'Splinter', 'SqueezeBert', 'Swin2SR', 'Swin', 'Swinv2', 'SwitchTransformers', 'T5', 'TFAlbert', 'TFBart', 'TFBert', 'TFBlenderbot', 'TFBlenderbotSmall', 'TFCLIP', 'TFCTRL', 'TFCamembert', 'TFConvBert', 'TFConvNext', 'TFCvt', 'TFData2VecVision', 'TFDeberta', 'TFDebertaV2', 'TFDeiT', 'TFDistilBert', 'TFElectra', 'TFEsm', 'TFFlaubert', 'TFFunnel', 'TFGPT2', 'TFGPTJ', 'TFGroupViT', 'TFHubert', 'TFLED', 'TFLayoutLM', 'TFLayoutLMv3', 'TFLongformer', 'TFLxmert', 'TFMBart', 'TFMPNet', 'TFMarian', 'TFMobileBert', 'TFMobileViT', 'TFOPT', 'TFOpenAIGPT', 'TFPegasus', 'TF', 'TFRag', 'TFRegNet', 'TFRemBert', 'TFResNet', 'TFRoFormer', 'TFRobertaPreLayerNorm', 'TFRoberta', 'TFSegformer', 'TFSpeech2Text', 'TFSwin', 'TFT5', 'TFTapas', 'TFTransfoXL', 'TFViTMAE', 'TFViT', 'TFWav2Vec2', 'TFWhisper', 'TFXGLM', 'TFXLM', 'TFXLMRoberta', 'TFXLNet', 'TableTransformer', 'Tapas', 'TimeSeriesTransformer', 'Timesformer', 'TrOCR', 'TrajectoryTransformer', 'TransfoXL', 'Tvlt', 'UniSpeech', 'UniSpeechSat', 'UperNet', 'Van', 'ViTHybrid', 'ViTMAE', 'ViTMSN', 'ViT', 'VideoMAE', 'Vilt', 'VisualBert', 'Wav2Vec2Conformer', 'Wav2Vec2', 'WavLM', 'Whisper', 'XCLIP', 'XGLM', 'XLM', 'XLMProphetNet', 'XLMRoberta', 'XLMRobertaXL', 'XLNet', 'Xmod', 'Yolos', 'Yoso']\n"
     ]
    }
   ],
   "source": [
    "print(f'Number of new_config_names: {len(new_config_names)}')\n",
    "print(new_config_names)\n",
    "print(f'Number of new_model_names: {len(new_model_names)}')\n",
    "print(new_model_names)\n",
    "print(f'Number of new_ptm_names: {len(new_ptm_names)}')\n",
    "print(new_ptm_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model architectures from new_config_names\n",
    "model_list = []\n",
    "for model_name in new_config_names:\n",
    "    model_archs = [name for name in dir(transformers) if name.startswith(model_name)]\n",
    "    # add model_archs to model_list\n",
    "    model_list.extend(model_archs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ASTConfig',\n",
       " 'ASTFeatureExtractor',\n",
       " 'ASTForAudioClassification',\n",
       " 'ASTModel',\n",
       " 'ASTPreTrainedModel',\n",
       " 'AlbertConfig',\n",
       " 'AlbertForMaskedLM',\n",
       " 'AlbertForMultipleChoice',\n",
       " 'AlbertForPreTraining',\n",
       " 'AlbertForQuestionAnswering',\n",
       " 'AlbertForSequenceClassification',\n",
       " 'AlbertForTokenClassification',\n",
       " 'AlbertModel',\n",
       " 'AlbertPreTrainedModel',\n",
       " 'AlbertTokenizer',\n",
       " 'AlbertTokenizerFast',\n",
       " 'AlignConfig',\n",
       " 'AlignModel',\n",
       " 'AlignPreTrainedModel',\n",
       " 'AlignProcessor',\n",
       " 'AlignTextConfig',\n",
       " 'AlignTextModel',\n",
       " 'AlignVisionConfig',\n",
       " 'AlignVisionModel',\n",
       " 'AlignTextConfig',\n",
       " 'AlignTextModel',\n",
       " 'AlignVisionConfig',\n",
       " 'AlignVisionModel',\n",
       " 'AltCLIPConfig',\n",
       " 'AltCLIPModel',\n",
       " 'AltCLIPPreTrainedModel',\n",
       " 'AltCLIPProcessor',\n",
       " 'AltCLIPTextConfig',\n",
       " 'AltCLIPTextModel',\n",
       " 'AltCLIPVisionConfig',\n",
       " 'AltCLIPVisionModel',\n",
       " 'AltCLIPTextConfig',\n",
       " 'AltCLIPTextModel',\n",
       " 'AltCLIPVisionConfig',\n",
       " 'AltCLIPVisionModel',\n",
       " 'AutoBackbone',\n",
       " 'AutoConfig',\n",
       " 'AutoFeatureExtractor',\n",
       " 'AutoImageProcessor',\n",
       " 'AutoModel',\n",
       " 'AutoModelForAudioClassification',\n",
       " 'AutoModelForAudioFrameClassification',\n",
       " 'AutoModelForAudioXVector',\n",
       " 'AutoModelForCTC',\n",
       " 'AutoModelForCausalLM',\n",
       " 'AutoModelForDepthEstimation',\n",
       " 'AutoModelForDocumentQuestionAnswering',\n",
       " 'AutoModelForImageClassification',\n",
       " 'AutoModelForImageSegmentation',\n",
       " 'AutoModelForInstanceSegmentation',\n",
       " 'AutoModelForMaskedImageModeling',\n",
       " 'AutoModelForMaskedLM',\n",
       " 'AutoModelForMultipleChoice',\n",
       " 'AutoModelForNextSentencePrediction',\n",
       " 'AutoModelForObjectDetection',\n",
       " 'AutoModelForPreTraining',\n",
       " 'AutoModelForQuestionAnswering',\n",
       " 'AutoModelForSemanticSegmentation',\n",
       " 'AutoModelForSeq2SeqLM',\n",
       " 'AutoModelForSequenceClassification',\n",
       " 'AutoModelForSpeechSeq2Seq',\n",
       " 'AutoModelForTableQuestionAnswering',\n",
       " 'AutoModelForTokenClassification',\n",
       " 'AutoModelForUniversalSegmentation',\n",
       " 'AutoModelForVideoClassification',\n",
       " 'AutoModelForVision2Seq',\n",
       " 'AutoModelForVisualQuestionAnswering',\n",
       " 'AutoModelForZeroShotImageClassification',\n",
       " 'AutoModelForZeroShotObjectDetection',\n",
       " 'AutoModelWithLMHead',\n",
       " 'AutoProcessor',\n",
       " 'AutoTokenizer',\n",
       " 'AutomaticSpeechRecognitionPipeline',\n",
       " 'BartConfig',\n",
       " 'BartForCausalLM',\n",
       " 'BartForConditionalGeneration',\n",
       " 'BartForQuestionAnswering',\n",
       " 'BartForSequenceClassification',\n",
       " 'BartModel',\n",
       " 'BartPretrainedModel',\n",
       " 'BartTokenizer',\n",
       " 'BartTokenizerFast',\n",
       " 'BarthezTokenizer',\n",
       " 'BarthezTokenizerFast',\n",
       " 'BartphoTokenizer',\n",
       " 'BeitConfig',\n",
       " 'BeitFeatureExtractor',\n",
       " 'BeitForImageClassification',\n",
       " 'BeitForMaskedImageModeling',\n",
       " 'BeitForSemanticSegmentation',\n",
       " 'BeitImageProcessor',\n",
       " 'BeitModel',\n",
       " 'BeitPreTrainedModel',\n",
       " 'BertConfig',\n",
       " 'BertForMaskedLM',\n",
       " 'BertForMultipleChoice',\n",
       " 'BertForNextSentencePrediction',\n",
       " 'BertForPreTraining',\n",
       " 'BertForQuestionAnswering',\n",
       " 'BertForSequenceClassification',\n",
       " 'BertForTokenClassification',\n",
       " 'BertGenerationConfig',\n",
       " 'BertGenerationDecoder',\n",
       " 'BertGenerationEncoder',\n",
       " 'BertGenerationPreTrainedModel',\n",
       " 'BertGenerationTokenizer',\n",
       " 'BertJapaneseTokenizer',\n",
       " 'BertLMHeadModel',\n",
       " 'BertLayer',\n",
       " 'BertModel',\n",
       " 'BertPreTrainedModel',\n",
       " 'BertTokenizer',\n",
       " 'BertTokenizerFast',\n",
       " 'BertweetTokenizer',\n",
       " 'BertGenerationConfig',\n",
       " 'BertGenerationDecoder',\n",
       " 'BertGenerationEncoder',\n",
       " 'BertGenerationPreTrainedModel',\n",
       " 'BertGenerationTokenizer',\n",
       " 'BigBirdConfig',\n",
       " 'BigBirdForCausalLM',\n",
       " 'BigBirdForMaskedLM',\n",
       " 'BigBirdForMultipleChoice',\n",
       " 'BigBirdForPreTraining',\n",
       " 'BigBirdForQuestionAnswering',\n",
       " 'BigBirdForSequenceClassification',\n",
       " 'BigBirdForTokenClassification',\n",
       " 'BigBirdLayer',\n",
       " 'BigBirdModel',\n",
       " 'BigBirdPegasusConfig',\n",
       " 'BigBirdPegasusForCausalLM',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BigBirdPegasusForQuestionAnswering',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'BigBirdPegasusModel',\n",
       " 'BigBirdPegasusPreTrainedModel',\n",
       " 'BigBirdPreTrainedModel',\n",
       " 'BigBirdTokenizer',\n",
       " 'BigBirdTokenizerFast',\n",
       " 'BigBirdPegasusConfig',\n",
       " 'BigBirdPegasusForCausalLM',\n",
       " 'BigBirdPegasusForConditionalGeneration',\n",
       " 'BigBirdPegasusForQuestionAnswering',\n",
       " 'BigBirdPegasusForSequenceClassification',\n",
       " 'BigBirdPegasusModel',\n",
       " 'BigBirdPegasusPreTrainedModel',\n",
       " 'BioGptConfig',\n",
       " 'BioGptForCausalLM',\n",
       " 'BioGptModel',\n",
       " 'BioGptPreTrainedModel',\n",
       " 'BioGptTokenizer',\n",
       " 'BitBackbone',\n",
       " 'BitConfig',\n",
       " 'BitForImageClassification',\n",
       " 'BitImageProcessor',\n",
       " 'BitModel',\n",
       " 'BitPreTrainedModel',\n",
       " 'BitsAndBytesConfig',\n",
       " 'BitsAndBytesConfig',\n",
       " 'BlenderbotConfig',\n",
       " 'BlenderbotForCausalLM',\n",
       " 'BlenderbotForConditionalGeneration',\n",
       " 'BlenderbotModel',\n",
       " 'BlenderbotPreTrainedModel',\n",
       " 'BlenderbotSmallConfig',\n",
       " 'BlenderbotSmallForCausalLM',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'BlenderbotSmallModel',\n",
       " 'BlenderbotSmallPreTrainedModel',\n",
       " 'BlenderbotSmallTokenizer',\n",
       " 'BlenderbotSmallTokenizerFast',\n",
       " 'BlenderbotTokenizer',\n",
       " 'BlenderbotTokenizerFast',\n",
       " 'BlenderbotSmallConfig',\n",
       " 'BlenderbotSmallForCausalLM',\n",
       " 'BlenderbotSmallForConditionalGeneration',\n",
       " 'BlenderbotSmallModel',\n",
       " 'BlenderbotSmallPreTrainedModel',\n",
       " 'BlenderbotSmallTokenizer',\n",
       " 'BlenderbotSmallTokenizerFast',\n",
       " 'Blip2Config',\n",
       " 'Blip2ForConditionalGeneration',\n",
       " 'Blip2Model',\n",
       " 'Blip2PreTrainedModel',\n",
       " 'Blip2Processor',\n",
       " 'Blip2QFormerConfig',\n",
       " 'Blip2QFormerModel',\n",
       " 'Blip2VisionConfig',\n",
       " 'Blip2VisionModel',\n",
       " 'Blip2QFormerConfig',\n",
       " 'Blip2QFormerModel',\n",
       " 'Blip2VisionConfig',\n",
       " 'Blip2VisionModel',\n",
       " 'Blip2Config',\n",
       " 'Blip2ForConditionalGeneration',\n",
       " 'Blip2Model',\n",
       " 'Blip2PreTrainedModel',\n",
       " 'Blip2Processor',\n",
       " 'Blip2QFormerConfig',\n",
       " 'Blip2QFormerModel',\n",
       " 'Blip2VisionConfig',\n",
       " 'Blip2VisionModel',\n",
       " 'BlipConfig',\n",
       " 'BlipForConditionalGeneration',\n",
       " 'BlipForImageTextRetrieval',\n",
       " 'BlipForQuestionAnswering',\n",
       " 'BlipImageProcessor',\n",
       " 'BlipModel',\n",
       " 'BlipPreTrainedModel',\n",
       " 'BlipProcessor',\n",
       " 'BlipTextConfig',\n",
       " 'BlipTextModel',\n",
       " 'BlipVisionConfig',\n",
       " 'BlipVisionModel',\n",
       " 'BlipTextConfig',\n",
       " 'BlipTextModel',\n",
       " 'BlipVisionConfig',\n",
       " 'BlipVisionModel',\n",
       " 'BloomConfig',\n",
       " 'BloomForCausalLM',\n",
       " 'BloomForQuestionAnswering',\n",
       " 'BloomForSequenceClassification',\n",
       " 'BloomForTokenClassification',\n",
       " 'BloomModel',\n",
       " 'BloomPreTrainedModel',\n",
       " 'BloomTokenizerFast',\n",
       " 'BridgeTowerConfig',\n",
       " 'BridgeTowerForContrastiveLearning',\n",
       " 'BridgeTowerForImageAndTextRetrieval',\n",
       " 'BridgeTowerForMaskedLM',\n",
       " 'BridgeTowerImageProcessor',\n",
       " 'BridgeTowerModel',\n",
       " 'BridgeTowerPreTrainedModel',\n",
       " 'BridgeTowerProcessor',\n",
       " 'BridgeTowerTextConfig',\n",
       " 'BridgeTowerVisionConfig',\n",
       " 'BridgeTowerTextConfig',\n",
       " 'BridgeTowerVisionConfig',\n",
       " 'CLIPConfig',\n",
       " 'CLIPFeatureExtractor',\n",
       " 'CLIPImageProcessor',\n",
       " 'CLIPModel',\n",
       " 'CLIPPreTrainedModel',\n",
       " 'CLIPProcessor',\n",
       " 'CLIPSEG_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CLIPSEG_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLIPSegConfig',\n",
       " 'CLIPSegForImageSegmentation',\n",
       " 'CLIPSegModel',\n",
       " 'CLIPSegPreTrainedModel',\n",
       " 'CLIPSegProcessor',\n",
       " 'CLIPSegTextConfig',\n",
       " 'CLIPSegTextModel',\n",
       " 'CLIPSegVisionConfig',\n",
       " 'CLIPSegVisionModel',\n",
       " 'CLIPTextConfig',\n",
       " 'CLIPTextModel',\n",
       " 'CLIPTextModelWithProjection',\n",
       " 'CLIPTokenizer',\n",
       " 'CLIPTokenizerFast',\n",
       " 'CLIPVisionConfig',\n",
       " 'CLIPVisionModel',\n",
       " 'CLIPVisionModelWithProjection',\n",
       " 'CLIP_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CLIP_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CLIPSegConfig',\n",
       " 'CLIPSegForImageSegmentation',\n",
       " 'CLIPSegModel',\n",
       " 'CLIPSegPreTrainedModel',\n",
       " 'CLIPSegProcessor',\n",
       " 'CLIPSegTextConfig',\n",
       " 'CLIPSegTextModel',\n",
       " 'CLIPSegVisionConfig',\n",
       " 'CLIPSegVisionModel',\n",
       " 'CLIPSegTextConfig',\n",
       " 'CLIPSegTextModel',\n",
       " 'CLIPSegVisionConfig',\n",
       " 'CLIPSegVisionModel',\n",
       " 'CLIPTextConfig',\n",
       " 'CLIPTextModel',\n",
       " 'CLIPTextModelWithProjection',\n",
       " 'CLIPVisionConfig',\n",
       " 'CLIPVisionModel',\n",
       " 'CLIPVisionModelWithProjection',\n",
       " 'CTRLConfig',\n",
       " 'CTRLForSequenceClassification',\n",
       " 'CTRLLMHeadModel',\n",
       " 'CTRLModel',\n",
       " 'CTRLPreTrainedModel',\n",
       " 'CTRLTokenizer',\n",
       " 'CTRL_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'CTRL_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'CamembertConfig',\n",
       " 'CamembertForCausalLM',\n",
       " 'CamembertForMaskedLM',\n",
       " 'CamembertForMultipleChoice',\n",
       " 'CamembertForQuestionAnswering',\n",
       " 'CamembertForSequenceClassification',\n",
       " 'CamembertForTokenClassification',\n",
       " 'CamembertModel',\n",
       " 'CamembertPreTrainedModel',\n",
       " 'CamembertTokenizer',\n",
       " 'CamembertTokenizerFast',\n",
       " 'CanineConfig',\n",
       " 'CanineForMultipleChoice',\n",
       " 'CanineForQuestionAnswering',\n",
       " 'CanineForSequenceClassification',\n",
       " 'CanineForTokenClassification',\n",
       " 'CanineLayer',\n",
       " 'CanineModel',\n",
       " 'CaninePreTrainedModel',\n",
       " 'CanineTokenizer',\n",
       " 'ChineseCLIPConfig',\n",
       " 'ChineseCLIPFeatureExtractor',\n",
       " 'ChineseCLIPImageProcessor',\n",
       " 'ChineseCLIPModel',\n",
       " 'ChineseCLIPPreTrainedModel',\n",
       " 'ChineseCLIPProcessor',\n",
       " 'ChineseCLIPTextConfig',\n",
       " 'ChineseCLIPTextModel',\n",
       " 'ChineseCLIPVisionConfig',\n",
       " 'ChineseCLIPVisionModel',\n",
       " 'ChineseCLIPTextConfig',\n",
       " 'ChineseCLIPTextModel',\n",
       " 'ChineseCLIPVisionConfig',\n",
       " 'ChineseCLIPVisionModel',\n",
       " 'ClapAudioConfig',\n",
       " 'ClapAudioModel',\n",
       " 'ClapAudioModelWithProjection',\n",
       " 'ClapAudioConfig',\n",
       " 'ClapAudioModel',\n",
       " 'ClapAudioModelWithProjection',\n",
       " 'ClapConfig',\n",
       " 'ClapFeatureExtractor',\n",
       " 'ClapModel',\n",
       " 'ClapPreTrainedModel',\n",
       " 'ClapProcessor',\n",
       " 'ClapTextConfig',\n",
       " 'ClapTextModel',\n",
       " 'ClapTextModelWithProjection',\n",
       " 'ClapTextConfig',\n",
       " 'ClapTextModel',\n",
       " 'ClapTextModelWithProjection',\n",
       " 'CodeGenConfig',\n",
       " 'CodeGenForCausalLM',\n",
       " 'CodeGenModel',\n",
       " 'CodeGenPreTrainedModel',\n",
       " 'CodeGenTokenizer',\n",
       " 'CodeGenTokenizerFast',\n",
       " 'ConditionalDetrConfig',\n",
       " 'ConditionalDetrFeatureExtractor',\n",
       " 'ConditionalDetrForObjectDetection',\n",
       " 'ConditionalDetrForSegmentation',\n",
       " 'ConditionalDetrImageProcessor',\n",
       " 'ConditionalDetrModel',\n",
       " 'ConditionalDetrPreTrainedModel',\n",
       " 'ConvBertConfig',\n",
       " 'ConvBertForMaskedLM',\n",
       " 'ConvBertForMultipleChoice',\n",
       " 'ConvBertForQuestionAnswering',\n",
       " 'ConvBertForSequenceClassification',\n",
       " 'ConvBertForTokenClassification',\n",
       " 'ConvBertLayer',\n",
       " 'ConvBertModel',\n",
       " 'ConvBertPreTrainedModel',\n",
       " 'ConvBertTokenizer',\n",
       " 'ConvBertTokenizerFast',\n",
       " 'ConvNextBackbone',\n",
       " 'ConvNextConfig',\n",
       " 'ConvNextFeatureExtractor',\n",
       " 'ConvNextForImageClassification',\n",
       " 'ConvNextImageProcessor',\n",
       " 'ConvNextModel',\n",
       " 'ConvNextPreTrainedModel',\n",
       " 'ConvNextV2Backbone',\n",
       " 'ConvNextV2Config',\n",
       " 'ConvNextV2ForImageClassification',\n",
       " 'ConvNextV2Model',\n",
       " 'ConvNextV2PreTrainedModel',\n",
       " 'ConvNextV2Backbone',\n",
       " 'ConvNextV2Config',\n",
       " 'ConvNextV2ForImageClassification',\n",
       " 'ConvNextV2Model',\n",
       " 'ConvNextV2PreTrainedModel',\n",
       " 'CvtConfig',\n",
       " 'CvtForImageClassification',\n",
       " 'CvtModel',\n",
       " 'CvtPreTrainedModel',\n",
       " 'DPRConfig',\n",
       " 'DPRContextEncoder',\n",
       " 'DPRContextEncoderTokenizer',\n",
       " 'DPRContextEncoderTokenizerFast',\n",
       " 'DPRPreTrainedModel',\n",
       " 'DPRPretrainedContextEncoder',\n",
       " 'DPRPretrainedQuestionEncoder',\n",
       " 'DPRPretrainedReader',\n",
       " 'DPRQuestionEncoder',\n",
       " 'DPRQuestionEncoderTokenizer',\n",
       " 'DPRQuestionEncoderTokenizerFast',\n",
       " 'DPRReader',\n",
       " 'DPRReaderOutput',\n",
       " 'DPRReaderTokenizer',\n",
       " 'DPRReaderTokenizerFast',\n",
       " 'DPR_CONTEXT_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPR_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DPR_QUESTION_ENCODER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPR_READER_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'DPTConfig',\n",
       " 'DPTFeatureExtractor',\n",
       " 'DPTForDepthEstimation',\n",
       " 'DPTForSemanticSegmentation',\n",
       " 'DPTImageProcessor',\n",
       " 'DPTModel',\n",
       " 'DPTPreTrainedModel',\n",
       " 'DPT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'DPT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'Data2VecAudioConfig',\n",
       " 'Data2VecAudioForAudioFrameClassification',\n",
       " 'Data2VecAudioForCTC',\n",
       " 'Data2VecAudioForSequenceClassification',\n",
       " 'Data2VecAudioForXVector',\n",
       " 'Data2VecAudioModel',\n",
       " 'Data2VecAudioPreTrainedModel',\n",
       " 'Data2VecTextConfig',\n",
       " 'Data2VecTextForCausalLM',\n",
       " 'Data2VecTextForMaskedLM',\n",
       " 'Data2VecTextForMultipleChoice',\n",
       " 'Data2VecTextForQuestionAnswering',\n",
       " 'Data2VecTextForSequenceClassification',\n",
       " 'Data2VecTextForTokenClassification',\n",
       " 'Data2VecTextModel',\n",
       " 'Data2VecTextPreTrainedModel',\n",
       " 'Data2VecVisionConfig',\n",
       " 'Data2VecVisionForImageClassification',\n",
       " 'Data2VecVisionForSemanticSegmentation',\n",
       " 'Data2VecVisionModel',\n",
       " 'Data2VecVisionPreTrainedModel',\n",
       " 'DebertaConfig',\n",
       " 'DebertaForMaskedLM',\n",
       " 'DebertaForQuestionAnswering',\n",
       " 'DebertaForSequenceClassification',\n",
       " 'DebertaForTokenClassification',\n",
       " 'DebertaModel',\n",
       " 'DebertaPreTrainedModel',\n",
       " 'DebertaTokenizer',\n",
       " 'DebertaTokenizerFast',\n",
       " 'DebertaV2Config',\n",
       " 'DebertaV2ForMaskedLM',\n",
       " 'DebertaV2ForMultipleChoice',\n",
       " 'DebertaV2ForQuestionAnswering',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DebertaV2ForTokenClassification',\n",
       " 'DebertaV2Model',\n",
       " 'DebertaV2PreTrainedModel',\n",
       " 'DebertaV2Tokenizer',\n",
       " 'DebertaV2TokenizerFast',\n",
       " 'DebertaV2Config',\n",
       " 'DebertaV2ForMaskedLM',\n",
       " 'DebertaV2ForMultipleChoice',\n",
       " 'DebertaV2ForQuestionAnswering',\n",
       " 'DebertaV2ForSequenceClassification',\n",
       " 'DebertaV2ForTokenClassification',\n",
       " 'DebertaV2Model',\n",
       " 'DebertaV2PreTrainedModel',\n",
       " 'DebertaV2Tokenizer',\n",
       " 'DebertaV2TokenizerFast',\n",
       " 'DecisionTransformerConfig',\n",
       " 'DecisionTransformerGPT2Model',\n",
       " 'DecisionTransformerGPT2PreTrainedModel',\n",
       " 'DecisionTransformerModel',\n",
       " 'DecisionTransformerPreTrainedModel',\n",
       " 'DeformableDetrConfig',\n",
       " 'DeformableDetrFeatureExtractor',\n",
       " 'DeformableDetrForObjectDetection',\n",
       " 'DeformableDetrImageProcessor',\n",
       " 'DeformableDetrModel',\n",
       " 'DeformableDetrPreTrainedModel',\n",
       " 'DeiTConfig',\n",
       " 'DeiTFeatureExtractor',\n",
       " 'DeiTForImageClassification',\n",
       " 'DeiTForImageClassificationWithTeacher',\n",
       " 'DeiTForMaskedImageModeling',\n",
       " 'DeiTImageProcessor',\n",
       " 'DeiTModel',\n",
       " 'DeiTPreTrainedModel',\n",
       " 'DetaConfig',\n",
       " 'DetaForObjectDetection',\n",
       " 'DetaImageProcessor',\n",
       " 'DetaModel',\n",
       " 'DetaPreTrainedModel',\n",
       " 'DetrConfig',\n",
       " 'DetrFeatureExtractor',\n",
       " 'DetrForObjectDetection',\n",
       " 'DetrForSegmentation',\n",
       " 'DetrImageProcessor',\n",
       " 'DetrModel',\n",
       " 'DetrPreTrainedModel',\n",
       " 'DinatBackbone',\n",
       " 'DinatConfig',\n",
       " 'DinatForImageClassification',\n",
       " 'DinatModel',\n",
       " 'DinatPreTrainedModel',\n",
       " 'DistilBertConfig',\n",
       " 'DistilBertForMaskedLM',\n",
       " 'DistilBertForMultipleChoice',\n",
       " 'DistilBertForQuestionAnswering',\n",
       " 'DistilBertForSequenceClassification',\n",
       " 'DistilBertForTokenClassification',\n",
       " 'DistilBertModel',\n",
       " 'DistilBertPreTrainedModel',\n",
       " 'DistilBertTokenizer',\n",
       " 'DistilBertTokenizerFast',\n",
       " 'DonutSwinConfig',\n",
       " 'DonutSwinModel',\n",
       " 'DonutSwinPreTrainedModel',\n",
       " 'EfficientFormerConfig',\n",
       " 'EfficientFormerForImageClassification',\n",
       " 'EfficientFormerForImageClassificationWithTeacher',\n",
       " 'EfficientFormerImageProcessor',\n",
       " 'EfficientFormerModel',\n",
       " 'EfficientFormerPreTrainedModel',\n",
       " 'EfficientNetConfig',\n",
       " 'EfficientNetForImageClassification',\n",
       " 'EfficientNetImageProcessor',\n",
       " 'EfficientNetModel',\n",
       " 'EfficientNetPreTrainedModel',\n",
       " 'ElectraConfig',\n",
       " 'ElectraForCausalLM',\n",
       " 'ElectraForMaskedLM',\n",
       " 'ElectraForMultipleChoice',\n",
       " 'ElectraForPreTraining',\n",
       " 'ElectraForQuestionAnswering',\n",
       " 'ElectraForSequenceClassification',\n",
       " 'ElectraForTokenClassification',\n",
       " 'ElectraModel',\n",
       " 'ElectraPreTrainedModel',\n",
       " 'ElectraTokenizer',\n",
       " 'ElectraTokenizerFast',\n",
       " 'EncoderDecoderConfig',\n",
       " 'EncoderDecoderModel',\n",
       " 'ErnieConfig',\n",
       " 'ErnieForCausalLM',\n",
       " 'ErnieForMaskedLM',\n",
       " 'ErnieForMultipleChoice',\n",
       " 'ErnieForNextSentencePrediction',\n",
       " 'ErnieForPreTraining',\n",
       " 'ErnieForQuestionAnswering',\n",
       " 'ErnieForSequenceClassification',\n",
       " 'ErnieForTokenClassification',\n",
       " 'ErnieMConfig',\n",
       " 'ErnieMForInformationExtraction',\n",
       " 'ErnieMForMultipleChoice',\n",
       " 'ErnieMForQuestionAnswering',\n",
       " 'ErnieMForSequenceClassification',\n",
       " 'ErnieMForTokenClassification',\n",
       " 'ErnieMModel',\n",
       " 'ErnieMPreTrainedModel',\n",
       " 'ErnieMTokenizer',\n",
       " 'ErnieModel',\n",
       " 'ErniePreTrainedModel',\n",
       " 'ErnieMConfig',\n",
       " 'ErnieMForInformationExtraction',\n",
       " 'ErnieMForMultipleChoice',\n",
       " 'ErnieMForQuestionAnswering',\n",
       " 'ErnieMForSequenceClassification',\n",
       " 'ErnieMForTokenClassification',\n",
       " 'ErnieMModel',\n",
       " 'ErnieMPreTrainedModel',\n",
       " 'ErnieMTokenizer',\n",
       " 'ErnieModel',\n",
       " 'EsmConfig',\n",
       " 'EsmFoldPreTrainedModel',\n",
       " 'EsmForMaskedLM',\n",
       " 'EsmForProteinFolding',\n",
       " 'EsmForSequenceClassification',\n",
       " 'EsmForTokenClassification',\n",
       " 'EsmModel',\n",
       " 'EsmPreTrainedModel',\n",
       " 'EsmTokenizer',\n",
       " 'FNetConfig',\n",
       " 'FNetForMaskedLM',\n",
       " 'FNetForMultipleChoice',\n",
       " 'FNetForNextSentencePrediction',\n",
       " 'FNetForPreTraining',\n",
       " 'FNetForQuestionAnswering',\n",
       " 'FNetForSequenceClassification',\n",
       " 'FNetForTokenClassification',\n",
       " 'FNetLayer',\n",
       " 'FNetModel',\n",
       " 'FNetPreTrainedModel',\n",
       " 'FNetTokenizer',\n",
       " 'FNetTokenizerFast',\n",
       " 'FSMTConfig',\n",
       " 'FSMTForConditionalGeneration',\n",
       " 'FSMTModel',\n",
       " 'FSMTTokenizer',\n",
       " 'FSMT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'FlaubertConfig',\n",
       " 'FlaubertForMultipleChoice',\n",
       " 'FlaubertForQuestionAnswering',\n",
       " 'FlaubertForQuestionAnsweringSimple',\n",
       " 'FlaubertForSequenceClassification',\n",
       " 'FlaubertForTokenClassification',\n",
       " 'FlaubertModel',\n",
       " 'FlaubertPreTrainedModel',\n",
       " 'FlaubertTokenizer',\n",
       " 'FlaubertWithLMHeadModel',\n",
       " 'FlavaConfig',\n",
       " 'FlavaFeatureExtractor',\n",
       " 'FlavaForPreTraining',\n",
       " 'FlavaImageCodebook',\n",
       " 'FlavaImageCodebookConfig',\n",
       " 'FlavaImageConfig',\n",
       " 'FlavaImageModel',\n",
       " 'FlavaImageProcessor',\n",
       " 'FlavaModel',\n",
       " 'FlavaMultimodalConfig',\n",
       " 'FlavaMultimodalModel',\n",
       " 'FlavaPreTrainedModel',\n",
       " 'FlavaProcessor',\n",
       " 'FlavaTextConfig',\n",
       " 'FlavaTextModel',\n",
       " 'FlavaImageCodebook',\n",
       " 'FlavaImageCodebookConfig',\n",
       " 'FlavaImageCodebook',\n",
       " 'FlavaImageCodebookConfig',\n",
       " 'FlavaImageConfig',\n",
       " 'FlavaImageModel',\n",
       " 'FlavaImageProcessor',\n",
       " 'FlavaMultimodalConfig',\n",
       " 'FlavaMultimodalModel',\n",
       " 'FlavaTextConfig',\n",
       " 'FlavaTextModel',\n",
       " 'FunnelBaseModel',\n",
       " 'FunnelConfig',\n",
       " 'FunnelForMaskedLM',\n",
       " 'FunnelForMultipleChoice',\n",
       " 'FunnelForPreTraining',\n",
       " 'FunnelForQuestionAnswering',\n",
       " 'FunnelForSequenceClassification',\n",
       " 'FunnelForTokenClassification',\n",
       " 'FunnelModel',\n",
       " 'FunnelPreTrainedModel',\n",
       " 'FunnelTokenizer',\n",
       " 'FunnelTokenizerFast',\n",
       " 'GLPNConfig',\n",
       " 'GLPNFeatureExtractor',\n",
       " 'GLPNForDepthEstimation',\n",
       " 'GLPNImageProcessor',\n",
       " 'GLPNModel',\n",
       " 'GLPNPreTrainedModel',\n",
       " 'GLPN_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GLPN_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPT2Config',\n",
       " 'GPT2DoubleHeadsModel',\n",
       " 'GPT2ForSequenceClassification',\n",
       " 'GPT2ForTokenClassification',\n",
       " 'GPT2LMHeadModel',\n",
       " 'GPT2Model',\n",
       " 'GPT2PreTrainedModel',\n",
       " 'GPT2Tokenizer',\n",
       " 'GPT2TokenizerFast',\n",
       " 'GPT2_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPT2_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTJConfig',\n",
       " 'GPTJForCausalLM',\n",
       " 'GPTJForQuestionAnswering',\n",
       " 'GPTJForSequenceClassification',\n",
       " 'GPTJModel',\n",
       " 'GPTJPreTrainedModel',\n",
       " 'GPTJ_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'GPTJ_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'GPTNeoConfig',\n",
       " 'GPTNeoForCausalLM',\n",
       " 'GPTNeoForSequenceClassification',\n",
       " 'GPTNeoModel',\n",
       " 'GPTNeoPreTrainedModel',\n",
       " 'GPTNeoXConfig',\n",
       " 'GPTNeoXForCausalLM',\n",
       " 'GPTNeoXJapaneseConfig',\n",
       " 'GPTNeoXJapaneseForCausalLM',\n",
       " 'GPTNeoXJapaneseLayer',\n",
       " 'GPTNeoXJapaneseModel',\n",
       " 'GPTNeoXJapanesePreTrainedModel',\n",
       " 'GPTNeoXJapaneseTokenizer',\n",
       " 'GPTNeoXLayer',\n",
       " 'GPTNeoXModel',\n",
       " 'GPTNeoXPreTrainedModel',\n",
       " 'GPTNeoXTokenizerFast',\n",
       " 'GPTNeoXConfig',\n",
       " 'GPTNeoXForCausalLM',\n",
       " 'GPTNeoXJapaneseConfig',\n",
       " 'GPTNeoXJapaneseForCausalLM',\n",
       " 'GPTNeoXJapaneseLayer',\n",
       " 'GPTNeoXJapaneseModel',\n",
       " 'GPTNeoXJapanesePreTrainedModel',\n",
       " 'GPTNeoXJapaneseTokenizer',\n",
       " 'GPTNeoXLayer',\n",
       " 'GPTNeoXModel',\n",
       " 'GPTNeoXPreTrainedModel',\n",
       " 'GPTNeoXTokenizerFast',\n",
       " 'GPTNeoXJapaneseConfig',\n",
       " 'GPTNeoXJapaneseForCausalLM',\n",
       " 'GPTNeoXJapaneseLayer',\n",
       " 'GPTNeoXJapaneseModel',\n",
       " 'GPTNeoXJapanesePreTrainedModel',\n",
       " 'GPTNeoXJapaneseTokenizer',\n",
       " 'GPTSanJapaneseConfig',\n",
       " 'GPTSanJapaneseForConditionalGeneration',\n",
       " 'GPTSanJapaneseModel',\n",
       " 'GPTSanJapanesePreTrainedModel',\n",
       " 'GPTSanJapaneseTokenizer',\n",
       " 'GenerationConfig',\n",
       " 'GenerationMixin',\n",
       " 'GitConfig',\n",
       " 'GitForCausalLM',\n",
       " 'GitModel',\n",
       " 'GitPreTrainedModel',\n",
       " 'GitProcessor',\n",
       " 'GitVisionConfig',\n",
       " 'GitVisionModel',\n",
       " 'GitVisionConfig',\n",
       " 'GitVisionModel',\n",
       " 'GraphormerConfig',\n",
       " 'GraphormerForGraphClassification',\n",
       " 'GraphormerModel',\n",
       " 'GraphormerPreTrainedModel',\n",
       " 'GroupViTConfig',\n",
       " 'GroupViTModel',\n",
       " 'GroupViTPreTrainedModel',\n",
       " 'GroupViTTextConfig',\n",
       " 'GroupViTTextModel',\n",
       " 'GroupViTVisionConfig',\n",
       " 'GroupViTVisionModel',\n",
       " 'GroupViTTextConfig',\n",
       " 'GroupViTTextModel',\n",
       " 'GroupViTVisionConfig',\n",
       " 'GroupViTVisionModel',\n",
       " 'HubertConfig',\n",
       " 'HubertForCTC',\n",
       " 'HubertForSequenceClassification',\n",
       " 'HubertModel',\n",
       " 'HubertPreTrainedModel',\n",
       " 'IBertConfig',\n",
       " 'IBertForMaskedLM',\n",
       " 'IBertForMultipleChoice',\n",
       " 'IBertForQuestionAnswering',\n",
       " 'IBertForSequenceClassification',\n",
       " 'IBertForTokenClassification',\n",
       " 'IBertModel',\n",
       " 'IBertPreTrainedModel',\n",
       " 'ImageGPTConfig',\n",
       " 'ImageGPTFeatureExtractor',\n",
       " 'ImageGPTForCausalImageModeling',\n",
       " 'ImageGPTForImageClassification',\n",
       " 'ImageGPTImageProcessor',\n",
       " 'ImageGPTModel',\n",
       " 'ImageGPTPreTrainedModel',\n",
       " 'InformerConfig',\n",
       " 'InformerForPrediction',\n",
       " 'InformerModel',\n",
       " 'InformerPreTrainedModel',\n",
       " 'JukeboxConfig',\n",
       " 'JukeboxModel',\n",
       " 'JukeboxPreTrainedModel',\n",
       " 'JukeboxPrior',\n",
       " 'JukeboxPriorConfig',\n",
       " 'JukeboxTokenizer',\n",
       " 'JukeboxVQVAE',\n",
       " 'JukeboxVQVAEConfig',\n",
       " 'JukeboxPrior',\n",
       " 'JukeboxPriorConfig',\n",
       " 'JukeboxVQVAE',\n",
       " 'JukeboxVQVAEConfig',\n",
       " 'LEDConfig',\n",
       " 'LEDForConditionalGeneration',\n",
       " 'LEDForQuestionAnswering',\n",
       " 'LEDForSequenceClassification',\n",
       " 'LEDModel',\n",
       " 'LEDPreTrainedModel',\n",
       " 'LEDTokenizer',\n",
       " 'LEDTokenizerFast',\n",
       " 'LED_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'LED_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'LayoutLMConfig',\n",
       " 'LayoutLMForMaskedLM',\n",
       " 'LayoutLMForQuestionAnswering',\n",
       " 'LayoutLMForSequenceClassification',\n",
       " 'LayoutLMForTokenClassification',\n",
       " 'LayoutLMModel',\n",
       " 'LayoutLMPreTrainedModel',\n",
       " 'LayoutLMTokenizer',\n",
       " 'LayoutLMTokenizerFast',\n",
       " 'LayoutLMv2Config',\n",
       " 'LayoutLMv2FeatureExtractor',\n",
       " 'LayoutLMv2ForQuestionAnswering',\n",
       " 'LayoutLMv2ForSequenceClassification',\n",
       " 'LayoutLMv2ForTokenClassification',\n",
       " 'LayoutLMv2ImageProcessor',\n",
       " 'LayoutLMv2Model',\n",
       " 'LayoutLMv2PreTrainedModel',\n",
       " 'LayoutLMv2Processor',\n",
       " 'LayoutLMv2Tokenizer',\n",
       " 'LayoutLMv2TokenizerFast',\n",
       " 'LayoutLMv3Config',\n",
       " 'LayoutLMv3FeatureExtractor',\n",
       " 'LayoutLMv3ForQuestionAnswering',\n",
       " 'LayoutLMv3ForSequenceClassification',\n",
       " 'LayoutLMv3ForTokenClassification',\n",
       " 'LayoutLMv3ImageProcessor',\n",
       " 'LayoutLMv3Model',\n",
       " 'LayoutLMv3PreTrainedModel',\n",
       " 'LayoutLMv3Processor',\n",
       " 'LayoutLMv3Tokenizer',\n",
       " 'LayoutLMv3TokenizerFast',\n",
       " 'LayoutLMv2Config',\n",
       " 'LayoutLMv2FeatureExtractor',\n",
       " 'LayoutLMv2ForQuestionAnswering',\n",
       " 'LayoutLMv2ForSequenceClassification',\n",
       " 'LayoutLMv2ForTokenClassification',\n",
       " 'LayoutLMv2ImageProcessor',\n",
       " 'LayoutLMv2Model',\n",
       " 'LayoutLMv2PreTrainedModel',\n",
       " 'LayoutLMv2Processor',\n",
       " 'LayoutLMv2Tokenizer',\n",
       " 'LayoutLMv2TokenizerFast',\n",
       " 'LayoutLMv3Config',\n",
       " 'LayoutLMv3FeatureExtractor',\n",
       " 'LayoutLMv3ForQuestionAnswering',\n",
       " 'LayoutLMv3ForSequenceClassification',\n",
       " 'LayoutLMv3ForTokenClassification',\n",
       " 'LayoutLMv3ImageProcessor',\n",
       " 'LayoutLMv3Model',\n",
       " 'LayoutLMv3PreTrainedModel',\n",
       " 'LayoutLMv3Processor',\n",
       " 'LayoutLMv3Tokenizer',\n",
       " 'LayoutLMv3TokenizerFast',\n",
       " 'LevitConfig',\n",
       " 'LevitFeatureExtractor',\n",
       " 'LevitForImageClassification',\n",
       " 'LevitForImageClassificationWithTeacher',\n",
       " 'LevitImageProcessor',\n",
       " 'LevitModel',\n",
       " 'LevitPreTrainedModel',\n",
       " 'LiltConfig',\n",
       " 'LiltForQuestionAnswering',\n",
       " 'LiltForSequenceClassification',\n",
       " 'LiltForTokenClassification',\n",
       " 'LiltModel',\n",
       " 'LiltPreTrainedModel',\n",
       " 'LongT5Config',\n",
       " 'LongT5EncoderModel',\n",
       " 'LongT5ForConditionalGeneration',\n",
       " 'LongT5Model',\n",
       " 'LongT5PreTrainedModel',\n",
       " 'LongformerConfig',\n",
       " 'LongformerForMaskedLM',\n",
       " 'LongformerForMultipleChoice',\n",
       " 'LongformerForQuestionAnswering',\n",
       " 'LongformerForSequenceClassification',\n",
       " 'LongformerForTokenClassification',\n",
       " 'LongformerModel',\n",
       " 'LongformerPreTrainedModel',\n",
       " 'LongformerSelfAttention',\n",
       " 'LongformerTokenizer',\n",
       " 'LongformerTokenizerFast',\n",
       " 'LukeConfig',\n",
       " 'LukeForEntityClassification',\n",
       " 'LukeForEntityPairClassification',\n",
       " 'LukeForEntitySpanClassification',\n",
       " 'LukeForMaskedLM',\n",
       " 'LukeForMultipleChoice',\n",
       " 'LukeForQuestionAnswering',\n",
       " 'LukeForSequenceClassification',\n",
       " 'LukeForTokenClassification',\n",
       " 'LukeModel',\n",
       " 'LukePreTrainedModel',\n",
       " 'LukeTokenizer',\n",
       " 'LxmertConfig',\n",
       " 'LxmertEncoder',\n",
       " 'LxmertForPreTraining',\n",
       " 'LxmertForQuestionAnswering',\n",
       " 'LxmertModel',\n",
       " 'LxmertPreTrainedModel',\n",
       " 'LxmertTokenizer',\n",
       " 'LxmertTokenizerFast',\n",
       " 'LxmertVisualFeatureEncoder',\n",
       " 'LxmertXLayer',\n",
       " 'M2M100Config',\n",
       " 'M2M100ForConditionalGeneration',\n",
       " 'M2M100Model',\n",
       " 'M2M100PreTrainedModel',\n",
       " 'M2M100Tokenizer',\n",
       " 'MBart50Tokenizer',\n",
       " 'MBart50TokenizerFast',\n",
       " 'MBartConfig',\n",
       " 'MBartForCausalLM',\n",
       " 'MBartForConditionalGeneration',\n",
       " 'MBartForQuestionAnswering',\n",
       " 'MBartForSequenceClassification',\n",
       " 'MBartModel',\n",
       " 'MBartPreTrainedModel',\n",
       " 'MBartTokenizer',\n",
       " 'MBartTokenizerFast',\n",
       " 'MCTCTConfig',\n",
       " 'MCTCTFeatureExtractor',\n",
       " 'MCTCTForCTC',\n",
       " 'MCTCTModel',\n",
       " 'MCTCTPreTrainedModel',\n",
       " 'MCTCTProcessor',\n",
       " 'MCTCT_PRETRAINED_CONFIG_ARCHIVE_MAP',\n",
       " 'MCTCT_PRETRAINED_MODEL_ARCHIVE_LIST',\n",
       " 'MMBTConfig',\n",
       " 'MMBTForClassification',\n",
       " 'MMBTModel',\n",
       " 'MPNetConfig',\n",
       " 'MPNetForMaskedLM',\n",
       " 'MPNetForMultipleChoice',\n",
       " 'MPNetForQuestionAnswering',\n",
       " 'MPNetForSequenceClassification',\n",
       " 'MPNetForTokenClassification',\n",
       " 'MPNetLayer',\n",
       " 'MPNetModel',\n",
       " 'MPNetPreTrainedModel',\n",
       " 'MPNetTokenizer',\n",
       " 'MPNetTokenizerFast',\n",
       " 'MT5Config',\n",
       " 'MT5EncoderModel',\n",
       " 'MT5ForConditionalGeneration',\n",
       " 'MT5Model',\n",
       " 'MT5PreTrainedModel',\n",
       " 'MT5Tokenizer',\n",
       " 'MT5TokenizerFast',\n",
       " 'MarianConfig',\n",
       " 'MarianForCausalLM',\n",
       " 'MarianMTModel',\n",
       " 'MarianModel',\n",
       " 'MarianTokenizer',\n",
       " 'MarkupLMConfig',\n",
       " 'MarkupLMFeatureExtractor',\n",
       " 'MarkupLMForQuestionAnswering',\n",
       " 'MarkupLMForSequenceClassification',\n",
       " 'MarkupLMForTokenClassification',\n",
       " 'MarkupLMModel',\n",
       " 'MarkupLMPreTrainedModel',\n",
       " 'MarkupLMProcessor',\n",
       " 'MarkupLMTokenizer',\n",
       " 'MarkupLMTokenizerFast',\n",
       " 'Mask2FormerConfig',\n",
       " 'Mask2FormerForUniversalSegmentation',\n",
       " 'Mask2FormerImageProcessor',\n",
       " 'Mask2FormerModel',\n",
       " 'Mask2FormerPreTrainedModel',\n",
       " 'MaskFormerConfig',\n",
       " 'MaskFormerFeatureExtractor',\n",
       " 'MaskFormerForInstanceSegmentation',\n",
       " 'MaskFormerImageProcessor',\n",
       " 'MaskFormerModel',\n",
       " 'MaskFormerPreTrainedModel',\n",
       " 'MaskFormerSwinBackbone',\n",
       " 'MaskFormerSwinConfig',\n",
       " 'MaskFormerSwinBackbone',\n",
       " 'MaskFormerSwinConfig',\n",
       " 'MegatronBertConfig',\n",
       " 'MegatronBertForCausalLM',\n",
       " 'MegatronBertForMaskedLM',\n",
       " 'MegatronBertForMultipleChoice',\n",
       " 'MegatronBertForNextSentencePrediction',\n",
       " 'MegatronBertForPreTraining',\n",
       " 'MegatronBertForQuestionAnswering',\n",
       " 'MegatronBertForSequenceClassification',\n",
       " 'MegatronBertForTokenClassification',\n",
       " 'MegatronBertModel',\n",
       " 'MegatronBertPreTrainedModel',\n",
       " 'MgpstrConfig',\n",
       " 'MgpstrForSceneTextRecognition',\n",
       " 'MgpstrModel',\n",
       " 'MgpstrPreTrainedModel',\n",
       " 'MgpstrProcessor',\n",
       " 'MgpstrTokenizer',\n",
       " 'MobileBertConfig',\n",
       " 'MobileBertForMaskedLM',\n",
       " 'MobileBertForMultipleChoice',\n",
       " 'MobileBertForNextSentencePrediction',\n",
       " 'MobileBertForPreTraining',\n",
       " 'MobileBertForQuestionAnswering',\n",
       " 'MobileBertForSequenceClassification',\n",
       " 'MobileBertForTokenClassification',\n",
       " 'MobileBertLayer',\n",
       " 'MobileBertModel',\n",
       " 'MobileBertPreTrainedModel',\n",
       " 'MobileBertTokenizer',\n",
       " 'MobileBertTokenizerFast',\n",
       " 'MobileNetV1Config',\n",
       " 'MobileNetV1FeatureExtractor',\n",
       " ...]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save new_config_names to a json file\n",
    "import json\n",
    "\n",
    "with open('model_list.json', 'w') as f:\n",
    "    json.dump(new_config_names, f)\n",
    "\n",
    "with open('modelArch_list.json', 'w') as f:\n",
    "    json.dump(model_list, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PTM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
